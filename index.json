[{"categories":["极客有力量"],"content":"本文记录如何把米家蓝牙温湿度计 2（型号LYWSD03MMC）集成到 Home Assistant 中。 前言 米家蓝牙温湿度计 2（型号LYWSD03MMC）是小米出品的价格十分美丽的蓝牙温湿度计，69 元 3 个，长这样 ![LYWSD03MMC](在 Home Assistant 中集成 69 元 3 个的米家蓝牙温湿度计 2.assets/LYWSD03MMC.jpg) 它的蓝牙数据广播频率为： 大约每隔 10 分钟通过蓝牙广播温湿度数据； 大约每隔 1 小时通过蓝牙广播电量。 Home Assistant（以下简称 HA） 的 官方集成 ，目前不支持米家蓝牙温湿度计 2，原因可能是 2 代的蓝牙广播数据进行了加密。我在 GitHub 上找到了一个 HA 的自定义组件 ble_monitor，几乎支持米家所有的蓝牙温湿度计硬件，非常不错。 本次集成所使用的版本为： Python 3.8.6； Home Assistant 0.118.4 米家蓝牙温湿度计 2 固件版本号 0109； 集成步骤 ","date":"2020-11-29","objectID":"/posts/b5ee0/:0:0","tags":[],"title":"在 Home Assistant 中集成 69 元 3 个的米家蓝牙温湿度计 2","uri":"/posts/b5ee0/"},{"categories":["极客有力量"],"content":"准备 Python 环境 ble_monitor 需要使用 Python 标准库的 socket.AF_BLUETOOTH，需要先检查运行 HA 的 Python 环境是否有支持常量。若不支持则需要重新编译 Python 环境。 以 Debian 系统为例，首先安装 libbluetooth-dev 包，确保 /usr/include 或 /usr/include/bluetooth 路径中有 bluetooth.h 文件。 sudo apt install libbluetooth-dev 然后使用 pyenv 编译 Python，此时编译出的 Python 就会支持 socket.AF_BLUETOOTH pyenv install 3.8.6 ","date":"2020-11-29","objectID":"/posts/b5ee0/:1:0","tags":[],"title":"在 Home Assistant 中集成 69 元 3 个的米家蓝牙温湿度计 2","uri":"/posts/b5ee0/"},{"categories":["极客有力量"],"content":"安装 HA 自定义组件 ble_monitor ble_monitor 是一个被动式收集数据的自定义组件。它不主动向温湿度计发起轮询请求数据，而是被动地等待温湿度计的蓝牙广播，能够有效节约蓝牙温湿度计的电池电量。 首先要授权运行 HA 的 Python 对 HCI interface 的 rootless 访问权限（使用 Python 虚拟环境运行 HA 的要在虚拟环境中执行）： sudo setcap 'cap_net_raw,cap_net_admin+eip' `readlink -f \\`which python3\\`` 检查权限设置： sudo getcap `readlink -f \\`which python3\\`` 获取代码 git clone https://github.com/custom-components/ble_monitor.git 添加自定义组件到 HA 配置中 cp -r ble_monitor/custom_components/ble_monitor \u003cHA_CONFIG\u003e/custom_components/ \u003cHA_CONFIG\u003e 请替换为 HA 的配置目录，一般是 $HOME/.homeassistant。 ","date":"2020-11-29","objectID":"/posts/b5ee0/:2:0","tags":[],"title":"在 Home Assistant 中集成 69 元 3 个的米家蓝牙温湿度计 2","uri":"/posts/b5ee0/"},{"categories":["极客有力量"],"content":"获取温湿度计数据加密密钥 如上文所述，米家蓝牙温湿度计 2 的蓝牙广播数据默认是加密的，我们要配置密钥才能正确解析数据。获取密钥有多种方法，可以参考 ble_monitor/faq.md at master · custom-components/ble_monitor，这里使用最简单的一种。 首先，在米家 App 添加将米家蓝牙温湿度计 2，读取到数据。 然后，在 Android 手机、支持蓝牙功能的 Windows、Mac 上用 Chrome 打开 Telink Flasher 这个网站，点击 Connect，Chrome 会请求蓝牙权限，并扫描附近的蓝牙设备，选择名为 LYWSD03MMC 进行配对。由于米家蓝牙温湿度计 2 的蓝牙广播周期较长，需要耐心等待其出现在设备列表中。 配对成功后网页上会展示实时的温度和湿度，此时点击 “Do Activation” 按钮，等待完成后，“Mi Bind Key” 中的值就是我们需要的密钥。 ","date":"2020-11-29","objectID":"/posts/b5ee0/:3:0","tags":[],"title":"在 Home Assistant 中集成 69 元 3 个的米家蓝牙温湿度计 2","uri":"/posts/b5ee0/"},{"categories":["极客有力量"],"content":"添加 HA 配置 在 HA 的 configuration.yaml 中，添加配置，保存后重启 HA 服务。 ble_monitor:rounding:Truedecimals:1period:60log_spikes:Falseuse_median:Falseactive_scan:Falsehci_interface:0batt_entities:Falsediscovery:Truerestore_state:Falsereport_unknown:Falsedevices:- mac:'A4:C1:38:2F:86:6C'# 米家蓝牙温湿度计 2 的蓝牙 MAC 地址name:'Livingroom'encryption_key:'217C568CF5D22808DA20181502D84C1B'# 上一步中获取到的密钥temperature_unit:C 具体配置项含义请参考 ble_monitor 的 README。 使用感受 米家蓝牙温湿度计 2 的数据更新时间比较久，大概每隔 11 分钟更新一次； 每次更新时的数据不是实时数据，猜测是 11 分钟内温度数据的均值； 因此这种集成，不太适合作为传感器触发自动化温度调节。 想要提高米家蓝牙温湿度计 2 广播频率，可以选择给米家蓝牙温湿度计 2 刷自定义的固件，参考 atc1441/ATC_MiThermometer: Custom firmware for the Xiaomi Thermometer LYWSD03MMC and Telink Flasher via USB to Serial converter。 参考链接 Home Assistant Xiaomi Mijia BLE Temperature and Humidity Sensor - Home Assistant Missing socket.AF_BLUETOOTH in Anaconda Python? - Stack Overflow custom-components/ble_monitor: Xiaomi Mijia BLE MiBeacon monitor ble_monitor/faq.md at master · custom-components/ble_monitor Telink Flasher atc1441/ATC_MiThermometer: Custom firmware for the Xiaomi Thermometer LYWSD03MMC and Telink Flasher via USB to Serial converter ","date":"2020-11-29","objectID":"/posts/b5ee0/:4:0","tags":[],"title":"在 Home Assistant 中集成 69 元 3 个的米家蓝牙温湿度计 2","uri":"/posts/b5ee0/"},{"categories":["Web 开发"],"content":"《图解 HTTP》是一本通俗易懂的介绍 HTTP 协议的书，由日本作者上野宣写作于 2014 年。由于写作时间早于 HTTP/2 的正式发布时间——2015 年 5 月，书中对于 HTTP/2 的部分表述可能有所出入。 了解 Web 及网络基础 ","date":"2020-11-22","objectID":"/posts/eeefc/:0:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"网络基础 TCP/IP 协议族 TCP/IP 协议族由上至下分为 4 层：应用层、传输层、网络层、数据链路层。 利用 TCP/IP 协议族进行网络通信时，会通过分层顺序与对方进行通信。发送端从应用层往下走，接收端则往应用层往上走。 发送端在层与层之间传输数据时，每经过一层时必定会被打上一个该层所属的首部信息。反之，接收端在层与层传输数据时，每经过一层时会把对应的首部消去。这种把数据信息包装起来的做法称为封装（encapsulate）。 ","date":"2020-11-22","objectID":"/posts/eeefc/:1:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"与 HTTP 关系密切的协议：IP、TCP 和 DNS IP（Internet Protocol）网际协议位于网络层，IP 协议的作用是把各种数据包传送给对方。 路由选择（routing），没有计算机设备能够掌握互联网中的细节。 字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。 ","date":"2020-11-22","objectID":"/posts/eeefc/:2:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"URI 和 URL URL（Uniform Resource Locator，统一资源定位符）。URL 正是使用 Web 浏览器等访问 Web 页面时需要输入的网页地址。 URI 是 Uniform Resource Identifier 的缩写，称为统一资源标识符。 Uniform：规定统一的格式； Resource：资源的定义是“可标识的任何东西”。 Identifier：表示可标识的对象。也称为标识符。 综上所述，URI 就是由某个协议方案表示的资源的定位标识符。 标准的 URI 协议方案有 30 种左右，由隶属于国际互联网资源管理的非营利社团 ICANN（Internet Corporation for Assigned Names and Numbers，互联网名称与数字地址分配机构 ）的 IANA（Internet Assigned Numbers Authority，互联网号码分配局）管理颁布。 URI 用字符串标识某一互联网资源，而 URL 表示资源的地点（互联网上所处的位置）。可见 URL 是 URI 的子集。 简单的 HTTP 协议 ","date":"2020-11-22","objectID":"/posts/eeefc/:3:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"请求报文和响应报文 请求报文是由请求方法、请求 URI、协议版本、可选的请求首部字段和内容实体构成的。 响应报文基本上由协议版本、状态码（表示请求成功或失败的数字代码）、用以解释状态码的原因短语、可选的响应首部字段以及实体主体构成。 ","date":"2020-11-22","objectID":"/posts/eeefc/:4:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTP 方法 GET 获取资源； POST 传输实体； PUT 传输文件，HTTP/1.1 的 PUT 方法自身不带验证机制； HEAD 与 GET 一样，但不返回报文主体内容； OPTIONS 用来查询支持的方法。 TRACE 让 Web 服务器端将之前的请求通信环回给客户端的方法。 CONNECT 要求在与代理服务器通信时建立隧道，实现用隧道协议进行 TCP 通信。 HTTP 报文内的 HTTP 信息 ","date":"2020-11-22","objectID":"/posts/eeefc/:5:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"编码提升传输速率 压缩传输的内容编码：把实体压缩后传送。主要有： gzip（GNU zip） compress（UNIX 系统的标准压缩） deflate（zlib） identity（不进行编码） 分割发送的分块传输编码：在传输大容量数据时，把数据分割成多块传送。 ","date":"2020-11-22","objectID":"/posts/eeefc/:6:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"multipart multipart/form-data 在 Web 表单文件上传时使用。 multipart/byteranges 状态码 206（Partial Content，部分内容）响应报文包含了多个范围的内容时使用。 使用时会在 header 中加上 Content-type 字段，并在其中指明 boundary 字符串，来划分多部分对象集合指明的各类实体。在 boundary 字符串指定的各个实体的起始行之前插入--标记，而在多部分对象集合对应的字符串的最后插入--标记。多部分对象集合的每个部分类型中，都可以含有首部字段。 举个栗子（from POST - HTTP | MDN） POST /test HTTP/1.1 Host: foo.example Content-Type: multipart/form-data;boundary=\"boundary\" --boundary Content-Disposition: form-data; name=\"field1\" value1 --boundary Content-Disposition: form-data; name=\"field2\"; filename=\"example.txt\" value2 --boundary-- ","date":"2020-11-22","objectID":"/posts/eeefc/:7:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"获取部分内容的范围请求 指定所请求实体的范围发送的请求叫做范围请求（Range Request）。 执行范围请求时，会用到首部字段 Range 来指定资源的 byte 范围。 Range: bytes=5001-10000 针对范围请求，响应会返回状态码为 206 Partial Content 的响应报文。 如果服务器端无法响应范围请求，则会返回状态码 200 OK 和完整的实体内容。 ","date":"2020-11-22","objectID":"/posts/eeefc/:8:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"内容协商返回最合适的内容 内容协商（Content Negotiation） 服务器驱动协商（Server-driven Negotiation） 客户端驱动协商（Agent-driven Negotiation） 透明协商（Transparent Negotiation） 返回结果的 HTTP 状态码 状态码以 3 位数字和原因短语组成，例如 200 OK。 ","date":"2020-11-22","objectID":"/posts/eeefc/:9:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"2XX 成功 204 No Content 该状态码代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。 206 Partial Content 该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的 GET 请求。响应报文中包含由 Content-Range 指定范围的实体内容。 ","date":"2020-11-22","objectID":"/posts/eeefc/:10:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"3XX 重定向 303 See Other 303 状态码和 302 Found 状态码有着相同的功能，但 303 状态码明确表示客户端应当采用 GET 方法获取资源，这点与 302 状态码有区别。301、302 标准是禁止将 POST 方法改变成 GET 方法的，但实际使用时大家都会这么做。 307 Temporary Redirect 和 302 Found 状态码有着相同的含义，但 307 会遵照浏览器标准，不会从 POST 变成 GET。 ","date":"2020-11-22","objectID":"/posts/eeefc/:11:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"4XX 客户端错误 401 Unauthorized 该状态码表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。返回含有 401 的响应必须包含一个适用于被请求资源的 WWW-Authenticate 首部用以质询（challenge）用户信息。也就是说，不采用 HTTP 认证的 Web 系统不应该使用该状态码。 ","date":"2020-11-22","objectID":"/posts/eeefc/:12:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"5XX 服务器错误 当返回 503 时，如果事先得知解除以上状况需要的时间，最好写入 Retry-After 首部字段再返回给客户端。 与 HTTP 协作的 Web 服务器 ","date":"2020-11-22","objectID":"/posts/eeefc/:13:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"代理、网关和隧道 HTTP 通信过程中，转发时，需要附加 Via 首部字段以标记出经过的主机信息。 代理： 缓存代理（Caching Proxy） 会预先将资源的副本（缓存）保存在代理服务器上 透明代理（Transparent Proxy） 转发请求或响应时，不对报文做任何加工的代理。反之，对报文内容进行加工的代理被称为非透明代理。 网关能使通信线路上的服务器提供非 HTTP 协议服务。 隧道的目的是确保客户端能与服务器进行安全的通信，隧道本身不会去解析 HTTP 请求。 HTTP 首部 ","date":"2020-11-22","objectID":"/posts/eeefc/:14:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTP 报文首部 在请求中，HTTP 报文由方法、URI、HTTP 版本、HTTP 首部字段等部分构成。 在响应中，HTTP 报文由 HTTP 版本、状态码（数字和原因短语）、HTTP 首部字段 3 部分构成。 ","date":"2020-11-22","objectID":"/posts/eeefc/:15:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTP 首部字段 根据实际用途被分为以下 4 种类型： 通用首部字段（General Header Fields） 请求首部字段（Request Header Fields） 响应首部字段（Response Header Fields） 实体首部字段（Entity Header Fields） 实体首部字段是针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的信息。 首部字段的主要定义在 RFC 2616 - Hypertext Transfer Protocol -- HTTP/1.1 和 RFC 4229 - HTTP Header Field Registrations 中。 逐跳首部（Hop-by-hop Header）首部只对单次转发有效，会因通过缓存或代理而不再转发。HTTP/1.1 中的逐跳首部字段有： Connection Keep-Alive Proxy-Authenticate Proxy-Authorization Trailer TE Transfer-Encoding Upgrade 除这 8 个首部字段之外，其他所有字段都属于端到端首部。 ","date":"2020-11-22","objectID":"/posts/eeefc/:16:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTP/1.1 通用首部字段 ","date":"2020-11-22","objectID":"/posts/eeefc/:17:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"Cache-Control 通过指定首部字段 Cache-Control 的指令，就能操作缓存的工作机制。 no-cache 指令： 客户端发送的请求中如果包含 no-cache 指令，则表示客户端将不会接收缓存过的响应。于是，“中间”的缓存服务器必须把客户端请求转发给源服务器。 如果服务器返回的响应中包含 no-cache 指令，那么缓存服务器不能对资源进行缓存。 由服务器返回的响应中，若报文首部字段 Cache-Control 中对 no-cache 字段名具体指定参数值，那么客户端在接收到这个被指定参数值的首部字段对应的响应报文后，就不能使用缓存。 no-store 指令：当使用 no-store 指令时，暗示请求（和对应的响应）或响应中包含机密信息。因此，该指令规定缓存不能在本地存储请求或响应的任一部分。 max-age 指令： 当客户端发送的请求中包含 max-age 指令时，如果判定缓存资源的缓存时间数值比指定时间的数值更小，那么客户端就接收缓存的资源。另外，当指定 max-age 值为 0，那么缓存服务器通常需要将请求转发给源服务器。 当服务器返回的响应中包含 max-age 指令时，缓存服务器将不对资源的有效性再作确认，而 max-age 数值代表资源保存为缓存的最长时间。 no-transform 指令：无论是在请求还是响应中，缓存都不能改变实体主体的媒体类型。 ","date":"2020-11-22","objectID":"/posts/eeefc/:17:1","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"Connection Connection 字段的作用： 控制不再转发给代理的首部字段。在客户端发送请求和服务器返回响应内，使用 Connection 首部字段，可控制不再转发给代理的首部字段（即 Hop-by-hop 首部）。 管理持久连接。HTTP/1.1 版本的默认连接都是持久连接。为此，客户端会在持久连接上连续发送请求。当服务器端想明确断开连接时，则指定 Connection 首部字段的值为 Close。 ","date":"2020-11-22","objectID":"/posts/eeefc/:17:2","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"Transfer-Encoding 首部字段 Transfer-Encoding 规定了传输报文主体时采用的编码方式。HTTP/1.1 的传输编码方式仅对分块传输编码有效。 ","date":"2020-11-22","objectID":"/posts/eeefc/:17:3","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"Upgrade 首部字段 Upgrade 用于检测 HTTP 协议及其他协议是否可使用更高的版本进行通信，其参数值可以用来指定一个完全不同的通信协议。 Upgrade 首部字段产生作用的 Upgrade 对象仅限于客户端和邻接服务器之间。因此，使用首部字段 Upgrade 时，还需要额外指定 Connection:Upgrade。 ","date":"2020-11-22","objectID":"/posts/eeefc/:17:4","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"Via 使用首部字段 Via 是为了追踪客户端与服务器之间的请求和响应报文的传输路径。 Via 首部是为了追踪传输路径，所以经常会和 TRACE 方法一起使用。 ","date":"2020-11-22","objectID":"/posts/eeefc/:17:5","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"请求首部字段 Accept 首部字段可通知服务器，用户代理能够处理的媒体类型及媒体类型的相对优先级。可使用 type/subtype 这种形式，一次指定多种媒体类型。若想要给显示的媒体类型增加优先级，则使用 q=来额外表示权重值 Accept-Charset 首部字段可用来通知服务器用户代理支持的字符集及字符集的相对优先顺序。另外，可一次性指定多种字符集。与首部字段 Accept 相同的是可用权重 q 值来表示相对优先级。 Accept-Encoding 首部字段用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序。可一次性指定多种内容编码。 gzip compress deflate identity Accept-Language 用来告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级。可一次指定多种自然语言集。和 Accept 首部字段一样，按权重值 q 来表示相对优先级。 Authorization 是用来告知服务器，用户代理的认证信息（证书值）。 Expect 来告知服务器，期望出现的某种特定行为。因服务器无法理解客户端的期望作出回应而发生错误时，会返回状态码 417 Expectation Failed。 From 用来告知服务器使用用户代理的用户的电子邮件地址。 Host 会告知服务器，请求的资源所处的互联网主机名和端口号。Host 首部字段在 HTTP/1.1 规范内是唯一一个必须被包含在请求内的首部字段。 Max-Forwards：通过 TRACE 方法或 OPTIONS 方法，发送包含首部字段 Max-Forwards 的请求时，该字段以十进制整数形式指定可经过的服务器最大数目。服务器在往下一个服务器转发请求之前，会将 Max-Forwards 的值减 1 后重新赋值。当服务器接收到 Max-Forwards 值为 0 的请求时，则不再进行转发，而是直接返回响应。 Proxy-Authorization：接收到从代理服务器发来的认证质询时，客户端会发送包含首部字段 Proxy-Authorization 的请求，以告知服务器认证所需要的信息。 Range：对于只需获取部分资源的范围请求，包含首部字段 Range 即可告知服务器资源的指定范围。 Referer：正确拼写应是 Referrer，当直接在浏览器的地址栏输入 URI 时，或出于安全性的考虑时，也可以不发送该首部字段。 ","date":"2020-11-22","objectID":"/posts/eeefc/:18:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"响应首部字段 ETag 能告知客户端实体标识。它是一种可将资源以字符串形式做唯一性标识的方式。服务器会为每份资源分配对应的 ETag 值。 Location 可以将响应接收方引导至某个与请求 URI 位置不同的资源。 Proxy-Authenticate 会把由代理服务器所要求的认证信息发送给客户端。 Retry-After 告知客户端应该在多久之后再次发送请求。 Server 告知客户端当前服务器上安装的 HTTP 服务器应用程序的信息。 WWW-Authenticate 用于 HTTP 访问认证。它会告知客户端适用于访问请求 URI 所指定资源的认证方案（Basic 或是 Digest）和带参数提示的质询（challenge）。 ","date":"2020-11-22","objectID":"/posts/eeefc/:19:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"实体首部字段 实体首部字段是包含在请求报文和响应报文中的实体部分所使用的首部，用于补充内容的更新时间等与实体相关的信息。 Allow 用于通知客户端能够支持 Request-URI 指定资源的所有 HTTP 方法。 Content-Encoding 会告知客户端服务器对实体的主体部分选用的内容编码方式，主要有： gzip compress deflate identity Content-Language 会告知客户端，实体主体使用的自然语言（指中文或英文等语言）。 Content-Type 说明了实体主体内对象的媒体类型。 ","date":"2020-11-22","objectID":"/posts/eeefc/:20:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"为 Cookie 服务的首部字段 Cookie 的 path 属性可用于限制指定 Cookie 的发送范围的文件目录。不过另有办法可避开这项限制，看来对其作为安全机制的效果不能抱有期待。 通过 Cookie 的 domain 属性指定的域名可做到与结尾匹配一致。 ","date":"2020-11-22","objectID":"/posts/eeefc/:21:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"其他首部字段 X-Frame-Options 属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（click jacking）攻击。可指定的字段值有： DENY：拒绝； SAMEORIGIN：仅同源域名下的页面（Top-level-browsing-context）匹配时许可。 X-XSS-Protection 属于 HTTP 响应首部，它是针对跨站脚本攻击（XSS）的一种对策，用于控制浏览器 XSS 防护机制的开关。首部字段 X-XSS-Protection 可指定的字段值有： 0 ：将 XSS 过滤设置成无效状态； 1 ：将 XSS 过滤设置成有效状态。 DNT 属于 HTTP 请求首部，其中 DNT 是 Do Not Track 的简称，意为拒绝个人信息被收集，是表示拒绝被精准广告追踪的一种方法。首部字段 DNT 可指定的字段值有： 0 ：同意被追踪 1 ：拒绝被追踪 在 HTTP 等多种协议中，通过给非标准参数加上前缀 X-，来区别于标准参数，并使那些非标准的参数作为扩展变成可能。但是这种简单粗暴的做法有百害而无一益，因此在 RFC 6648 - Deprecating the “X-” Prefix and Similar Constructs in Application Protocols 中提议停止该做法。然而，对已经在使用中的 X-前缀来说，不应该要求其变更。 确保 Web 安全的 HTTPS ","date":"2020-11-22","objectID":"/posts/eeefc/:22:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTP 的缺点 通信使用明文（不加密），内容可能会被窃听； 不验证通信方的身份，因此有可能遭遇伪装； 无法证明报文的完整性，所以有可能已遭篡改； 几个名词缩写： SSL（Secure Socket Layer，安全套接层） TLS（Transport LayerSecurity，安全传输层协议） PGP（Pretty Good Privacy，完美隐私） ","date":"2020-11-22","objectID":"/posts/eeefc/:23:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTP + 加密 + 认证 + 完整性保护 = HTTPS SSL 是独立于 HTTP 的协议，所以不光是 HTTP 协议，其他运行在应用层的 SMTP 和 Telnet 等协议均可配合 SSL 协议使用。可以说 SSL 是当今世界上应用最为广泛的网络安全技术。 两种加密方式： 公开密钥加密（Public-key cryptography） 加密使用一对非对称的密钥，分别叫做私钥（private key）和公钥（public key）。私钥不能让其他任何人知道，而公钥则可以随意发布，任何人都可以获得。 共享密钥加密（Common key crypto system） 加密和解密同用一个密钥，也被叫做对称密钥加密。 HTTPS 采用共享密钥加密和公开密钥加密两者并用的混合加密机制——在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。 ","date":"2020-11-22","objectID":"/posts/eeefc/:24:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTPS 数字证书 数字证书认证机构（CA, Certificate Authority）处于客户端与服务器双方都可信赖的第三方机构的立场上。在判明提出申请者的身份之后，会对申请的公钥做数字签名，然后分配这个已签名的公钥，并将该公钥放入公钥证书后绑定在一起。公钥证书也可叫做数字证书或直接称为证书。 服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端； 客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可确认认证服务器公钥的是真实有效的数字证书认证机构，进而确认服务器的公钥是值得信赖的。 SSL 机制中，介入认证机构之所以可行，是因为建立在其信用绝对可靠这一大前提下的。值得信赖的第三方机构介入认证，才能让已植入在浏览器内的认证机构颁布的公开密钥发挥作用，并借此证明服务器的真实性。 HTTPS 中还可以使用客户端证书。以客户端证书进行客户端认证，证明服务器正在通信的对方始终是预料之内的客户端，其作用跟服务器证书如出一辙。但客户端证书仍存在几点问题： 证书的获取及发布困难，对 Web 系统的用户来说自行安装证书需要学习成本； 客户端证书只能用来证明客户端真实有效，而不能用来证明用户本人的真实有效性； ","date":"2020-11-22","objectID":"/posts/eeefc/:25:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTPS 的通信步骤 客户端通过发送 Client Hello 报文开始 SSL 通信。报文中包含客户端支持的 SSL 的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）。 服务器可进行 SSL 通信时，会以 Server Hello 报文作为应答。和客户端一样，在报文中包含 SSL 版本以及加密组件。服务器的加密组- 件内容是从接收到的客户端加密组件内筛选出来的。 之后服务器发送 Certificate 报文。报文中包含公开密钥证书。 最后服务器发送 Server Hello Done 报文通知客户端，最初阶段的 SSL 握手协商部分结束。 SSL 第一次握手结束之后，客户端以 Client Key Exchange 报文作为回应。报文中包含通信加密中使用的一种被称为 Pre-master secret 的随机密码串。该报文已用步骤 3 中的公开密钥进行加密。 接着客户端继续发送 Change Cipher Spec 报文。该报文会提示服务器，在此报文之后的通信会采用 Pre-master secret 密钥加密。 客户端发送 Finished 报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。 服务器同样发送 Change Cipher Spec 报文。 服务器同样发送 Finished 报文。 服务器和客户端的 Finished 报文交换完毕之后，SSL 连接就算建立完成。当然，通信会受到 SSL 的保护。从此处开始进行应用层协议的通信，即发送 HTTP 请求。 应用层协议通信，即发送 HTTP 响应。 最后由客户端断开连接。断开连接时，发送 close_notify 报文。上图做了一些省略，这步之后再发送 TCP FIN 报文来关闭与 TCP 的通信。 在以上流程中，应用层发送数据时会附加一种叫做 MAC（Message Authentication Code） 的报文摘要。MAC 能够查知报文是否遭到篡改，从而保护报文的完整性。 CBC 模式（Cipher Block Chaining） 又名密码分组链接模式。在此模式下，将前一个明文块加密处理后和下一个明文块做 XOR 运算，使之重叠，然后再对运算结果做加密处理。对第一个明文块做加密时，要么使用前一段密文的最后一块，要么利用外部生成的初始向量（initial vector,IV）。 确认访问用户身份的认证 质询/响应（challenge/response）认证方式是指，一开始一方会先发送认证要求给另一方，接着使用从另一方那接收到的质询码计算生成响应码。最后将响应码返回给对方进行认证的方式。 HTTP BASIC 认证和 HTTP DIGEST 认证都属于质询/响应认证方式。 ","date":"2020-11-22","objectID":"/posts/eeefc/:26:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"BASIC 认证 认证步骤： 当请求的资源需要 BASIC 认证时，服务器会随状态码 401 Authorization Required，返回带 WWW-Authenticate 首部字段的响应。该字段内包含认证的方式（BASIC）及 Request-URI 安全域字符串（realm）。 接收到状态码 401 的客户端为了通过 BASIC 认证，需要将用户 ID 及密码发送给服务器。发送的字符串内容是由用户 ID 和密码构成，两者中间以冒号 : 连接后，再经过 Base64 编码处理，放在 header 字段 Authorization 中。 缺点： 由于明文解码后就是用户 ID 和密码，在 HTTP 等非加密通信的线路上进行 BASIC 认证的过程中，如果被人窃听，被盗的可能性极高。 除此之外想再进行一次 BASIC 认证时，一般的浏览器却无法实现认证注销操作，这也是问题之一。 ","date":"2020-11-22","objectID":"/posts/eeefc/:27:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"DIGEST 认证 DIGEST 认证弥补了 BASIC 认证直接发送明文密码的缺点。 认证步骤： 请求需认证的资源时，服务器会随着状态码 401 AuthorizationRequired，返回带 WWW-Authenticate 首部字段的响应。首部字段 WWW-Authenticate 内必须包含 realm 和 nonce 这两个字段的信息。客户端就是依靠向服务器回送这两个值进行认证的。nonce 是一种每次随返回的 401 响应生成的任意随机字符串。该字符串通常推荐由 Base64 编码的十六进制数的组成形式，但实际内容依赖服务器的具体实现。 接收到 401 状态码的客户端，返回的响应中包含 DIGEST 认证必须的首部字段 Authorization 信息。首部字段 Authorization 内必须包含 username、realm、nonce、uri 和 response 的字段信息。其中，realm 和 nonce 就是之前从服务器接收到的响应中的字段。uri（digest-uri）即 Request-URI 的值，但考虑到经代理转发后 Request-URI 的值可能被修改，因此事先会复制一份副本保存在 uri 内。response 也可叫做 Request-Digest，存放经过哈希算法运算后的密码字符串（不是简单的对密码做哈希），形成响应码。 服务器认证通过后则返回包含 Request-URI 资源的响应。并且这时会在首部字段 Authentication-Info 写入一些认证成功的相关信息。 缺点：DIGEST 认证提供防止密码被窃听的保护机制，但并不存在防止用户伪装的保护机制。 ","date":"2020-11-22","objectID":"/posts/eeefc/:28:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"SSL 客户端认证 认证步骤： 接收到需要认证资源的请求，服务器会发送 Certificate Request 报文，要求客户端提供客户端证书。 用户选择将发送的客户端证书后，客户端会把客户端证书信息以 Client Certificate 报文方式发送给服务器。 服务器验证客户端证书验证通过后方可领取证书内客户端的公开密钥，然后开始 HTTPS 加密通信。 多数情况下，SSL 客户端认证会作为一种多因素认证方式存在，而不会单独使用（因为无法该方式只能认证客户端有效，不能证明客户本人有效）。并且由于成本、易用性等原因，仅在部分安全要求较高的 Web 系统中使用，例如网银、支付系统等。 ","date":"2020-11-22","objectID":"/posts/eeefc/:29:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"基于表单认证 但是对于 Web 网站的认证功能，能够满足其安全使用级别的标准规范并不存在，所以只好使用由 Web 应用程序各自实现基于表单的认证方式。 保证安全性： Session ID 应使用难以推测的字符串，且服务器端也需要进行有效期的管理，保证其安全性。 为减轻跨站脚本攻击（XSS）造成的损失，建议事先在 Cookie 内加上 httponly 属性。 不明文保存密码，加盐后做哈希。 基于 HTTP 的功能追加协议 HTTP 的瓶颈： 一条连接上只可发送一个请求。 请求只能从客户端开始。客户端不可以接收除响应以外的指令。 请求/响应首部未经压缩就发送。首部信息越多延迟越大。 发送冗长的首部。每次互相发送相同的首部造成的浪费较多。 可任意选择数据压缩格式。非强制压缩发送。 ","date":"2020-11-22","objectID":"/posts/eeefc/:30:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"Ajax、Comet 和 SPDY Ajax（Asynchronous JavaScript and XML，异步 JavaScript 与 XML 技术），Ajax 的核心技术是名为 XMLHttpRequest 的 API，借由这种手段从已加载完毕的 Web 页面上发起请求，只更新局部页面。但是，利用 Ajax 实时地从服务器获取内容，有可能会导致大量请求产生。另外 Ajax 仍未解决 HTTP 协议本身存在的问题。 Comet 是一种通过延迟应答，模拟实现服务器端向客户端推送（Server Push）的功能。Comet 会先将响应置于挂起状态，当服务器端有内容更新时，再返回该响应。这导致为了维持连接会消耗更多的资源。 SPDY 是由 Google 开发的网络传输协议，SPDY 未能单独成为正式标准，但 SPDY 的成果被采纳而最终演变为 HTTP/2。SPDY 协议通过压缩、多路复用和优先级来缩短加载时间。SPDY 基本上只是将单个域名（IP 地址）的通信多路复用，所以当一个 Web 网站上使用多个域名下的资源，改善效果就会受到限制。 ","date":"2020-11-22","objectID":"/posts/eeefc/:31:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"使用浏览器进行全双工通信的 WebSocket WebSocket 通信协议在 2011 年 12 月 11 日，被 RFC 6455 - The WebSocket Protocol 定为标准。由于是建立在 HTTP 基础上的协议，因此连接的发起方仍是客户端，而一旦确立 WebSocket 通信连接，不论服务器还是客户端，任意一方都可直接向对方发送报文。 WebSocket 协议的主要特点： 推送功能：支持由服务器向客户端推送数据； 减少通信量：长连接，header 信息比 HTTP 少； ","date":"2020-11-22","objectID":"/posts/eeefc/:32:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"Web 服务器管理文件的 WebDAV WebDAV（Web-based Distributed Authoring and Versioning，基于万维网的分布式创作和版本控制）是一个可对 Web 服务器上的内容直接进行文件复制、编辑等操作的分布式文件系统。它还具备文件创建者管理、文件编辑过程中禁止其他用户内容覆盖的加锁功能，以及对文件内容修改的版本控制功能。 构建 Web 内容的技术 ","date":"2020-11-22","objectID":"/posts/eeefc/:33:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"CGI 和 Servlet CGI（Common Gateway Interface，通用网关接口）是指 Web 服务器在接收到客户端发送过来的请求后转发给程序的一组机制。由于每次接到请求，程序都要跟着启动一次。因此一旦访问量过大，Web 服务器要承担相当大的负载。 Servlet 是一种能在服务器上创建动态内容的程序。Servlet 是用 Java 语言实现的一个接口，属于面向企业级 Java（JavaEE,Java Enterprise Edition）的一部分。 ","date":"2020-11-22","objectID":"/posts/eeefc/:34:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"数据发布的格式及语言 XML（eXtensible Markup Language，可扩展标记语言） RSS（简易信息聚合，也叫聚合内容）和 Atom JSON（JavaScript Object Notation） Web 的攻击技术 ","date":"2020-11-22","objectID":"/posts/eeefc/:35:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"对 Web 应用的攻击模式 对 Web 应用的攻击模式有两种： 主动攻击（active attack） 是指攻击者通过直接访问 Web 应用，把攻击代码传入的攻击模式。主动攻击模式里具有代表性的攻击是 SQL 注入攻击和 OS 命令注入攻击。 被动攻击（passive attack） 是指利用圈套策略执行攻击代码的攻击模式。被动攻击模式中具有代表性的攻击是跨站脚本攻击和跨站点请求伪造。 主动攻击直接针对服务器资源进行攻击，被动攻击的目标是使用 Web 应用的用户。 ","date":"2020-11-22","objectID":"/posts/eeefc/:36:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"因输出值转义不完全引发的安全漏洞 ","date":"2020-11-22","objectID":"/posts/eeefc/:37:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"跨站脚本攻击 跨站脚本攻击（Cross-Site Scripting,XSS） 是指通过存在安全漏洞的 Web 网站注册用户的浏览器内运行非法的 HTML 标签或 JavaScript 进行的一种攻击。 会造成以下影响： 利用虚假输入表单骗取用户个人信息； 利用脚本窃取用户的 Cookie 值，被害者在不知情的情况下，帮助攻击者发送恶意请求； 显示伪造的文章或图片。 XSS 是攻击者利用预先设置的陷阱触发的被动攻击。 ","date":"2020-11-22","objectID":"/posts/eeefc/:37:1","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"SQL 注入 SQL 注入（SQL Injection） 是指针对 Web 应用使用的数据库，通过运行非法的 SQL 而产生的攻击。 SQL 注入攻击有可能会造成以下等影响： 非法查看或篡改数据库内的数据； 规避认证； 执行和数据库服务器业务关联的程序等。 ","date":"2020-11-22","objectID":"/posts/eeefc/:37:2","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"OS 命令注入 OS 命令注入攻击（OS Command Injection） 是指通过 Web 应用，执行非法的操作系统命令达到攻击的目的。 OS 命令注入攻击可以向 Shell 发送命令，让 Windows 或 Linux 操作系统的命令行启动程序。也就是说，通过 OS 注入攻击可执行 OS 上安装着的各种程序。 ","date":"2020-11-22","objectID":"/posts/eeefc/:37:3","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"HTTP 首部注入 HTTP 首部注入攻击（HTTP Header Injection） 是指攻击者通过在响应首部字段内插入换行，添加任意响应首部或主体的一种攻击。属于被动攻击模式。 HTTP 首部注入攻击有可能会造成以下一些影响： 设置任何 Cookie 信息； 重定向至任意 URL； 显示任意的主体（HTTP 响应截断攻击）。 向首部主体内添加内容的攻击称为 HTTP 响应截断攻击（HTTP Response Splitting Attack）。 HTTP 响应截断攻击是用在 HTTP 首部注入的一种攻击。攻击顺序相同，但是要将两个 %0D%0A% 并排插入字符串后发送（%0D%0A代表 HTTP 报文中的换行符）。利用这两个连续的换行就可作出 HTTP 首部与主体分隔所需的空行了，这样就能显示伪造的主体，达到攻击目的。 另外，滥用 HTTP/1.1 中汇集多响应返回功能，会导致缓存服务器对任意内容进行缓存操作。这种攻击称为缓存污染。使用该缓存服务器的用户，在浏览遭受攻击的网站时，会不断地浏览被替换掉的 Web 网页。 ","date":"2020-11-22","objectID":"/posts/eeefc/:37:4","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"邮件首部注入 邮件首部注入（Mail Header Injection） 是指 Web 应用中的邮件发送功能，攻击者通过向邮件首部 To 或 Subject 内任意添加非法内容发起的攻击。利用存在安全漏洞的 Web 网站，可对任意邮件地址发送广告邮件或病毒邮件。 ","date":"2020-11-22","objectID":"/posts/eeefc/:37:5","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"目录遍历 目录遍历（Directory Traversal）攻击 是指对本无意公开的文件目录，通过非法截断其目录路径后，达成访问目的的一种攻击。这种攻击有时也称为 路径遍历（Path Traversal） 攻击。因此服务器上任意的文件或文件目录皆有可能被访问到。这样一来，就有可能非法浏览、篡改或删除 Web 服务器上的文件。 ","date":"2020-11-22","objectID":"/posts/eeefc/:37:6","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"因设置或设计上的缺陷引发的安全漏洞 ","date":"2020-11-22","objectID":"/posts/eeefc/:38:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"强制浏览 强制浏览（Forced Browsing） 安全漏洞是指，从安置在 Web 服务器的公开目录下的文件中，浏览那些原本非自愿公开的文件。 会造成的影响有： 泄露顾客的个人信息等重要情报； 泄露原本需要具有访问权限的用户才可查阅的信息内容； 泄露未外连到外界的文件； 容易产生的漏洞地方： 文件目录一览； 容易被推测的文件名及目录名； 备份文件； 经认证才可显示的文件； ","date":"2020-11-22","objectID":"/posts/eeefc/:38:1","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"不正确的错误消息处理 不正确的错误消息处理（Error Handling Vulnerability） 的安全漏洞是指，Web 应用的错误信息内包含对攻击者有用的信息。主要包括： Web 应用抛出的错误消息； -数据库等系统抛出的错误消息； PHP 或 ASP 等脚本错误； 数据库或中间件的错误； Web 服务器的错误； ","date":"2020-11-22","objectID":"/posts/eeefc/:38:2","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"开放重定向 开放重定向（Open Redirect） 是一种对指定的任意 URL 作重定向跳转的功能。而与此功能相关联的安全漏洞是指，假如指定的重定向 URL 到某个具有恶意的 Web 网站，那么用户就会被诱导至那个 Web 网站。 可信度高的 Web 网站如果开放重定向功能，则很有可能被攻击者选中并用来作为钓鱼攻击的跳板。 ","date":"2020-11-22","objectID":"/posts/eeefc/:38:3","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"因会话管理疏忽引发的安全漏洞 ","date":"2020-11-22","objectID":"/posts/eeefc/:39:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"会话劫持 会话劫持（Session Hijack） 是指攻击者通过某种手段拿到了用户的会话 ID，并非法使用此会话 ID 伪装成用户，达到攻击的目的。 攻击者可获得会话 ID 的途径有： 通过非正规的生成方法推测会话 ID； 通过窃听或 XSS 攻击盗取会话 ID； 通过会话固定攻击（Session Fixation）强行获取会话 ID； ","date":"2020-11-22","objectID":"/posts/eeefc/:39:1","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"会话固定攻击 对以窃取目标会话 ID 为主动攻击手段的会话劫持而言，会话固定攻击（Session Fixation） 攻击会强制用户使用攻击者指定的会话 ID，属于被动攻击。 ","date":"2020-11-22","objectID":"/posts/eeefc/:39:2","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"跨站点请求伪造 跨站点请求伪造（Cross-Site Request Forgeries,CSRF） 攻击是指攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或设定信息等某些状态更新，属于被动攻击。 可能会造成的影响： 利用已通过认证的用户权限更新设定信息等； 利用已通过认证的用户权限购买商品； 利用已通过认证的用户权限在留言板上发表言论； ","date":"2020-11-22","objectID":"/posts/eeefc/:39:3","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"其他安全漏洞 ","date":"2020-11-22","objectID":"/posts/eeefc/:40:0","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"密码破解攻击 密码破解攻击（Password Cracking） 即算出密码，突破认证。 密码破解有以下两种手段： 通过网络的密码试错； 对已加密密码的破解（指攻击者入侵系统，已获得加密或散列处理的密码数据的情况）； 通过网络的密码试错的方法主要有： 穷举法（Brute-force Attack，又称暴力破解法）是指对所有密钥集合构成的密钥空间（Keyspace）进行穷举。 字典攻击是指利用事先收集好的候选密码（经过各种组合方式后存入字典），枚举字典中的密码，尝试通过认证的一种攻击手法。 对已加密密码的破解的方法主要有： 通过穷举法和字典攻击进行类推； 彩虹表； 拿到密钥； 加密算法的漏洞； 彩虹表（Rainbow Table）是由明文密码及与之对应的散列值构成的一张数据库表，是一种通过事先制作庞大的彩虹表，可在穷举法·字典攻击等实际破解过程中缩短消耗时间的技巧。 ","date":"2020-11-22","objectID":"/posts/eeefc/:40:1","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"点击劫持 点击劫持（Click jacking）是指利用透明的按钮或链接做成陷阱，覆盖在 Web 页面之上。然后诱使用户在不知情的情况下，点击那个链接访问内容的一种攻击手段。这种行为又称为界面伪装（UI Redressing）。 ","date":"2020-11-22","objectID":"/posts/eeefc/:40:2","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"DoS 攻击 DoS 攻击（Denial of Service attack） 是一种让运行中的服务呈停止状态的攻击。有时也叫做服务停止攻击或拒绝服务攻击。DoS 攻击的对象不仅限于 Web 网站，还包括网络设备及服务器等。 攻击方式主要有： 集中利用访问请求造成资源过载，资源用尽的同时，实际上服务也就呈停止状态。 通过攻击安全漏洞使服务停止。 多台计算机发起的 DoS 攻击称为 DDoS 攻击（Distributed Denial of Service attack）。 ","date":"2020-11-22","objectID":"/posts/eeefc/:40:3","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Web 开发"],"content":"后门程序 后门程序（Backdoor） 是指开发设置的隐藏入口，可不按正常步骤使用受限功能。 ","date":"2020-11-22","objectID":"/posts/eeefc/:40:4","tags":[],"title":"《图解HTTP》笔记","uri":"/posts/eeefc/"},{"categories":["Python"],"content":"不用 Python 的 base64 标准库，如何自己实现一个 Base64 编码函数？ 什么是 Base64 Base64 是一种使用 64 个可打印字符来表示任意二进制数据的编码方法。常用在一些通常处理文本数据的场合，表示、传输、存储一些二进制数据，例如： 在电子邮件中嵌入多媒体内容或者附件； 在 HTML 中嵌入图片； 完整的 Base64 定义可见 RFC 1421 和 RFC 2045。需要注意的是，Base64 是一种编码方法，而不是加密方法。 Base64 使用的 64 个可打印字符为 ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/，分别代表 0~63 的所有数值。 Base64 原理 由于 $2^6=64$，因此每 6 bits 数据可以用 1 个 Base64 的单元表示，即 3 Byte 的数据（24 bits）可以用 4 个 Base 64 的单元表示，即 3 个字节可以用 4 个可打印字符表示。可以看出，Base64 的代价是编码后数据长度增加了。 Base64 规定，编码时每 3 个字节为 1 组，编码为 4 个可打印字符。若要编码的二进制数据字节数不是 3 的整数倍，最后会剩下 1 个或 2 个字节，需要使用 \\x00 补齐到 3 个字节，再进行 Base64 的编码。在编码后的Base64文本后加上一个或两个 = 号，代表补足的字节数。具体来说： 当二进制数据剩下 1 个字节，需要补 2 个字节，我们用 x 表示原数据的 bit，这三个字节可以表示为 xxxxxxxx0000000000000000，Base64 编码时，拆分为 xxxxxx、xx0000、000000 和 000000，可见前 2 个 Base64 字符含有原始数据，此时就把最后两个不含有原始数据的 Base64 字符替换为 =，即编码后的数据中会有 2 个 =，也代表了补足的字节数为 2。 当二进制数据剩下 2 个字节，需要补 1 个字节，我们用 x 表示原数据的 bit，这三个字节可以表示为 xxxxxxxxxxxxxxxx00000000，Base64 编码时，拆分为 xxxxxx、xxxxxx、xxxx00 和 000000，可见前 3 个 Base64 字符含有原始数据，此时就把最后一个不含有原始数据的 Base64 字符替换为 =，即编码后的数据中会有 1 个 =，也代表了补足的字节数为 1。 用 Python 实现 Base64 编码函数 chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/' def base64_encode(binary_data: bytes): # 二进制数据字节数不是 3 的倍数时，使用 \\x00 填充 padding_count = 3 - len(binary_data) % 3 if padding_count == 3: padding_count = 0 encode_data = binary_data + b'\\x00' * padding_count result = '' # 每次取出 3 个字节进行编码 for index in range(0, len(encode_data), 3): piece = encode_data[index:index+3] # 将字节数据转换为二进制 bit 数据 binary_string = bin(int.from_bytes(piece, 'big'))[2:].zfill(24) # 每次取出 6 个 bit for i in range(0, 24, 6): result += chars[int(binary_string[i:i+6], base=2)] # 若使用了 \\x00 填充过编码前数据，使用等数量的 = 填充编码后数据 if padding_count: result = result[:-padding_count] + '=' * padding_count # 输出的格式为 ascii 编码的 bytes return result.encode('ascii') 参考链接 Base64 - 维基百科，自由的百科全书 base64 - 廖雪峰的官方网站 ","date":"2020-11-20","objectID":"/posts/0b6b7/:0:0","tags":[],"title":"使用Python自己实现Base64","uri":"/posts/0b6b7/"},{"categories":["Python"],"content":"我们经常会在日历中看到本周是今年的第几周，这是如何定义的？又如何用 Python 来计算呢？ 日历星期的定义 国标《GB/T 7408-2005》和 ISO 标准《ISO 8601-2004》中关于日历周的定义是一致的。主要包括： ","date":"2020-11-12","objectID":"/posts/0bf3d/:0:0","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"参考点 日历星期的参考点为，把 2000 年 1 月 1 日定为星期六。 ","date":"2020-11-12","objectID":"/posts/0bf3d/:1:0","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"weekdays 编号 日历星期从星期一开始，编号为 01；至星期日结束，编号为 07。 ","date":"2020-11-12","objectID":"/posts/0bf3d/:2:0","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"日历星期数 日历年中的日历星期由日历星期数标识。 一年中的第一个日历星期包括该年的第一个星期四，且日历年中的最后一个日历星期就是下一个日历年的第一个日历星期之前的星期。日历星期数是其在该年中的顺序。 一个日历年中有52或53个日历星期。 注意⚠️：也可以这样判断——一年中的第一个日历星期是包含 1 月 4 日的那个星期。 Python模块 在 Python 中处理日历星期的标准库模块有 datetime 和 calendar。 ","date":"2020-11-12","objectID":"/posts/0bf3d/:3:0","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"datetime import datetime # 东八区，中国标准时 timezone_cst = datetime.timezone(offset=datetime.timedelta(hours=8)) new_year = datetime.date(2000, 1, 1) now = datetime.datetime.now(tz=timezone_cst) # 2020-11-12 ","date":"2020-11-12","objectID":"/posts/0bf3d/:4:0","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"isoweekday() isoweekday() 方法获取 weekdays 编号 new_year.isoweekday() # 6 now.isoweekday() # 4 ","date":"2020-11-12","objectID":"/posts/0bf3d/:4:1","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"isocalendar() isocalendar() 方法返回三元组，(ISO year, ISO week number, ISO weekday) new_year.isocalendar() # (1999, 52, 6) 由于 2020-1-1 是周六，它的下一个周才包含周四，因此 2020-1-1 属于 1999 年的第 52 周。 now.isocalendar() # (2020, 46, 4) ","date":"2020-11-12","objectID":"/posts/0bf3d/:4:2","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"calendar calendar 模块中的 weekday() 函数返回的是星期日编号是0-6，而不是1-7。 import calendar calendar.weekday(2000, 1, 1) # 5 示例 ","date":"2020-11-12","objectID":"/posts/0bf3d/:5:0","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"计算给定时间所在星期的起止时间 计算给定时间的 weekdays 编号； 根据 weekdays 编号计算星期一的日期，进而计算得到起始时间； 根据起始时间计算终止时间； datetime.datetime.combine(date, time)可以将date对象和time对象合并为一个datetime对象。如果date对象参数传入了datetime类型对象，该对象的时间部分和时区部分将会被忽略。 import datetime def get_week_by_time(given_time): weekday_num = given_time.isoweekday() # combine(星期一的日期, 零时, 给定时间的时区) week_start = datetime.datetime.combine( given_time - datetime.timedelta(days=weekday_num-1), datetime.time(), tzinfo=given_time.tzinfo ) week_end = week_start + datetime.timedelta(weeks=1) return week_start, week_end timezone_cst = datetime.timezone(offset=datetime.timedelta(hours=8)) now = datetime.datetime.now(tz=timezone_cst) week_start, week_end = get_week_by_time(now) print(now) print(week_start) print(week_end) 输出 2020-11-12 09:13:06.840023+08:00 2020-11-09 00:00:00+08:00 2020-11-16 00:00:00+08:00 ","date":"2020-11-12","objectID":"/posts/0bf3d/:6:0","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Python"],"content":"给定年份和日历星期数，计算该星期的起止时间 根据日历星期的定义，每一年的 1 月 4 日肯定在这一年的第一个日历星期中。 计算给定年份 1 月 4 日的 weekdays 编号； 计算今年第一个日历星期的开始日期； 根据日历星期数差，计算给定日历星期数的起始日期，进而计算的到起始时间； 根据起始时间计算终止时间； import datetime def get_week_by_weeknum(year, weeknum, tzinfo=None): # 组装1月4日的日期 day_jan_4th = datetime.date(year, 1, 4) # 今年第一个日历星期的开始日期 first_week_start = day_jan_4th - datetime.timedelta(days=day_jan_4th.isoweekday()-1) # 所求星期的开始时间 week_start = datetime.datetime.combine( first_week_start + datetime.timedelta(weeks=weeknum-1), datetime.time(), tzinfo=tzinfo, ) week_end = week_start + datetime.timedelta(weeks=1) return week_start, week_end timezone_cst = datetime.timezone(offset=datetime.timedelta(hours=8)) week_start, week_end = get_week_by_weeknum(2020, 46, tzinfo=timezone_cst) print(week_start) print(week_end) 输出 2020-11-09 00:00:00+08:00 2020-11-16 00:00:00+08:00 参考链接 国家标准 - 全国标准信息公共服务平台 ISO 8601 - 维基百科，自由的百科全书 ","date":"2020-11-12","objectID":"/posts/0bf3d/:7:0","tags":[],"title":"Python计算日历星期","uri":"/posts/0bf3d/"},{"categories":["Web 开发"],"content":"Web 应用程序中经常会有导出文件报表的需求，csv 格式结构简单，Python 无需安装第三方库，标准库即可生成 csv 文件，是导出报表的不二首选。然而，如果没有设置好 csv 文件的编码，在 Microsoft Excel 中打开时，可能是一片乱码。 乱码的原因 Python 的默认文件编码为 UTF-8，因此不特别设定的话，生成的 csv 文件也是 UTF-8 编码。 根据参考链接中文章的描述推测（存疑，在 Office 2207 SP2 更新日志中未找到 csv 相关更新内容）： Office 2007 版本和 Office 2007 SP1 版本，打开 csv 文件时的默认编码为 ANSI，对应中文即是 GBK 编码； Office 2003、Office 2007 SP2 以及更新的版本，打开 csv 文件时的默认编码还支持带 BOM 头的 UTF-8； 而 Python 语言（或者说大多数编程语言）默认的 UTF-8 是不带 BOM 头的，因此不管用什么版本的 Microsoft Office 打开都会乱码。 解决方案 其实在 Office Excel 中，可以选择在数据菜单中“从文件导入”的方式读取 csv，该过程中可以指定 csv 文件的编码，就不会乱码了。 但是作为一个 Web 开发者，为了提高用户体验，还是希望用户能够直接打开 csv 文件而不乱码。我们可以通过在生成 csv 文件时，指定 csv 文件编码实现： 若需要兼容 Office 2007 和 Office 2007 SP1，使用 GBK 编码（Python 中该编码为gbk），但是仅限于中英文内容，其他语言 GBK 可能无法编码或乱码； 若不需要兼容 Office 2007 和 Office 2007 SP1，使用带 BOM 头的 UTF-8 编码（Python 中该编码为utf-8-sig），对多语言的支持更加友好； 需要特别注意的是，一般业务中可能没有其他外文语言，但会有 emoji 表情。这些 emoji 表情是无法用 GBK 编码的，注意做好容错。举个 Python 的例子，使用 ? 代替无法编码的字符： str.encode('gbk', errors='replace') 参考链接 Windows Office打开.csv文件为乱码问题的说明与解决_快乐很伟大-CSDN博客 用Excel 2007打开含有utf-8编码的csv文件，中文显示为乱码。请问怎样解决些高题？ - Microsoft Community ","date":"2020-11-12","objectID":"/posts/bbe08/:0:0","tags":[],"title":"解决csv中文乱码","uri":"/posts/bbe08/"},{"categories":["Infrastructure"],"content":"supervisor 是用 Python 语言实现的一个进程持久化管理工具，可以通过 pip 安装，或某些发行版的包管理器安装。但是在 CentOS 上，能直接 yum install 安装吗？事情并没有这么简单。 网上大部分教程，都告诉你直接在 CentOS8 上运行 yum install supervisor 命令。但是会提示找不到这个包。 正确的做法是，先安装 EPEL： yum install epel-release EPEL 是 Extra Packages for Enterprise Linux 的缩写，EPEL 是由 Fedora 特殊兴趣小组创建、维护和管理的高质量企业 Linux 附加软件包集。我们需要的 supervisor 就在其中。 上述命令执行成功后，再安装 supervisor： yum install supervisor 值得注意的是，CentOS 上 supervisor 与 Ubuntu 上稍有不同： 被管理进程的日志，默认在 /tmp 目录下，Ubuntu 上是 /var/log/supervisor； 被管理进程的配置文件，默认读取 /etc/supervisord.d/*.ini，Ubuntu 上是 /etc/supervisor/conf.d/*.conf。 参考链接 EPEL - Fedora Project Wiki ","date":"2020-09-27","objectID":"/posts/fcac4/:0:0","tags":[],"title":"在CentOS上安装supervisor","uri":"/posts/fcac4/"},{"categories":["工欲善其事"],"content":"Bitwarden 是一个开源的密码管理器解决方案，拥有多个平台的客户端。它采用的方式是云端数据库、客户端同步和离线使用的模式，类似现在的 1password。其优势在于： 官方许可私有化部署； 代码开源，安全性高； 拥有完善的多平台客户端支持，包括 Linux、Android、主流浏览器都覆盖； 支持保存 TOTP 密钥； 本文记录如何在 Linux 上部署 bitwarden_rs。 安装 docker 参考 docker 官方文档。 安装 bitwarden_rs bitwarden_rs 并不是 bitwarden 的官方项目，而是从官方项目中衍生的第三方实现。bitwarden 的 server 项目使用 .NET 语言和 MSSQL 数据库，生成的 docker 镜像体积较大，第三方作者于是用 rust 重写，并使用 sqlite 数据库，并实现了官方的一些付费功能，该 docker 镜像体积较小，方便部署。 拉取 docker 镜像： docker pull bitwardenrs/server:latest 新建数据目录： mkdir bitwarden-data 新建环境变量配置文件。 DOMAIN=your_domain SIGNUPS_ALLOWED=false WEB_VAULT_ENABLED=true INVITATIONS_ALLOWED=false WEBSOCKET_ENABLED=true ROCKET_WORKERS=20 SHOW_PASSWORD_HINT=false LOG_FILE=/data/bitwarden.log IP_HEADER=X-Real-IP TZ=Asia/Shanghai 注意第一次运行时，先把 SIGNUPS_ALLOWED 设置为 true，并修改 DOMAIN，以方便创建用户和导入密码库。 启动 docker 容器 export BITWARDEN_DATA=/root/bitwarden-data/ docker run -d \\ -v $BITWARDEN_DATA:/data/ \\ -p 127.0.0.1:10001:80 \\ -p 127.0.0.1:10002:3012 \\ --env-file=$BITWARDEN_DATA/bitwarden.env \\ --name=bitwarden \\ --restart=always \\ bitwardenrs/server 配置 nginx 作为一个密码管理器服务，为了安全必须开启 HTTPS。关于 HTTPS 的配置请参考项目 mrchi/secure-nginx。 这里只展示为 Bitwarden 设置的请求转发规则 # reverse proxy location / { proxy_pass http://127.0.0.1:10001; include nginxconfig.io/proxy.conf; } # notification location /notifications/hub { proxy_pass http://127.0.0.1:10002; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } # notification location /notifications/hub/negotiate { proxy_pass http://127.0.0.1:10001; include nginxconfig.io/proxy.conf; } 配置 fail2ban fail2ban 是一个通过监视应用日志并进行正则表达式匹配，将多次登录失败的 IP 通过设置 iptables 进行封禁的工具。给 Bitwarden 设置 fail2ban 可以一定程度上防止主密码遭受暴力破解。 安装 apt install fail2ban 在设置前，检查 docker 容器的 TZ 环境变量和 IP_HEADER 环境变量设置正确。前者影响日志的时间，后者影响日志中记录的真实访问 IP。 首先创建一个过滤器，在 /etc/fail2ban/filter.d 目录新增文件 bitwarden.local，写入以下内容 [INCLUDES] before = common.conf [Definition] failregex = ^.*Username or password is incorrect\\. Try again\\. IP: \u003cADDR\u003e\\. Username:.*$ ignoreregex = 然后创建一个 jail，在 /etc/fail2ban/jail.d 目录新增文件 bitwarden.local，写入以下内容 [bitwarden] enabled = true port = 80,443 name = bitwarden filter = bitwarden banaction = iptables-multiport logpath = /root/bitwarden-data/bitwarden.log maxretry = 3 bantime = 14400 findtime = 14400 假如你对外监听的端口不是 80 和 443，那么要修改成实际使用的端口，否则 fail2ban 会设置成错误的 iptables，无法禁止 IP 对实际端口的访问。 修改完成后，重启 fail2ban systemctl restart fail2ban 此时即可故意输入错误的密码，查看 jail 状态中的记录数是否增加 fail2ban-client status bitwarden 输错达到 3 次后，当前 IP 应该就不能再访问服务器的 80 和 443 端口。解封 IP fail2ban-client set bitwarden unbanip XX.XX.XX.XX 备份 Bitwarden 的模式决定了服务器端的数据永远是最新的，虽然 iOS 和 Android 的客户端支持导出数据，但客户端不会在后台自动同步密码库。若长时间未打开，密码库将不会是最新版本。 此时对服务器数据进行备份就显得尤为重要。服务器端数据是加密的，没有主密码很难解开（话不能说的太绝对）。我们可以定时将将容器挂载目录打包，上传到网络存储。 这里以通过 webdav 上传到坚果云为例。 到 /etc/cron.daily 目录下新建文件 bitwarden-backup，写入以下内容 #!/bin/sh set -e filename=\"bitwarden-`date +%F`.tar.gz\" cd /root tar czf \"${filename}\" bitwarden-data/ curl -u \"USERNAME:APP_PASSWD\" -T \"${filename}\" \"https://dav.jianguoyun.com/dav/bitwarden/\" rm \"${filename}\" 增加可执行权限 chmod a+x bitwarden-backup 参考链接 Open Source Password Manager for Individuals and Teams | Bitwarden dani-garcia/bitwarden_rs: Unofficial Bitwarden compatible server written in Rust Configuration overview · dani-garcia/bitwarden_rs Wiki mrchi/secure-nginx: A secure Nginx configuration example for HTTPS website, generated by https://nginxconfig.io/. ","date":"2020-06-13","objectID":"/posts/88980/:0:0","tags":[],"title":"自己部署Bitwarden服务","uri":"/posts/88980/"},{"categories":["极客有力量"],"content":"树莓派 zero w 是一个非常小巧的树莓派型号，既没有以太网口，也没有 USB-A 口，只有 micro USB 接口 和 Mini HDMI。若没有各种转接线，想要连接树莓派只能靠 配置无线网络。但是，假如需要使用 zero w 的无线网卡做一些嗅探抓包之类的功能，就不太方便了。 Ethernet Gadget 可以使树莓派的 USB 接口成为一个以太网设备，只需要一根 micro USB 的数据线就可以连接电脑，从而 SSH 登录、通过电脑的网络上网。 注意：以下的方法只在 Raspberrypi OS(Raspbian) 下完全有效，其他的基于 Debian 的系统或多或少都有些问题。 开启 USB ethernet gadget 开启该功能需要修改启动参数。将刻录好系统的 SD 卡连接电脑，有两个分区，找到 boot 分区。 编辑 config.txt 在末尾添加 dtoverlay=dwc2 编辑 cmdline.txt，在 rootwait 后添加一个空格，然后添加 modules-load=dwc2,g_ether 创建一个名为 ssh 的空文件，开启树莓派的 sshd 服务 touch ssh 设置固定的 MAC 地址 默认情况下，每次启动树莓派都会生成一个随机的 MAC 地址，而 Ubuntu 的 Network Manager 根据 Mac 地址生成配置文件。这就造成了每次启动时 Ubuntu 都会生成新的配置文件并要修改配置。设置固定的 MAC 地址可以避免这种情况。 将刻录好系统的 SD 卡连接电脑，找到 rootfs 分区，修改文件 etc/modprobe.d/g_ether.conf，写入以下内容 options g_ether host_addr=00:22:44:66:88:f0 dev_addr=00:22:44:66:88:f1 MAC 地址可以随意定义，只要不和已有设备的 MAC 地址冲突。 设置静态 IP 设置静态 IP 可以在网络连接后，方便地从电脑上 SSH 登录到树莓派。由于我们要通过电脑共享网络给树莓派，而 Ubuntu 16.04 中共享网络时，电脑的 IP 固定为 10.42.0.1，因此我们给树莓派设置 IP 为 10.42.0.2。 同样找到 rootfs 分区，修改文件 etc/network/interfaces，添加以下内容 allow-hotplug usb0 iface usb0 inet static address 10.42.0.2 netmask 255.255.255.0 gateway 10.42.0.1 dns-nameservers 10.42.0.1 电脑端配置 以 Ubuntu 16.04 为例，将树莓派通过 micro USB 接入电脑，树莓派启动后，Ubuntu 会自动生成一个网络配置文件，在网络设置中打开该配置文件，将 IPV4 设置中的方法改为 “与其他计算机共享” 即可。 稍等片刻网络设置好后，就可以通过 10.42.0.2 登录树莓派了。 参考链接 Raspberry Pi Console over USB: Configuring an Ethernet Gadget (Shallow Thoughts) Ethernet Gadget | Turning your Raspberry Pi Zero into a USB Gadget | Adafruit Learning System udev for stable MAC address: Raspberry Pi Zero gadget mode - Raspberry Pi Forums ","date":"2020-06-11","objectID":"/posts/edd5c/:0:0","tags":[],"title":"树莓派zero的USB ethernet gadget配置","uri":"/posts/edd5c/"},{"categories":["极客有力量"],"content":"Home Assistant（简称 HA）是一个开源的智能家居平台，可以运行在树莓派或者服务器上。目前已经能够接入许多品牌的智能设备，包括米家和 Yeelight。同时，还支持 Apple HomeKit、Google Assistant 和 Amazon Alexa 等智能家居控制平台。通过 Home Assistant，不需要米家网关，也能方便地使用 Siri 控制米家的智能设备。 准备 软件方面，目前 HA 有多种安装方式（如下），这里选用的 Raspbian 安装方式）。 Hass.io，它基于 Docker 和 HassOS，只支持树莓派，通过树莓派镜像的方式直接安装。安装简单，但断电兼容性不好，一次断电就会导致服务挂掉。 在 Raspbian 上安装。安装步骤较多，安装完成后没有 hassio add-on 功能，但稳定。 硬件方面，考虑到不需要太多 GPIO 的功能，我选用了树莓派 Zero W，自带 WiFi 和蓝牙。但是其性能可怕，跑 apt 和 pip 时 CPU 会直接 100%。 安装 ","date":"2020-06-08","objectID":"/posts/dbf6a/:0:0","tags":[],"title":"Home Assistant-开源智能家居系统","uri":"/posts/dbf6a/"},{"categories":["极客有力量"],"content":"Hass.io 安装 去官网下载对应硬件的 Hass.io 镜像，刻录到 SD 卡。 网络配置参考 HassOS howto 文档，按照文档描述，需要外接 U 盘。这里提供一种不需要 USB 外接设备的配置方式。 刻录好的树莓派镜像 SD 卡上有四个 ext 分区（Mac 不支持 ext 分区格式，需要安装软件或在 Ubuntu 上操作），在名称为 hassos-overlay 的分区中，新建目录： sudo mkdir -p etc/NetworkManager/system-connections 创建 my-network 文件，按照参考文档写入配置： sudo vi my-network [connection] id=my-wireless uuid=82b0ccd9-f0a0-4ca8-aa73-6a595d847a58 type=802-11-wireless [802-11-wireless] mode=infrastructure ssid=YOUR-SSID # Uncomment below if your SSID is not broadcasted #hidden=true [802-11-wireless-security] auth-alg=open key-mgmt=wpa-psk psk=YOUR-PASSWORD [ipv4] method=auto [ipv6] addr-gen-mode=stable-privacy method=auto 需要注意的是： id 任意取，uuid 用 Python3 的 uuid.uuid4 生成； 设置无线网络时，key-mgmt 无线网加密类型，对于 “WPA-PSK”、“WPA2-PSK” 和 “mixed WPA/WPA2 PSK” 类型，这个值都是 wpa-psk。 最后，修改文件权限为 600。 sudo chmod 600 my-network unmount SD 卡，插入树莓派启动即可。启动后，在路由器上能看到设备连接，但要等一段时间才能访问 web 界面 http://hassio.local:8123（如果路由器不支持 mDNS 就通过 ip 访问，下同）。 ","date":"2020-06-08","objectID":"/posts/dbf6a/:1:0","tags":[],"title":"Home Assistant-开源智能家居系统","uri":"/posts/dbf6a/"},{"categories":["极客有力量"],"content":"在 Raspbian 上安装 首先去树莓派官网下载最新的 Raspbian Lite 系统镜像，刻录后并进行必要的设置。 安装必要包 sudo apt update \u0026\u0026 sudo apt upgrade sudo apt install build-essential libssl-dev libffi-dev sudo apt install python3 python3-dev python3-pip python3-venv （optional）将当前用户添加到 dialout 和 gpio 用户组中，第一个用户组用于访问 Z-Wave 和 Zigbee 控制器，第二个用户组用户访问 GPIO。 sudo usermod -aG dialout,gpio pi 创建虚拟环境 cd ~ mkdir homeassistant cd homeassistant python3 -m venv . 激活虚拟环境并安装 Home Assistant source bin/activate python3 -m pip install wheel pip3 install homeassistant 在虚拟环境中启动 Home Assistant hass 首次启动后，将会在 ~/.homeassistant 目录中创建配置文件，并下载安装必要库和依赖项，可能需要 5～10分钟。完成后即可通过 8123 端口访问 web 界面。 配置 主要包括 **（仅支持 Hass.io）**添加两个 add-on：Configurator 和 SSH server； 配置时区； 添加 add-on 在 web 界面 [Hass.io] - [ADD-ON STORE] 中。 ","date":"2020-06-08","objectID":"/posts/dbf6a/:2:0","tags":[],"title":"Home Assistant-开源智能家居系统","uri":"/posts/dbf6a/"},{"categories":["极客有力量"],"content":"Configurator add-on 这个扩展提供了一个 web 编辑器，从而能够在 web 界面编辑 Home Assistant 的配置。 打开上述菜单安装该 add-on，安装完成后，进行以下配置： 设置用户名和密码； 调整 allowed_networks； 单击保存，并启用加载项。默认访问地址为 http://hassio.local:3218 打开后，编辑 /config/configuration.yaml，添加以下内容 panel_iframe:configurator:title:Configuratoricon:mdi:wrenchurl:http://hassio.local:3218 panel_iframe 能够把 Configurator 集成到 8123 端口的 web 界面中。编辑完成后，在 8123 端口的 web 界面中，选择 配置 - 通用 - 服务管理，选择重启服务使配置生效。 ","date":"2020-06-08","objectID":"/posts/dbf6a/:3:0","tags":[],"title":"Home Assistant-开源智能家居系统","uri":"/posts/dbf6a/"},{"categories":["极客有力量"],"content":"SSH server add-on 这个扩展提供通过 SSH 访问 hass.io。 打开上述菜单安装该 add-on，安装完成后： 添加公钥，密码留空； 修改默认端口到 3154； 单击保存，并启用加载项，稍等片刻后，即可通过 SSH 访问。 ","date":"2020-06-08","objectID":"/posts/dbf6a/:4:0","tags":[],"title":"Home Assistant-开源智能家居系统","uri":"/posts/dbf6a/"},{"categories":["极客有力量"],"content":"修改时区 在 configuration.yaml 文件中修改 homeassistant 的配置，修改 time_zone 为 Asia/Shanghai。修改完成后重启 HASS。 其他配置如经纬度、海拔高度等用来推测日出日落时间，以下是武汉市的配置。 homeassistant:# Name of the location where Home Assistant is runningname:Home# Location required to calculate the time the sun rises and setslatitude:30.583333longitude:114.316667# Impacts weather/sunrise data (altitude above sea level in meters)elevation:121# metric for Metric, imperial for Imperialunit_system:metric# Pick yours from here: http://en.wikipedia.org/wiki/List_of_tz_database_time_zonestime_zone:Asia/Shanghai 注意：要使 add-on 也使用该时区，需要重启 add-on。 连接 HomeKit 连接 HomeKit 后，HA 作为网桥联通 HomeKit 和智能硬件。HA 已经内置了对 HomeKit 的支持，只需要在 configuration.yaml 中增加记录，然后重启 HASS。 homekit:include_domains:- light 重启完成后，在概览中会出现 HomeKit 卡片，显示用于连接的代码。在家庭 App 中输入代码添加配件即可。 连接智能设备 注意事项： 使用 Zigbee 网络智能设备需要树莓派外接 Zigbee 收发器； 使用 WiFi 控制的智能设备建议在路由器中为设备设置静态 IP； ","date":"2020-06-08","objectID":"/posts/dbf6a/:5:0","tags":[],"title":"Home Assistant-开源智能家居系统","uri":"/posts/dbf6a/"},{"categories":["极客有力量"],"content":"Yeelight Bulb Yeelight 灯具使用 WiFi 控制，连接 HA 前需要在 Yeelight App 中打开灯具的局域网控制功能（参考局域网控制 Yeelight）。 打开该功能并且灯具成功接入 WiFi 后，在 configuration.yaml 文件中添加配置，name 更多详细参数可以参考官方文档。 light:- platform:yeelightdevices:192.168.1.25:name:LivingRoom 添加配置后重启 HASS，灯具将会在概览中出现。如果在上一步中配置好了 HomeKit，那么在家庭 App 中已经出现了该灯具，可以使用 Siri 控制。 参考链接 Home Assistant Xiaomi Smart Home Ecosystem - Google Sheets Configure Home Assistant - Home Assistant HomeKit - Home Assistant Yeelight Wifi Bulb - Home Assistant Home Assistant + 树莓派：强大的智能家居系统 · 小米篇 - 少数派 Panel iFrame - Home Assistant nm-settings: NetworkManager Reference Manual HASS Configurator - Home Assistant Manual installation on a Raspberry Pi - Home Assistant ","date":"2020-06-08","objectID":"/posts/dbf6a/:6:0","tags":[],"title":"Home Assistant-开源智能家居系统","uri":"/posts/dbf6a/"},{"categories":["极客有力量"],"content":"安装PL2303驱动 下载官方驱动：PL2303 Mac OS X Driver Download 安装驱动，安装完成后重启电脑； 检测安装成功： 插上USB转串口模块，打开终端执行以下命令 ls /dev/tty.usb*，出现 /dev/tty.usbserial 则说明安装成功。 另外在系统信息中能看到相关信息：硬件－USB－USB 3.0总线－USB-Serial Controller。 在“网络偏好设置“设置里多了一项USB-SerialController。 连接树莓派和USB转串口模块 测试发现可以使用串口模块给树莓派供电，在不接风扇的情况下。树莓派外侧引脚，从边缘数起第2、3、4、5引脚分别是VCC(5v)、GND、TX、RX。按照引脚图与树莓派连接即可。 调试 连接好硬件之后，在终端中输入命令 screen /dev/tty.usbserial 115200 就会出现树莓派的登录界面（如果开机完成的话～）。 断开连接时，不能关闭终端窗口后直接把串口模块拔出，会造成系统重启。终端退出的时候不会自动断开与树莓派的连接。需要执行：ps -x|grep tty，得到串口连接的进程号，然后：kill 进程号。 如果只是不小心给关了，需要再次连接，同样需要kill一下，然后再screen进行连接，否则也可能会出现could not find PTY的错误提示。 FAQ ","date":"2020-06-08","objectID":"/posts/32e91/:0:0","tags":[],"title":"在Mac上使用USB转串口调试树莓派","uri":"/posts/32e91/"},{"categories":["极客有力量"],"content":"如何卸载PL2303驱动？ 首先，需要在终端中执行以下命令： sudo rm –rf /Library/Extensions/ProlificUSBSerial.kext sudo rm –rf /var/db/receipts/*PL2303*.* 然后在“网络偏好设置“设置中删除USB-SerialController。 最后重启电脑。 ","date":"2020-06-08","objectID":"/posts/32e91/:1:0","tags":[],"title":"在Mac上使用USB转串口调试树莓派","uri":"/posts/32e91/"},{"categories":["极客有力量"],"content":"screen命令不存在？ 在终端中执行下列语句来安装screen命令： brew install screen ","date":"2020-06-08","objectID":"/posts/32e91/:2:0","tags":[],"title":"在Mac上使用USB转串口调试树莓派","uri":"/posts/32e91/"},{"categories":["极客有力量"],"content":"HAP-NodeJS是国外大神逆向了Apple的HomeKit Application Protocol协议后（HomeKit开发不对个人开发者开放），使用node.js实现的HomeKit Accessory Server，在树莓派上安装后，能够以树莓派作为Bridge，将自定义的设备接入Apple HomeKit，进而使用Siri控制设备，无需MFi认证。 使用pi用户登录， 安装依赖： sudo apt-get update sudo apt-get install git-core libnss-mdns libavahi-compat-libdnssd-dev -y 安装node.js和npm： sudo wget http://node-arm.herokuapp.com/node_latest_armhf.deb sudo dpkg -i node_latest_armhf.deb node -v npm -v 从npm安装必要的node.js模块： npm install -g node-gyp 下载HAP-NodeJS并运行： git clone https://github.com/KhaosT/HAP-NodeJS.git cd HAP-NodeJS npm install node-persist debug mdns fast-srp-hap ed25519 buffer-shims curve25519-n2 ip python-shell npm rebuild node Core.js 使iPhone或iPad与树莓派在同一局域网内，打开“家庭”App，添加配件，就能看到在accessories目录下创建的所有设备，默认设置代码为031-45-154，手动输入后配件即添加到HomeKit中，可以尝试用Siri进行控制。 参考： Install HAP-NodeJS on a Raspberry Pi 极客DIY：如何用Siri与树莓派“交互” - FreeBuf.COM | 关注黑客与极客 ","date":"2020-06-08","objectID":"/posts/e9313/:0:0","tags":[],"title":"在树莓派上安装HAP-NodeJS","uri":"/posts/e9313/"},{"categories":["极客有力量"],"content":"认识 OpenWrt 来自官网的介绍 The OpenWrt Project is a Linux operating system targeting embedded devices. Instead of trying to create a single, static firmware, OpenWrt provides a fully writable filesystem with package management. This frees you from the application selection and configuration provided by the vendor and allows you to customize the device through the use of packages to suit any application. For developers, OpenWrt is the framework to build an application without having to build a complete firmware around it; for users this means the ability for full customization, to use the device in ways never envisioned. OpenWrt 与 LEDE 项目还有一段相爱相杀的历史。 2016 年 5 月，由于原 OpenWrt 开发者社区已经长时间没有关键性更新以及对新设备的支持，而关于这些的讨论也迟迟未有结果，导致一群 OpenWrt 核心贡献者感到不满，另外成立了 LEDE 项目。该项目源码基本继承自 OpenWrt，但采取了更有效的开发讨论规定和决议流程。 2017 年 6 月，LEDE 社区和 OpwnWrt 社区均同意将原 OpenWrt 项目合并至 LEDE 项目。新项目使用 Openwrt 的名称，但沿用 LEDE 社区的版规和流程规定。 2018 年 1 月，所有源代码合并完成。 2018 年 7 月 31 日，发布合并之后的第一个稳定版本 OpenWrt 18.06。 OpenWrt 的优势主要有： 可扩展性 不仅支持多种设备，还提供了许多仅在高端设备中可用的功能； 安全性 OpenWrt 的标准安装是安全的——禁用 Wi-Fi、没有弱密码或后门，另外官方会及时修复漏洞； 性能和稳定性 标准模块化，经过充分的测试和错误修复后发布。 强大的社区支持 研究 许多团队使用 OpenWrt 作为他们研究网络性能的平台，成功实验的改进将首先在 OpenWrt 中提供； 开源免费 安装 OpenWrt 根据自己的硬件在 官网支持设备列表 中选择合适的镜像下载，目前树莓派受支持的型号有 A、B、B+、2B、3B、3B+ 和 Zero W。 下载完成后将镜像刷到 SD 卡中，将树莓派通过以太网接口连接到电脑或路由器（默认情况下 Wi-Fi 是关闭的），接通电源。树莓派直连电脑时 IP 地址为 192.168.1.1。 有两种方式可以访问树莓派： 通过浏览器访问 OpenWrt 自带的 luci Web 管理界面； 通过 SSH 登录树莓派，root 用户，默认为空密码； 注意 登录 luci 的账号密码和 SSH 的账号密码其实是同一套。 基本设置 更新软件列表 opkg update 安装 luci 中文界面 opkg install luci-compat luci-i18n-base-zh-cn 在 luci 中： 设置主机密码（root 用户密码）； 添加 SSH 访问公钥； 设置时区，修改时间； 安装网络设备驱动 ","date":"2020-06-08","objectID":"/posts/71093/:0:0","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"USB 有线网卡（RTL8152） 这是一款 TPLINK 的 USB 转 RJ45 有线网卡，使用芯片 RTL8152。安装驱动： opkg install kmod-usb-net-rtl8152 ","date":"2020-06-08","objectID":"/posts/71093/:1:0","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"USB 无线网卡（RT5370） 我的无线网卡型号为 Tenda W311MI，使用 RT5370 芯片，OpenWrt 默认没有安装该无线网卡的驱动。 安装 lsusb 命令： opkg update opkg install usbutils 安装驱动组件 opkg install kmod-rt2800-lib opkg install kmod-rt2800-usb opkg install kmod-rt2x00-lib opkg install kmod-rt2x00-usb 重新配置 Wi-Fi，会在 luci 的网络菜单中出现“无线”选项 wifi config 如果没有生效，尝试重启 OpenWrt。 Tenda W311MI 能够同时工作在 AP 模式 和 Client 模式，可以用作无线中继。 ","date":"2020-06-08","objectID":"/posts/71093/:2:0","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"Android USB 网络共享（RNDIS） 安卓手机的 USB 网络共享功能使用 RNDIS 协议（Remote Network Driver Interface Specification，远程网络驱动程序接口规范）。该协议为微软公司专有协议，OpenWrt 默认情况下不支持该协议。 安装驱动 opkg update opkg install kmod-usb-net-rndis usb-modeswitch 离线安装时需要下载的包有（包括上述包的依赖包）： kmod-mii kmod-usb-net-cdc-ether kmod-usb-net-rndis kmod-usb-net libusb-1.0 usb-modeswitch Shadowsocks 透明代理 这里我们使用 Shadowsocks + ChinaDNS + DNS-Forwarder 的方案。 Shadowsocks 实现透明代理、socks5 代理和端口转发等功能； ChinaDNS 解析国内域名时自动查询本地 DNS 服务器，解析国外域名时查询国外DNS服务器，以防止 DNS 投毒，同时它维护的 IP 列表可以实现 Shadowsocks 代理的分流； DNS-Forwarder 使用 TCP 协议转发 DNS 请求，DNS 默认使用 UDP 协议，但 ISP 的 UDP 常常出现不稳定的情况，因此使用 DNS-Forwarder 提高 DNS 转发的稳定性。如果配合了 SS，TCP 查询会自动走 SS 线路，也同时解决了线路优化的问题。 ","date":"2020-06-08","objectID":"/posts/71093/:3:0","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"安装 ","date":"2020-06-08","objectID":"/posts/71093/:4:0","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"源安装 这里安装我们使用了第三方源 Openwrt-dist。 添加公钥 wget http://openwrt-dist.sourceforge.net/openwrt-dist.pub opkg-key add openwrt-dist.pub 查看 openwrt 路由器 CPU 架构，树莓派 2B 是 arm_cortex-a7_neon-vfpv4。 $ opkg print-architecture arch all 1 arch noarch 1 arch arm_cortex-a7_neon-vfpv4 10 将以下内容添加到 /etc/opkg/customfeeds.conf 文件中。 src/gz openwrt_dist http://openwrt-dist.sourceforge.net/packages/base/{architecture} src/gz openwrt_dist_luci http://openwrt-dist.sourceforge.net/packages/luci 安装 opkg update opkg install shadowsocks-libev opkg install luci-app-shadowsocks opkg install dns-forwarder opkg install luci-app-dns-forwarder opkg install ChinaDNS opkg install luci-app-chinadns ","date":"2020-06-08","objectID":"/posts/71093/:4:1","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"一键安装脚本 一键安装脚本会额外安装 ShadowVPN。 wget http://openwrt-dist.sourceforge.net/auto_install.sh chmod +x auto_install.sh ./auto_install.sh ","date":"2020-06-08","objectID":"/posts/71093/:4:2","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"配置 为了方便，我们在 LUCI 界面进行配置，首先刷新页面。 ","date":"2020-06-08","objectID":"/posts/71093/:5:0","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"配置 Shadowsocks 进入[服务]-[影梭]菜单： 在[服务器管理]菜单，添加 Shadowsocks 服务器信息； 在[访问控制]菜单，“外网区域-被忽略IP列表” 选择 “ChinaDNS 路由表”； 在[基本设置]菜单，“全局设置-自启动延时” 选择 “5 秒”，透明代理和 SOCKS5 代理的服务器设置为刚刚添加的服务器； ","date":"2020-06-08","objectID":"/posts/71093/:5:1","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"配置 DNS 转发 进入[服务]-[DNS 转发]菜单，勾选 “启用”，设置 “监听端口” 为 5300，“上游 DNS” 为 8.8.8.8。 ","date":"2020-06-08","objectID":"/posts/71093/:5:2","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"配置 ChinaDNS 进入[服务]-[ChinaDNS]菜单： 勾选 “启用”，勾选 “启用双向过滤”； 设置 “本地端口” 为 5353； 设置上游服务器地址为 114.114.114.114,127.0.0.1:5300； 127.0.0.1:5300 即 DNS 转发的监听地址。这样配置后，ChinaDNS 国内域名查询走 114.114.114.114，国外域名查询会经由 DNS 转发走 ss 到 8.8.8.8； ","date":"2020-06-08","objectID":"/posts/71093/:5:3","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"配置 DHCP/DNS 进入[网络]-[DHCP/DNS]菜单： 在[基本设置]菜单，设置 “本地服务器” 为 127.0.0.1#5353，即 ChinaDNS 的服务监听地址； 在[HOSTS 和解析文件]菜单，勾选 “忽略解析文件”； Over，保存并重启。 其他设置 ","date":"2020-06-08","objectID":"/posts/71093/:5:4","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"定时重启 Wi-Fi 使用过程中发现无线网卡偶尔会出现网络缓慢的情况，重启 Wi-Fi 后就会恢复正常。因此设置一个定时任务，每天凌晨重启 Wi-Fi。 进入[系统]-[计划任务]菜单，添加内容： 0 4 * * * wifi down \u0026\u0026 sleep 3 \u0026\u0026 wifi 如果之前定时任务为空，需要手动重启一下 cron 服务：进入[系统]-[启动项]，重启 cron。 参考链接 OpenWrt Project: Welcome to the OpenWrt Project OpenWrt Project: Table of Hardware LEDE - 维基百科，自由的百科全书 openwrt挂载usb无线网卡 - 简书 Use RNDIS USB Dongle for WAN connection [OpenWrt Wiki] OPKG 软件包管理 [OpenWrt Wiki] FISHERMAN’S BLOG: 在 OpenWrt/LEDE路由器上，安装配置 Shadowsocks 服务 OpenWrt-dist by aa65535 ","date":"2020-06-08","objectID":"/posts/71093/:6:0","tags":[],"title":"在树莓派上安装OpenWrt","uri":"/posts/71093/"},{"categories":["极客有力量"],"content":"闲逛看到 openwrt 支持小米路由器 4A，并且现在 4A 的二手价格十分美丽，遂决定淘一个二手小米路由器 4A 刷 openwrt，解放目前在使用的树莓派。 Serial 刷机已不可用 我淘到的小米路由器 4A 生产时间是 2019.6，固件版本为 2.18.51。一开始，我按照 openwrt 官网给出的方法——拆机连接 serial。但是发现有两个问题： serial 连接的 TX 一直是高电平，无法发送数据给路由器，也就没有办法在出现启动选项时进行选择； serial 连接时给路由器上电，路由器不能正常启动，表现在启动时路由器电源灯应为橙色，但却是低亮度的蓝色，serial 收到一个字节数据后再无数据。这样当路由器上电、电源灯变为橙色后再连接 serial，也来不及在 “Erasing SPI Flash…” 后及时断开电源； 想来是小米在这个版本的固件里已经封堵了 serial 刷机。 利用远程代码执行漏洞刷机 几经周折后，在 github 发现了 acecilia/OpenWRTInvasion 这个项目。该项目利用小米路由器固件的漏洞 CVE-2019-18370 执行 shell 开启 telnet，在 telnet 连接中刷机。亲测 2.18.51 版本固件可以利用。 首先按照项目 readme 文件所述准备好运行环境，并需要让路由器有互联网连接。运行脚本时，需要填写路由器的 IP 地址和 stok 参数。stok 参数是一个认证 token，登录路由器管理 web，在 url 中可以获取。 telnet 开启成功后，使用 telnet 登录路由器，用户名为 root，无密码。 进入 /tmp 目录，从 openwrt 官网下载最新固件（当前最新版本为 19.07.3） cd /tmp curl http://downloads.openwrt.org/releases/19.07.3/targets/ramips/mt76x8/openwrt-19.07.3-ramips-mt76x8-xiaomi_mir4a-100m-squashfs-sysupgrade.bin --output firmware.bin 为了保证不会刷成砖头，下载完成后验证文件 md5，结果应该是 3ff6d8a909cb24c6a5ccada57a894a26 md5sum firmware.bin 刷固件（非常建议操作前先备个份） mtd -r write /tmp/firmware.bin OS1 完成后重启路由器，openwrt 就刷好了。 个人体验 和树莓派相比，4A 在 openwrt 的管理后台加载数据时要慢一些。但毕竟 4A 的配置和价格摆在那，还有 5G WiFi，总体来说还是比较满意。 参考链接 git.openwrt.org Git - openwrt/openwrt.git/commit OpenWrt Project: Techdata: Xiaomi Mi Router 4A (MIR4A) 100M acecilia/OpenWRTInvasion: Root shell exploit for several Xiaomi routers CVE - CVE-2019-18370 小米路由器远程命令执行漏洞（CVE-2019-18370） - 知乎 ","date":"2020-06-08","objectID":"/posts/b0ebf/:0:0","tags":[],"title":"小米路由器4A刷openwrt","uri":"/posts/b0ebf/"},{"categories":["极客有力量"],"content":"在启动前开启SSH For headless setup, SSH can be enabled by placing a file named ssh, without any extension, onto the boot partition of the SD card. When the Pi boots, it looks for the ‘ssh’ file. If it is found, SSH is enabled, and the file is deleted. The content of the file does not matter: it could contain text, or nothing at all. 配置无线网络 ","date":"2020-06-08","objectID":"/posts/51779/:0:0","tags":[],"title":"树莓派安装Raspbian系统后的一些设置","uri":"/posts/51779/"},{"categories":["极客有力量"],"content":"在启动前配置 参考无屏幕和键盘配置树莓派WiFi和SSH 在电脑上插入SD卡，在树莓派系统的/boot分区（即能够被正常识别的分区）下新建文件wpa_supplicant.conf，树莓派启动后会自动读取该文件里的wifi配置信息。内容格式与/etc/wpa_supplicant/wpa_supplicant.conf相同。 country=CN ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\"your_ssid\" psk=\"your_password\" key_mgmt=WPA-PSK priority=1 } ","date":"2020-06-08","objectID":"/posts/51779/:1:0","tags":[],"title":"树莓派安装Raspbian系统后的一些设置","uri":"/posts/51779/"},{"categories":["极客有力量"],"content":"在启动后配置 参考官方文档 切换到root用户 sudo su - root 使用wpa_passphrase命令生成配置 wpa_passphrase \"your_ssid\" \"your_password\" \u003e\u003e /etc/wpa_supplicant/wpa_supplicant.conf 使生效 wpa_cli reconfigure 配置免密码登录 cd ~ \u0026\u0026 mkdir .ssh cd .ssh \u0026\u0026 touch authorized_keys 将客户端生成的公钥内容粘贴到authorized_keys文件中； 修改.ssh目录权限为700，authorized_keys文件权限为600，保证其他用户没有权限查看和修改该文件 chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys 修改更新源并更新 编辑/etc/apt/sources.list文件，注释官方源并添加国内源。 # tsinghua deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ stretch main non-free contrib deb-src http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ stretch main non-free contrib 系统更新： sudo apt-get update sudo apt-get upgrade -y raspi-config配置 执行sudo raspi-config： 修改pi用户密码，修改为强密码； 修改主机名； 本地化设置，修改Locale为en_US utf-8和zh_CN utf-8，并设置时区； 修改启动选项到CLI模式； 扩展文件系统； 关闭UART的Console模式，启用硬件模式，使UART可以正常连接外设； 按照需要开启或关闭SPI、I2C等接口； 安全加固 更改/etc/ssh/sshd_config文件： # 修改端口 Port 3154 # 禁用旧版本的有漏洞的 SSH 协议 Protocol 2 # 禁止root账户通过SSH登入 PermitRootLogin no # 只允许白名单内的用户登入 AllowUsers pi 重新生成 private host ID keys，否则将会使用系统镜像文件中默认值，因为镜像是公开的，因此容易受到中间人攻击。 sudo rm /etc/ssh/ssh_host_* sudo dpkg-reconfigure openssh-server 重启sshd——sudo service ssh restart 安装常用软件 zsh git oh-my-zsh 备份树莓派系统镜像 ","date":"2020-06-08","objectID":"/posts/51779/:2:0","tags":[],"title":"树莓派安装Raspbian系统后的一些设置","uri":"/posts/51779/"},{"categories":["极客有力量"],"content":"备份为镜像文件 将树莓派 SD 卡通过 USB 读卡器连接电脑，Mac/Linux（使用 gzip 压缩）下执行： sudo dd if=/dev/disk2 | gzip \u003e /Users/chiqingjun/Downloads/rasbian_stretch_gzip_20180425.img 缺点是，SD 卡容量有多大，备份出来的镜像文件就有多大，并且……备份速度很慢。 ","date":"2020-06-08","objectID":"/posts/51779/:3:0","tags":[],"title":"树莓派安装Raspbian系统后的一些设置","uri":"/posts/51779/"},{"categories":["极客有力量"],"content":"备份到其他SD卡(推荐) Github上的一个开源项目 rpi-clone，可以将树莓派系统备份到另一张 SD 卡上（不确定另一张卡容量小于当前 SD 卡容量时是否可行）。备份 SD 卡插入可直接运行系统，方便快捷。 把 SD 卡通过 USB 读卡器连接到树莓派上，然后以下代码在树莓派上执行。 clone 代码 git clone https://github.com/billw2/rpi-clone.git 查看 SD 卡设备名，一般是 sda。 sudo fdisk -l 执行备份，注意目标设备不是分区名，而是设备名。-f 选项会格式化备份 SD 卡可加可不加。 cd rpi-clone sudo ./rpi-clone -f [sdx] ","date":"2020-06-08","objectID":"/posts/51779/:4:0","tags":[],"title":"树莓派安装Raspbian系统后的一些设置","uri":"/posts/51779/"},{"categories":["极客有力量"],"content":"raspi-config 最简单的方式，使用 raspi-config 工具，选择 Advanced Options - Expand Filesystem 即可。 sudo raspi-config 手动扩展 ","date":"2020-06-08","objectID":"/posts/2845d/:0:0","tags":[],"title":"树莓派扩展文件系统使用SD卡所有存储空间","uri":"/posts/2845d/"},{"categories":["极客有力量"],"content":"原理 SD 卡一般被分为两个分区，mmcblk0p1 是启动分区，mmcblk0p2 是系统分区。我们要把 SD 卡没有利用的存储空间加到 mmcblk0p2 分区上。首先我们将 mmcblk0p2 分区删除，然后创建一个新的主分区，并选择使用所有剩余存储空间，完成对分区的扩展。 ","date":"2020-06-08","objectID":"/posts/2845d/:1:0","tags":[],"title":"树莓派扩展文件系统使用SD卡所有存储空间","uri":"/posts/2845d/"},{"categories":["极客有力量"],"content":"操作 查看系统的文件系统。 df -h 查看 mmcblk0p2 分区的起始扇区编号 cat /sys/block/mmcblk0/mmcblk0p2/start 磁盘操作，删除分区再新建分区 sudo fdisk /dev/mmcblk0 Command 输入 d 选择删除分区操作； Partition number 输入 2 选择第二分区； Command 输入 n 创建一个新分区； Partition number 输入 2； First sector 输入之前查到的起始扇区编号； Last sector 使用默认值（可选范围的最大值），即整个未分配的存储空间； Command 输入 w 将改动写入分区表。 重启使 Linux kernel 使用新分区表。 sudo reboot 重启后使改动对文件系统生效 sudo resize2fs /dev/mmcblk0p2 参考链接 玩玩树莓派之扩展SD卡剩余空间 - 简书 ","date":"2020-06-08","objectID":"/posts/2845d/:2:0","tags":[],"title":"树莓派扩展文件系统使用SD卡所有存储空间","uri":"/posts/2845d/"},{"categories":["极客有力量"],"content":"硬件准备 淘宝来的电视棒（RTL2832U+R820T），接收的频率范围为24 ~ 1766 MHz； 树莓派2B，或其他Linux主机； 软件安装 把电视棒插到树莓派的USB口上，运行lsusb命令，如果有如下信息证明驱动正常： Bus 001 Device 004: ID 0bda:2838 Realtek Semiconductor Corp. RTL2838 DVB-T 安装必要包： sudo apt-get install librtlsdr-dev sudo apt-get install libusb-1.0-0-dev 下载并编译dump1090： git clone https://github.com/antirez/dump1090.git cd dump1090 make 见证奇迹的时刻 ./dump1090 --interactive --net 打开命令行交互信息界面；同时打开web地图，默认是8080端口。 ","date":"2020-06-08","objectID":"/posts/a9208/:0:0","tags":[],"title":"用电视棒接收民航客机ADS-B信号","uri":"/posts/a9208/"},{"categories":["Infrastructure"],"content":"本文是《Linux 创客实战》一书的笔记，主要涉及 Linux 和树莓派的知识点。 Linux 知识 ","date":"2019-12-29","objectID":"/posts/a3348/:0:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"信号 Ctrl+T：发送 SIGINFO 信号，在执行 dd 命令时可以检查进度。 kill PID：发送正常终止的信号。 kill -1 PID 发送一个重启信号； kill -2 PID 发送中断信号，与按 Ctrl+C 相同； kill -9 PID 发送 SIGKILL 信号，并立即关闭进程； ","date":"2019-12-29","objectID":"/posts/a3348/:1:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"shell 在 bash 脚本中，反引号表示执行其中的代码，例如输出当前时间： echo `date` # Sun Dec 29 11:51:50 CST 2019 ","date":"2019-12-29","objectID":"/posts/a3348/:2:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"Ctrl+Z、\u0026 和 fg Ctrl+Z 暂停程序执行（进入睡眠），fg 命令可以恢复到前台运行。 在命令的末尾加 \u0026 字符可以让程序启动后在后台运行，但日志仍然会输出到控制台。fg 命令可以将程序拉到前台执行。 ","date":"2019-12-29","objectID":"/posts/a3348/:3:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"输出重定向 command \u003e file 将输出重定向到文件； command \u003e\u003e file 将输出以追加的方式重定向到文件。 command \u0026\u003e file 相当于 command \u003e file 2\u003e\u00261； command \u0026\u003e\u003e file 相当于 command \u003e\u003e file 2\u003e\u00261。 2\u003e\u00261 表示将 stderr 重定向到 stdout。 ","date":"2019-12-29","objectID":"/posts/a3348/:4:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"同时运行多个命令 A \u0026\u0026 B 操作符，相当于逻辑与，只有 A 命令执行成功才会运行 B 命令； A || B 操作符，相当于逻辑或，只有 A 命令执行失败才会运行 B 命令； A;B 连续运行 A 和 B 命令，不管命令的结果。 ","date":"2019-12-29","objectID":"/posts/a3348/:5:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"ls 命令 ls 命令输出的文件特殊权限选项有： d 表示目录； l 表示链接； s 表示文件应该以所有者权限运行； t 表示只有所有者可以删除或重命名文件； - 表示一般文件； ls 命令输出的 total 160 表示所有文件使用的磁盘区块的总数； ls 命令选项： -X 按扩展名排序； -S 按文件大小排序； ","date":"2019-12-29","objectID":"/posts/a3348/:6:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"top 命令 top 命令的含义是 table of processes，即进程表。 僵尸进程（zombie process）通常是已完成正在执行的操作的子进程，但是必须等待其父进程退出才能从进程列表中清除。 top 第一行的 load average 指的是平均 CPU 负载。 Cpu 行各部分含义： us 用于运行正常用户进程的时间百分比； sy 用于运行系统内核的进程的时间百分比； ni 用于运行优先级或降优先级进程上的时间百分比； id 闲置的时间百分比； wa 用于等待 I/O 完成的时间百分比； hi 硬件中断时间的百分比； si 软件中断时间的百分比； st 仅适用于虚拟化系统，只是从系统中偷走的时间百分比，因为主机系统忙于执行其他操作； 内存 Mem 和虚拟内存 Swap 行的含义： total 总量 used 使用量 free 可用量 buffers 当系统挂载或访问连接到系统本身的文件系统时使用的内存； cached mem 来自文件和程序的实际数据。 进程行的含义： PR 进程的当前优先级； NI 进程的 nice 值或用户自定义的优先级； VIRT 进程需要用到的内存总量； RES 进程实际用到的内存量； SHR 进程可用的共享内存量； S 进程的当前状态，D 不间断睡眠，R 运行，S 睡眠，T 追踪或停止，Z 僵尸。 常用操作快捷键： x 突出显示当前的排序字段； P 按 %CPU 排序（默认）； M 按 %MEM 排序； N 按 PID 排序； T 按 TIME 排序； k 杀死进程； h 帮助； q 退出。 ","date":"2019-12-29","objectID":"/posts/a3348/:7:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"ps 命令 ps 命令默认只显示当前用户正在运行的进程，若要获取所有进程的列表，请使用 -ef 选项。 ","date":"2019-12-29","objectID":"/posts/a3348/:8:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"grep 命令 常用的选项： -e 同时搜索多个术语（逻辑或的关系），例如： cat run.log | grep -e \"a\" -e \"i\" -i 选项不区分大小写，例如： cat run.log | grep -i \"simple\" -c 计算多少行包含搜索项，例如： cat run.log | grep -c \"is\" 树莓派知识 ","date":"2019-12-29","objectID":"/posts/a3348/:9:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"树莓派重启和关机 使用 shutdown 命令，以 root 权限执行。 关机 sudo shutdown -h now 重启 sudo shutdown -r now ","date":"2019-12-29","objectID":"/posts/a3348/:10:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"实现开机启动 将脚本或程序添加到 /etc/rc.local 中执行； ","date":"2019-12-29","objectID":"/posts/a3348/:11:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"GPIO 操作 操作 GPIO 有两个模块，其中一个是 RPi.GPIO，另一个是 pigpio。后者以服务器的形式在系统中运行，并且能够被 C 和 Python 程序调用，甚至通过网络被另一台树莓派调用。 I2C 协议和 SPI 协议都是串行通信协议，I2C 协议的通信速度比 SPI 慢，但是只需要两根线，SPI 设备需要至少 4 根线。 ","date":"2019-12-29","objectID":"/posts/a3348/:12:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["Infrastructure"],"content":"播放音频和视频 推荐使用 omxplayer，理由有： 包含在树莓派的发行版中； 可以使用 GPU 解码； 支持许多数字格式。 播放： omxplayer -o [local|hdmi] filename 设置音量： omxplayer -o [local|hdmi] --vol \u003cmillibels\u003e filename millibels 表示在 500（大声）和 -4000（非常安静）之间的一个数字，而 0 是正常的。 在命令行中控制树莓派全局音量，可以使用 alsamixer 程序。 其他 构建系统时，应该遵循 KISS 规则，即”Keep It Simple, Stupid!“ TTY 来自 TeleType 这个词，指的是一种与电脑通信的方法。在计算机的早期，你需要使用电传打字机或电传打印机来打出想要进入计算机的信息。 VNC 是 Virtual Network Computing 的缩写，虚拟网络计算。 参考链接 《Linux创客实战》 亚伦·纽科姆（Aaron Newcomb）, 刘端阳 书评 简介 电子书下载 Kindle电子书 ","date":"2019-12-29","objectID":"/posts/a3348/:13:0","tags":[],"title":"Linux创客实战","uri":"/posts/a3348/"},{"categories":["工欲善其事"],"content":"问题 在 Jupyter 中，如果执行 asyncio 的代码，例如 from requests_html import AsyncHTMLSession session = AsyncHTMLSession() async def get_google(): r = await session.get('https://google.com/') return r session.run(get_google) 会报错： RuntimeError: This event loop is already running 解决 具体原因是因为 asyncio 不允许嵌套事件循环，而在 Jupyter 中就已经运行了一个时间循环。 一种解决方案是使用开发者 erdewit 开发的 nest_asyncio 模块，在 Jupyter 文件中添加并执行如下 cell 内容： !pip install nest_asyncio import nest_asyncio nest_asyncio.apply() 参考 erdewit/nest_asyncio: Patch asyncio to allow nested event loops ","date":"2019-12-17","objectID":"/posts/f5d56/:0:0","tags":[],"title":"在Jupyter中执行asyncio代码","uri":"/posts/f5d56/"},{"categories":["工欲善其事"],"content":"在 Ubuntu 16.04 LTS 上安装一个 kotlin 语言的 Android 开发和调试环境。 安装 adb 工具 sudo apt update sudo apt install android-tools-adb 安装完成后就会有 adb 命令了，但 adb server 以非 root 运行时没有权限访问到连接的 Android 设备，会报 no permissions 的错误。 连接手机，通过 lsusb 命令查看手机的信息： $ lsusb Bus 001 Device 004: ID \u003cVendorID\u003e:\u003cProductID\u003e Google Inc. 如果文件不存在则新建文件： sudo vi /etc/udev/rules.d/70-android.rules 添加以下行： SUBSYSTEM==\"usb\",ATTRS{idVendor}==\"\u003cVendorID\u003e\",ATTRS{idProduct}==\"\u003cProductID\u003e\",MODE=\"0666\" 重启 udev 服务： sudo systemctl restart udev 重启 adb server： adb kill-server adb start-server 重新连接手机，即可看到设备： adb devices 在 docker 容器中访问 Android 设备 Android 手机是 usb 设备，因此要在 Docker 容器中访问，只需要在创建 Docker 容器时额外添加以下参数： --privileged -v /dev/bus/usb/:/dev/bus/usb 如果容器中缺少 lsusb 命令，可以安装： sudo apt install usbutils 注意容器中的 adb-server 和宿主机中的 adb-server 互相冲突，只能启动其中一个。因此在容器中连接 Android 设备时，要将宿主机上的 adb-server 先 kill 掉。 adb kill-server 若还是在容器中看不到设备，可能要重新插拔 Android 手机。 安装 IntelliJ IDEA 从 Ubuntu software 中搜索 IDEA 安装 community edition 即可。 IntelliJ IDEA 自带 openjdk 和 kotlin 环境，新建 Android 项目时会提示安装 Android SDK，可以帮我们节省很多安装的工作。 参考 Ubuntu 16.04 adb 安装 - 知乎 Ubuntu下解决adb devices:???????????? no permissions的方法 - 小学徒V - 博客园 ","date":"2019-12-07","objectID":"/posts/473e0/:0:0","tags":[],"title":"在Ubuntu上开发Android","uri":"/posts/473e0/"},{"categories":["工欲善其事"],"content":"SSH 端口转发又称为 SSH 隧道，是通过 SSH 协议建立隧道，实现本地主机和远程主机的端口绑定，数据由 SSH 协议进行加密传输。 SSH 有三种端口转发模式： 本地端口转发（Local port forwarding）； 远程端口转发（Remote port forwarding）； 动态端口转发； 本文介绍 SSH 的这三种端口转发和持久化工具 autossh。 本地端口转发 SSH 绑定本地端口，将本地端口的访问转发到远端。使用 -L 参数，格式为 本地端口:目标主机:目标主机端口。 假设本地主机为 host1，host1 能够访问 host2, host2 能够访问 host3，但 host1 无法直接访问 host3。 在 host1 上执行： ssh -L 8888:host3:8000 host2 表示绑定本地 8888 端口，该端口的访问流量会由 host2 转发至 host3:8000 端口。 在 host1 上执行： ssh -L 8888:localhost:8000 host2 表示绑定本地 8888 端口，该端口的访问流量会转发至 host2:8000 端口。注意目标主机的 localhost 指的是目标主机本身。 本地端口默认绑定到 localhost，只能本地访问，若要可以外网访问（绑定 0.0.0.0），可以写成： ssh -L :8888:host3:8000 host2 远程端口转发 SSH 绑定远程端口，将远程端口的访问转发到本地。使用 -R 参数，格式为 远程主机端口:目标主机:目标主机端口。 SSH 远程端口转发非常适合用来做内网穿透。假如 host1 是公网主机，host2 是内网主机且能够访问公网，host3 是内网主机不能访问公网，但 host2 可以访问 host3。如果要从 host1 访问 host3，可以用 host2 中转。 在 host2 上执行： ssh -R 8888:host3:8000 host1 表示绑定 host1 的 8888 端口，该端口的访问流量会由 host2 转发至 host3:8000 端口。 在 host2 上执行： ssh -R 8888:localhost:8000 host1 表示绑定 host1 的 8888 端口，该端口的访问流量会转发至 host2:8000 端口，注意目标主机的 localhost 指的是本地主机（发起 SSH 连接的主机）。 远程端口也是默认绑定到 localhost，若要外网访问（绑定 0.0.0.0），需要修改远程主机的 /etc/ssh/sshd_config 配置： GatewayPorts yes 记得重启 sshd 服务： systemctl restart sshd 动态端口转发 上述两种端口转发都是固定端口对固定端口的转发。动态端口转发不必指定端口号，可以将本地任意端口的流量转发到 SSH 远端。 动态端口转发使用 -D 参数，参数为 绑定地址:绑定本地端口。SSH 会启动一个 SOCKS 服务器监听该地址和端口，当使用该端口作为 SOCKS 代理时，请求的流量会被转发到远端。 例如在 host1 上执行 ssh -D 8000 host2 则在 host1 的 Firefox 中指定 localhost:8000 作为 socks 代理时，可以直接访问 host2 能够访问的主机和端口。 SSH 的其他参数 -N 只连接远程主机，不打开远程 shell； -T 不为这个连接分配 TTY； 这两个参数可以一起使用，代表这个 SSH 连接只用来传输数据，不执行远程操作。 -f 表示 SSH 连接成功后，转入后台运行。 autossh SSH 连接可能会意外断开或 hang 住，用进程监控工具，并不能有效检测到 hang 住的情况，autossh 就是为了解决这个问题。 autossh 会启动一个 SSH 进程，并实现一个端口转发循环，当发现进程死掉或者端口转发循环的流量停止时，会重启 SSH 进程，有效避免了 hang 住导致 SSH 端口转发不可用的情况。 安装： sudo apt install autossh autossh 命令的参数除了 -M 参数（用于手动指定端口转发循环的端口）外，其他参数与 ssh 命令相同，并会把这些参数传递给监视的 SSH 进程。 所以一个稳定的 SSH 远程端口转发的命令可以是： autossh -NT -R 8888:localhost:8000 host1 可以将 autossh 与 supervisor 等进程管理工具配合使用，建立长期稳定的 SSH 端口转发。 参考 SSH原理与运用（二）：远程操作与端口转发 - 阮一峰的网络日志 内网机器通过 SSH 反向代理到公网机器之后，公网机器只监听了本地端口 - V2EX 玩转SSH端口转发 | Fundebug博客 autossh ","date":"2019-12-03","objectID":"/posts/246b1/:0:0","tags":[],"title":"SSH端口转发","uri":"/posts/246b1/"},{"categories":["工欲善其事"],"content":"问题描述 安装了 Windows 10 和 Ubuntu 16.04.5 LTS 的双系统，都设置在东八区后，发现 Ubuntu 时间总是比 Windows 的时间快 8 个小时。 如果把 Ubuntu 的时间调整成北京时间，那么 Windows 的时间就会比北京时间慢 8 个小时； 如果把 Windows 的时间调整成北京时间，那么 Ubuntu 的时间就会比北京时间快 8 个小时。 问题原因 Linux / Unix / Mac 将计算机主板上的硬件时间当作 UTC 时间，而 Windows 将计算机主板上的硬件时间当作本地时间。 解决方案 两种解决方案，修改 Ubuntu 设置将硬件时间作为本地时间，或者修改 Windows 设置将硬件时间作为 UTC 时间 ","date":"2019-10-11","objectID":"/posts/573b0/:0:0","tags":[],"title":"解决Ubuntu和Windows双系统时间不一致","uri":"/posts/573b0/"},{"categories":["工欲善其事"],"content":"修改 Ubuntu 若 Ubuntu 版本小于 16.04，则修改 /etc/default/rcS ，将 UTC=yes 改为 UTC=no； 若 Ubuntu 版本等于或高于 16.04，则执行下面的命令并重启： timedatectl set-local-rtc 1 --adjust-system-clock ","date":"2019-10-11","objectID":"/posts/573b0/:1:0","tags":[],"title":"解决Ubuntu和Windows双系统时间不一致","uri":"/posts/573b0/"},{"categories":["工欲善其事"],"content":"修改 Windows 以管理员身份打开 Power Shell 命令行，输入以下命令修改注册表： Reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1 参考 怎样解决Windows10时间快和Ubuntu时间差问题？ - 知乎 ","date":"2019-10-11","objectID":"/posts/573b0/:2:0","tags":[],"title":"解决Ubuntu和Windows双系统时间不一致","uri":"/posts/573b0/"},{"categories":["Python"],"content":"简介 在 Python 的官方文档中，记录了 python 命令的 -m \u003cmodule-name\u003e 参数： 在 sys.path 中搜索指定名称的模块并将其内容作为 __main__ 模块来执行。 例如有以下目录结构： . └── foo └── bar.py 则可以通过 python -m foo.bar 运行 bar.py 文件。 与普通运行方式的不同 不同点主要在于 sys.path 和 sys.modules。假设项目路径为 /Users/chi/Projects/j4t。 普通运行方式： sys.path 中含有路径 /Users/chi/Projects/j4t/foo； sys.modules 中的 __main__ 为 \u003cmodule '__main__' from 'foo/bar.py'\u003e,； __file__ 值为 foo/bar.py； -m 运行方式： sys.path 中含有路径 /Users/chi/Projects/j4t； sys.modules 中的 __main__ 为 \u003cmodule 'foo.bar' from '/Users/chi/Projects/j4t/foo/bar.py'\u003e __file__ 值为 /Users/chi/Projects/j4t/foo/bar.py； 可以看出，-m 运行方式将执行时的当前目录加入到了 PYTHONPATH 中，而不是目标文件所在的目录，其他不同点的机制有何影响还不清楚。 用途 可以用 -m 方式来执行单元测试，例如以下项目结构： . ├── src └── tests 在没有安装 src 模块的情况下，在 tests 目录的测试用例中，直接将 src 作为模块 import，然后执行时使用 python -m pytest 就可以。 因为此时 sys.path 中含有当前目录，因此 src 能够被搜索到。 参考 1. 命令行与环境 — Python 3.7.4 文档 ","date":"2019-08-07","objectID":"/posts/bfff0/:0:0","tags":[],"title":"使用python -m运行","uri":"/posts/bfff0/"},{"categories":["Python"],"content":"Flask 基础 ","date":"2019-04-30","objectID":"/posts/94780/:0:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"上下文 current_app 应用上下文，当前应用实例。 g 应用上下文，处理请求时的临时存储对象，每次请求会重设对象。 request 请求对象，封装请求，常用的属性和方法有： form 获取表单数据； args 获取 URL 查询参数，参数值都是 string，args.get(key, default=None, type=None) 的 type 参数指定的函数用于类型强制转换，如果转换失败就会返回默认值； cookies 获取请求 cookie； headers 获取 HTTP header； files 获取请求上传的文件； get_json() 获取 body 中的 JSON 数据； is_secure() 是否通过安全连接发送的请求； host 请求定义的主机名； blueprint 处理请求的 Flask 蓝本； endpoint 处理请求的端点名称； accept_mimetypes 获取请求客户端接受的响应格式，子属性 accept_json 和 accept_html，可用于内容协商； session 请求上下文，用户会话。 @app.shell_context_processor 装饰器可以用来添加 shell 上下文。 @app.app_context_processor 装饰器装饰的函数的返回内容在所有模版中都可访问。 with app.app_context() 可以用来在应用上下文中执行代码。 ","date":"2019-04-30","objectID":"/posts/94780/:1:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"route 请求钩子，使用 g 在请求钩子和视图函数之间共享数据。 before_request before_app_request 用于 blueprint 定义 app 的 before_request； before_first_request after_request teardown_request 添加路由的方式： @app.route 装饰器，endpoint 即为视图函数名称； app.add_url() 方法，可以自定义 endpoint； Flask 支持动态路由，内置动态路由的类型有 string、int、float 和 path。 查看路由表通过 app.url_map 属性读取。Flask 会自动为静态文件目录添加 static 路由，默认静态文件目录为 static。 url_for('blueprint.endpoint', _external=True)，第二个参数控制生成绝对链接，绝对链接主机名取决于 request。目标是动态路由时，通过关键字参数传入动态路由参数，也可以通过关键字参数传入 URL 查询参数。 如果没有定义 /api 但定义了 /api/，Flask 会自动将 /api 的请求重定向到 /api/，反之则不会重定向。 ","date":"2019-04-30","objectID":"/posts/94780/:2:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"view 和 blueprint view 函数处理逻辑并生成响应。 blueprint 是 view 的集合，可以设置 url 前缀，通过 app.register_blueprint() 注册到 Flask app。 blueprint 包中应该使用相对导入，以便解耦。 在 blueprint 中使用 url_for 指向同一 blueprint 的路由时， blueprint 名可以省略，仅使用 .endpoint 的形式。 ","date":"2019-04-30","objectID":"/posts/94780/:3:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"response 通过 [响应内容, 状态码, header] 的格式，在视图函数中直接返回，后两个参数可以省略，默认 200 状态码。 通过make_response 生成响应对象，响应对象常用属性和方法如下： status_code 状态码； headers HTTP 头部； set_cookie() 设置 cookie； delete_cookie() 删除 cookie； set_data() 使用字符串或字节值设定响应； get_data() 获取响应主体，常用于 Flask test_client 获取响应中数据； 通过 redirect 和 url_for 重定向； 通过 abort(xxx) 进行 xxx 状态码的错误处理。注意是通过抛出异常的方式，也就是说 abort 之后视图函数就返回了。abort 还可以传第二个参数，作为错误的描述。 根据客户端请求的格式改写响应类型，称为内容协商。浏览器一般不限制响应的格式。 ","date":"2019-04-30","objectID":"/posts/94780/:4:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"error handler @app.errorhandler(500) 为 app 定义错误处理函数 @blueprint.errorhandler(500) 为 blueprint 定义错误处理函数； @blueprint.app_errorhandler(500) 为 app 定义错误处理函数； 除了使用状态码，也可以使用 Exception 作为参数，例如 @bp.errorhandler(ValidationError)。 ","date":"2019-04-30","objectID":"/posts/94780/:5:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"管理 @app.cli.command() 用于添加 flask 自定义命令。修饰的函数的 docstring 会成为 help 消息。 安装 python-dotenv 包后，flask 可以自动从 .env 文件中导入环境变量。 模板 Flask 使用 Jinja2 模板引擎。 常用变量过滤器有： safe 不要在不可信的文本上使用 safe 过滤器。 capitalize lower upper title trim striptags 常用控制结构有 import ... macro 宏定义和宏导入，宏的参数列表中不需要显式指定 **kwargs 和 *args 即可接受关键字参数和可变参数； include 'xx.html' 引用模板片段； extends 'xx.html' 模板继承； 在模板继承中，常常使用 block 区块。如果要重新定义父模板的区块并保留父模板区块中的内容，可以在区块中使用 super() 函数。 跟模板有关的两个扩展是 Flask-Bootstrap 集成 Bootstrap 框架； Flask-Moment 集成 Moment.js 处理时间展示。在引入 Moment.js 之后，立即使用 locale('es') 函数设置时间的语言偏好。 模版的默认目录为 templates，也可以配置 blueprint 使用专门的目录保存模版。搜索时会先搜索 app 的模版目录，再搜索 blueprint 的模版目录。 在模版的 for 循环结构内，可以访问一个特殊的 loop 变量，提供了 for 循环状态的一些信息。 loop.index 当前循环计数，从 1 开始； loop.first 是否是循环的第一项； loop.last 是否是循环的最后一项； 具体可见 Jinjia 文档 表单 Flask 使用 Flask-WTF 扩展快速实现表单。该扩展不需要在应用层初始化，但要配置密钥 SECRET_KEY。 表单类继承自 FlaskForm 类，每个表单对象可以有多个多种类型的字段，每个字段可以绑定多个 validator，validator 也可以使用自定义函数。表单类构造函数可以接受一些参数，比如用户对象，并保存在环境变量中，供自定义的验证方法使用。 表单字段可以通过 coerce 参数指定函数进行强制类型转换。 将表单类实例化后可以在视图函数中使用，form.validate_on_submit() 用于判断表单提交且通过验证。 将表单对象传递给模版，在模版中构造表单，使用 form.hidden_tag() 可以为表单添加防止 CSRF 攻击的隐藏字段。也可以使用 Flask-Bootstrap 渲染整个 Flask-WTF 表单，只需要： {% import 'bootstrap/wtf.html' %}{{ wtf.quick_form(form) }} 在 POST 请求中，常使用 Post/重定向/Get 的模式提升用户体验，但不是所有场景都需要这样做，比如前后端分离模式下，以及 API 模式下就不应该返回 302。 Flask 调用 flash(msg, category=\"INFO\") 函数可以向模版中传递消息，在模版中调用 get_flashed_messages(with_categories=False) 获取消息列表。category 是消息类别。 数据库 数据库分为关系型数据库和非关系型数据库。 关系性数据库遵循 ACID 范式，存储数据高效且避免了重复，但是结构复杂。 非关系型数据库又有键值对数据库、文档数据库等，查询操作简单，查询速度快，但增加了数据重复量。 Flask 使用的关系型数据库 ORM 框架主要是 Flask-SQLAlchemy，依赖 SQLAlchemy。除此之外，还需要安装相应数据库的驱动模块，例如 MySQL 数据库需要安装 pymysql，Postgres 需要安装 psycopg2。 ","date":"2019-04-30","objectID":"/posts/94780/:6:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Flask-SQLAlchemy 模型通过 __tablename__ 类变量指定数据库表名，一般使用复数命名。 常用的查询过滤器有： filter() filter_by() limit() offset() order_by() group_by() 常用的查询执行方法有： all() first() first_or_404() Flask-SQLAlchemy 特有 get() get_or_404() Flask-SQLAlchemy 特有 count() paginate() Flask-SQLAlchemy 特有 分页对象属性和方法（分页对象是 Flask-SQLAlchemy 特有的）： items 记录集合 prev_num 上一页的页数 next_num 下一页的页数 has_prev 是否有上一页 has_next 是否有下一页 total pages 总页数 page 当前页码 per_page query 分页的源查询 iter_pages(left_edge=2, left_current=2, right_current=5, right_edge=2) 用户构建分页导航条数据的迭代器； prev() 上一页的分页对象 next() 下一页的分页对象 常用的关系选项有： backref 在关系的另一侧添加反向引用； lazy 如何加载相关记录，最常用的是 dynamic（不加载记录，但提供加载记录的查询）； uselist 设置为 false 时，不使用列表，而使用标量值； order_by 指定关系中记录的排序方式 secondary 指定多对多关系中关联表的名称； primaryjoin 明确指定两个模型之间使用的联接条件，只在模糊的关系中需要指定； secondaryjoin 指定多对多关系中的二级联结条件 涉及到外键定义和关系时，可以使用模型名，或者表名的字符串格式。 数据库字段的 default 参数可以接受函数作为默认值。 db.event.listen(Post.body, 'set', Post.on_changed_body) 用于增加数据库事件监听程序。 ","date":"2019-04-30","objectID":"/posts/94780/:7:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"一对多关系 定义一对多关系： # 在一的一侧使用 relationship class Role(db.Model): # ... users = db.relationship('User', backref='role', lazy='dynamic') # 在多的一侧使用 ForeignKey class User(db.Model): # ... role_id = db.Column(db.Integer, db.ForeignKey(Role.id)) ","date":"2019-04-30","objectID":"/posts/94780/:8:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"一对一关系 与定义一对多关系相似，只需要在调用 db.relationship() 的时候把 uselist 设为 False。 ","date":"2019-04-30","objectID":"/posts/94780/:9:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"多对多关系 多对多关系需要指定一张关联表，拆分成原表与关联表的两个一对多关系（关联表是多的一侧）。 如果不需要操作关联表，可以这样定义： registrations = db.Table( 'registrations', db.Column('student_id', db.Integer, db.ForeignKey('students.id')), db.Column('class_id', db.Integer, db.ForeignKey('classes.id')), ) class Class(db.Model): __tablename__ = 'classes' # ... class Student(db.Model): __tablename__ = 'students' # ... classes = db.relationship( Class, secondary=registrations, backref=db.backref('students', lazy='dynamic'), lazy='dynamic', ) 此时使用 secondary 参数设置了关联表，SQLAlchemy 会自动接管这张表。 如果需要操作关联表，可以这样定义： class Follow(db.Model): __tablename__ = 'follows' follower_id = db.Column(db.Integer, db.ForeignKey('users.id'), primary_key=True) followed_id = db.Column(db.Integer, db.ForeignKey('users.id'), primary_key=True) timestamp = db.Column(db.DateTime, default=datetime.utcnow) class User(UserMixin, db.Model): __tablename__ = 'users' followers = db.relationship( Follow, foreign_keys = [Follow.followed_id], backref=db.backref('followed', lazy='joined'), lazy='dynamic', cascade='all, delete-orphan', ) followed = db.relationship( Follow, foreign_keys = [Follow.follower_id], backref=db.backref('followed', lazy='joined'), lazy='dynamic', cascade='all, delete-orphan', ) 这是一个自引用关系，描述了用户的关注和 fans。要点如下： 由于 Follow 表上有两个外键都指向 User，因此需要使用 foreign_keys 参数指定外键。 lazy 模式设置为 joined，可以实现立即从联接查询中加载相关对象，在一次数据库查询中完成这些操作。 cascade 参数，在关联表中删除记录后应该把指向该记录的实体也删除，因此使用了 delete-orphan，all 表示除了 delete-orphan 之外的所有选项 ","date":"2019-04-30","objectID":"/posts/94780/:10:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"数据库迁移框架 数据库迁移框架能够跟踪数据库模式的变化，例如 Alembic 和 Flask-Migrate，后者是前者的轻量级包装，与 Flask 命令 flask db 做了集成。常用命令有： revision 手动创建迁移，需要分别实现 upgrade() 和 downgrade() 函数； migrate 自动创建迁移； upgrade 把改动应用到数据库； downgrade 还原前一个脚本对数据库的改动； stamp 把数据库标记为已更新。 数据库模型在开发过程中可能时有变动，在提交到版本控制系统之前，可以合并迁移，避免产生大量无意义的小迁移脚本。 数据库迁移框架并不完美，在一些情况下是无法迁移的。例如在表中添加了一个非 null 而且没有默认值的字段就无法迁移，因为框架不知道该如何填充这个字段的数据。 电子邮件 Flask 发送邮件可以使用 Flask-Mail 扩展库，它实现了对标准库 smtplib 的包装，能更好的与 Flask 集成。 使用时需要添加几个 SMTP 服务器的配置项： MAIL_SERVER MAIL_PORT MAIL_USE_TLS MAIL_USE_SSL MAIL_USERNAME MAIL_PASSWORD 一个简单示例： from flask_mail import Message msg = Message('this is title', sender='you@example.com', recipients=['you@example.com']) msg.body = 'This is the body' msg.html = 'This is the \u003cb\u003eHTML\u003c/b\u003e body' with app.app_context(): mail.send(msg) Flask-Mail 的 send() 函数使用 current_app，因此要在激活的应用上下文中执行。 身份认证 身份认证主要使用到以下几个库： Flask-Login 管理登录、登出用户，管理用户会话； itsdangerous 生成并核对加密安全令牌； Werkzeug 计算密码 hash 值并进行核对。 ","date":"2019-04-30","objectID":"/posts/94780/:11:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"密码 hash 计算 Werkzeug 的 security 模块实现了密码 hash 的计算。提供了两个常用的函数： generate_password_hash(password, method='pbkdf2:sha256', salt_length=8) 用于生成密码，生成的密码是加了 salt 的，即使两个用户使用相同的密码，hash 值也完全不一致。； check_password_hash(hash, password) 用于验证密码； 实际开发中，可以通过 @property 特性，在模型层面，让数据库中的密码字段只读。 ","date":"2019-04-30","objectID":"/posts/94780/:12:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Flask-Login Flask-Login 要求实现的用户模型的属性和方法： is_authenticated 用户提供的登录凭据是否有效 is_active 是否允许用户登录 is_anonymous 普通用户返回 False，匿名用户返回 True get_id() 返回用户的唯一标识符，使用 Unicode 编码字符串。 Flask-Login 的 UserMixin 类包含了以上的默认实现，用户模型继承该类即可： class User(UserMixin, db.Model): # ... 使用 Flask-Login，需要实例化 LoginManager 类，并设置： login_manager.login_view 属性指定登录页面的端点，用于匿名用户访问时重定向到该页面； login_manager.anonymous_user 属性指定自定义的匿名用户类，定义匿名用户类的目的是，给用户类添加的自定义方法，在匿名类中也定义，就不需要判断用户是否登录即可调用； @login_manager.user_loader 装饰器，指定加载用户的函数，函数参数是用户标识符（字符串），返回用户对象或 None。用于给上下文变量 current_user 赋值； @login_required 装饰器，装饰受保护的路由，该装饰器要在 @app.route() 之后； current_user 是由 Flask-Login 提供的上下文变量，可以在模版和视图函数中使用，是用户对象的轻度包装，获取真正的用户对象需要使用 current_user._get_current_object()； 用户登录，调用 login_user(user, remember=False, duration=None, force=False, fresh=True) 函数，duration 用于设置 cookie 的有效期，或者通过 REMEMBER_COOKIE_DURATION 配置选项设置； 用户登出，调用 logout_user() 函数 ","date":"2019-04-30","objectID":"/posts/94780/:13:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"安全令牌 使用 itsdangerous 库生成包含用户信息的安全令牌，可用于重置密码，电子邮件确认等场景； itsdangerous 提供了多种生成令牌的方法。TimedJSONWebSignatureSerializer 类生成具有过期时间的 JSON Web 签名（JWS）。 from itsdangerous import TimedJSONWebSignatureSerializer s = TimedJSONWebSignatureSerializer('secret_key', expires_in=3600) token = s.dumps({'user_id': 12}) data = s.loads(token) expires_in 参数指定令牌过期时间，单位为秒。如果令牌过期或者无效，会抛出异常。这种令牌在有效时间内，无法判断是否已经使用过。 ","date":"2019-04-30","objectID":"/posts/94780/:14:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Flask-HTTPAuth Flask-HTTPAuth 常用于 API 请求认证，因为 API 是无状态的，不能使用 cookie 认证的方式。 使用 Flask-HTTPAuth 需要实例化 HTTPBasicAuth 类，并设置： @auth.verify_password 装饰器，指定验证函数，函数只返回 True/False，获取到的用户需要存入 g 中； @auth.login_required 装饰器，修饰需要登录保护的路由； 使用令牌的身份认证，用户名即令牌，密码为空。 避免了总是发送敏感信息； 令牌具有短暂有效期，降低泄漏后的安全隐患； 必须使用登录凭据签发新令牌，不能使用旧令牌签发新令牌； 验证失败时，返回 401 状态码。 REST API ","date":"2019-04-30","objectID":"/posts/94780/:15:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"REST API 架构 RESTful 架构的特征： 客户端-服务端有明确的界线； 无状态； 服务器响应可以标记为缓存或者不缓存； 接口统一 系统分层 按需编程 资源 是 REST 架构风格的核心： 使用唯一的 URL 表示每个资源； 使用请求方法表示期望的操作； 常用请求方法： GET 目标 URL 是单个资源或者资源集合，获取目标资源，响应状态码 200； POST 目标 URL 是资源集合，用于新建资源，响应状态 201，并在 header 的 Location 中返回新资源 URL，也可以在响应的主体中包含该资源； PUT 目标 URL 是单个资源，用于修改资源（也可以用来创建），响应状态码 200 或者 204； DELETE 目标 URL 是单个资源或资源集合，用于删除资源，响应状态码 200 或者 204。 相关状态码说明： HTTP 201，Created，请求成功并且创建了一个新资源； HTTP 204，No Content，请求成功处理，但是返回的响应没有数据，比如资源被删除了。 设计良好的 RESTful API： 在返回数据中包含完整的其他资源 URL，可以由客户端自己发掘新资源； 使用版本区分 Web 服务所处理的 URL。 ","date":"2019-04-30","objectID":"/posts/94780/:16:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"数据验证 客户端提供的数据可能无效、错误或者多余，要进行数据验证。 数据验证时，可以通过抛出异常的方式，将错误交给上层调用函数处理。同时，可以注册该种错误的异常处理函数，来返回给客户端错误消息。 测试 ","date":"2019-04-30","objectID":"/posts/94780/:17:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"faker 使用 faker 库可以生成多种类型的虚拟数据 from faker import Faker fake = Faker() fake.email() fake.user_name() fake.name() fake.city() fake.past_date() fake.text() ","date":"2019-04-30","objectID":"/posts/94780/:18:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"coverage coverage 是一个代码覆盖度工具，用于统计单元测试检查了应用多少功能，并提供一份详细的报告。 coverage 提供了 CLI 命令 coverage。主要功能有： coverage run cmd args 启动覆盖度检测引擎并运行，cmd args 是运行单元测试的命令； coverage report 生成文本格式报告并输出到 stdout； coverage html 生成 html 格式报告； coverage erase 删除 coverage 缓存目录。 coverage 同时也可以在代码中进行控制。 import coverage # 创建覆盖度检测引擎 # branch 选项是否开启分支覆盖度分析，开启后会检查条件语句的 True 和 False 分支是否都执行了 # include 选项限制检测的文件在应用包内 COV = coverage.coverage(branch=True, include='app/*') COV.start() COV.stop() COV.save() # 会在 stdout 输出文本格式的报告 COV.report() # directory 指定 html 报告保存路径 COV.html_report(directory=covdir) COV.erase() 注意覆盖度指标无法表明项目中的代码多么健康，因为代码有没有缺陷还受其他因素的影响（例如测试的质量）。 ","date":"2019-04-30","objectID":"/posts/94780/:19:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Flask 测试客户端 Flask 内建了一个测试客户端，来向 Flask 应用发送请求，得到的结果是一个 Flask response 对象。 获得测试客户端。use_cookies 选项执行测试客户端是否使用 cookie。 app = create_app('testing') client = app.test_client(use_cookies=True) 发起 GET 请求： client.get('/') 发起 POST 请求（FORM）： client.post('/', data=data) 发起 POST 请求（JSON），测试客户端不会自动编码 JSON 数据： client.post( '/', headers={'Content-Type': 'application/json'}, data=json.dumps(data), ) 发请求时有以下参数： follow_redirects 自动重定向请求 headers 指定 HTTP header 获得的响应是 response 对象，可以使用 get_data() 方法获取响应主体，默认情况下返回字节数组，传入 as_text=True 参数后返回字符串。 在 with 上下文中使用 client，可以访问上下文变量，例如 session： from flask_login import current_user with client: assert current_user.id == 1 ","date":"2019-04-30","objectID":"/posts/94780/:20:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Selenium 端到端测试 Selenium 是一个浏览器自动化工具，支持多种主流 Web 浏览器。使用时，除了安装 selenium 外，还需要安装： 相应的浏览器驱动，比如 Chome 的 ChromeDriver。 Selenium 的 Python 接口； 使用 Selenium 进行 Web 测试时，让应用运行在后台线程的开发服务器中，而测试运行在主线程中。通过实现并发送一个 HTTP 请求，来关闭服务器。这里会调用 Werkzeug web 服务器本身的停止选项。 shutdown = request.environ.get('werkzeug.server.shutdown') shutdown() 启动 Chrome，headless 选项指定在无界面 Chrome 实例中运行，并执行所有操作： from selenium import webdriver options = webdriver.ChromeOptions() options.add_argument('headless') client = webdriver.Chrome(chrome_options=options) 测试过程中，可以禁止服务器的日志或只输出错误日志，保持输出简洁。 请求： client.get() 寻找元素： client.find_element_by_link_text() client.find_element_by_name() 操作： send_keys() 填写表单； click() 点击 关闭 Chrome： client.quit() 日志和性能 ","date":"2019-04-30","objectID":"/posts/94780/:21:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"日志 ","date":"2019-04-30","objectID":"/posts/94780/:22:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"应用日志 在应用启动过程中，Flask 会创建一个 logging.Logger 类实例，通过 app.logger 访问。 但在生产模式中，默认情况下没有配置日志的处理程序，如果不添加处理程序，就不会保存日志。 可以通过配置类的 init_app 方法添加处理程序。 @classmethod def init_app(cls, app): from logging.handlers import SMTPHandler mail_handler = SMTPHandler(...) mail_handler.setLevel(logging.ERROR) app.logger.addHandler(mail_handler) 常用 handler 有： SMTPHandler 发邮件 StreamHandler 日志内容输出到 stderr SysLogHandler 日志发送给守护进程 syslog ","date":"2019-04-30","objectID":"/posts/94780/:22:1","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Werkzeug 日志 获取 Werkzeug 日志对象： import logging logger = logging.getLogger('werkzeug') ","date":"2019-04-30","objectID":"/posts/94780/:22:2","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"性能分析 ","date":"2019-04-30","objectID":"/posts/94780/:23:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"数据库性能分析 多数数据库查询语言都提供了 explain 语句，用于显示数据库执行查询时采取的步骤。 Flask-SQLAlchemy 提供了获取数据库查询的接口。 首先需要设置 SQLALCHEMY_RECORD_QUERIES 为 True，启用记录查询统计数据的功能。 然后在 @after_request 中获取数据库查询： from flask_sqlalchemy import get_debug_queries for query in get_debug_queries(): # ... 查询对象拥有以下属性： statement SQL 语句； parameters SQL 语句使用的参数； duration 查询持续的时间，单位为秒； context 查询在源码中所处的位置； start_time 执行查询时的时间 end_time 返回查询结果时的时间 根据 duration 属性筛选出慢查询，将信息写入到日志中，级别 WARNING。 ","date":"2019-04-30","objectID":"/posts/94780/:23:1","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"源码分析 应当只在开发环境中分析源码，源码分析器会导致应用的运行速度比常规情况下慢的多。 Werkzeug 提供了一个源码分析器中间件，通过 Flask app 的 wsgi_app 属性依附到应用上。 from werkzeug.contrib.profiler import ProfilerMiddleware app.wsgi_app = ProfilerMiddleware( app.wsgi_app, restrictions=[func_count], profile_dir=profile_dir, ) app.run(debug=False) 应用启动后，控制台会显示每条请求的分析数据。 restrictions 参数的 func_count 指定了展示执行最慢的函数的数量； profile_dir 参数指定了保存分析数据的路径，分析器输出的数据文件可以用于生成更详细的报告，如调用图等； 部署 ","date":"2019-04-30","objectID":"/posts/94780/:23:2","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Flask-SSLify Flask-SSLify 扩展能够拦截发给 http:// 的请求，将其重定向到 https://，需要在应用层初始化。但是如果应用部署在 Nginx 等反向代理服务器后面时，就没有必要使用该库了，完全可以在 Nginx 配置 HTTPS 并进行重定向，同时应用使用 HTTP 与 Nginx 通信。 ","date":"2019-04-30","objectID":"/posts/94780/:24:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"ProxyFix 使用反向代理服务器时，代理会设定一些自定义的 HTTP 头部，以用来标识请求的真实协议、地址等。 Werkzeug 提供的一个 WSGI 中间件 ProxyFix 能够检查代理服务器设定的这些自定义 HTTP 头部，并更新 request 对象。举例来说，request.is_secure 会反映客户端发给反向代理服务器的请求的加密状态，而不是代理服务器到应用的请求的加密状态。 from werkzeug.contrib.fixers import ProxyFix app.wsgi_app = ProxyFix(app.wsgi_app) ","date":"2019-04-30","objectID":"/posts/94780/:25:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Web 服务器 常用的 Web 服务器有 Gunicorn, uWSGI 和 Waitress。 ","date":"2019-04-30","objectID":"/posts/94780/:26:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Docker 使用 Docker 部署时，应当使用单独的用户运行应用程序，单独的用户在 Dockerfile 文件中新建。 RUN adduser -D flaskyUSERflasky adduser 命令的 -D 选项禁止命令提示输入密码。 另外程序启动命令我们使用一个 shell 脚本 boot.sh，因为启动时还需要进行初始化工作： #!/bin/sh source venv/bin/activate flask deploy exec gunicorn -b 0.0.0.0:5000 --access-logfile - --error-logfile - flasky:app 使用 exec 命令启动 Gunicorn 后，Gunicorn 的进程便取代了运行 boot.sh 文件的进程，成为主进程。 排查容器问题的常用策略是，创建一个特殊的容器，加载一些辅助工具，然后在 shell 会话中调用。 执行 docker run 命令时有 --link target:alias 选项，该选项把这个新容器与一个现有的容器连接起来。其值是以冒号分隔的两个名称，一个是目标容器的名称或 ID target，另一个是在当前容器中访问目标容器所用的别名 alias。 使用容器编排时，尽可能让每个容器使用单独的 env 文件，隔离机密配置信息。 docker-compose 可以按照依赖顺序启动容器，但如 mysql 可能需要几秒钟才能启动，而 docker-compose 不会等待。因此连接外部服务器时要有重试机制。 docker-compose up -d --build 命令，--build 选项指明，应该在启动应用之前构建镜像。 docker system prune --volumes 命令，会删除所有不再使用的 image 或 volume，以及不在运行的容器。 在生产环境中使用 docker，需要考虑的安全问题： 监控和提醒 日志 机密信息管理 可靠性和伸缩性 其他 ","date":"2019-04-30","objectID":"/posts/94780/:27:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"权限设计 书中把不同权限的权限值设置为 2 的幂，有三个好处： 每种不同的权限组合对应的值都是唯一的，方便在数据库中存储； 为权限组合增加权限只需要 self.permissions += perm，反之则 self.permissions -= perm； 检查是否拥有某项权限，只需要按位与即可，self.permissions \u0026 perm == perm； ","date":"2019-04-30","objectID":"/posts/94780/:28:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Bleach Bleach 是使用 Python 实现的 HTML 清理程序。 bleach.clean(content, tags, strip=True) 删除不在白名单中的标签； bleach.linkify(content) 把纯文本中的 URL 转换为合适的 \u003ca\u003e 链接； ","date":"2019-04-30","objectID":"/posts/94780/:29:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"markdown 相关库 Markdown：使用 Python 实现的服务端 Markdown 到 HTML 转换程序； PageDown：使用 JavaScript 实现的客户端 Markdown 到 HTML 转换程序； Flask-PageDown：为 Flask 包装的 PageDown，把 PageDown 集成到 Flask-WTF 中； ","date":"2019-04-30","objectID":"/posts/94780/:30:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"URL 片段 URL 片段 用于指定加载页面后滚动条所在的初始位置。格式为在 URL 查询参数之后，以 # 开头的锚点名。 例如：http://example.com/users/?page=1#tom。 ","date":"2019-04-30","objectID":"/posts/94780/:31:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"HTTPie HTTPie 是一个 Python 编写的命令行 HTTP 请求工具，安装后会添加 CLI 命令 http。与 cURL 相比，其语法更加简洁，可读性更高，进行 API 请求也更便捷 发起 GET 请求： http \"httpbin.org/get?a=1\u0026b=2\" 发起 POST 请求（JSON）： http httpbin.org/post a=1 b=2 发起 POST 请求（FORM）： http --form httpbin.org/post a=1 b=2 发起带 Http AUTH 的请求： http --auth username:password httpbin.org/get 发起 PUT 请求： http --auth username:password PUT httpbin.org/put a=1 b=2 设置 header http httpbin.org/headers User-Agent:asdf ","date":"2019-04-30","objectID":"/posts/94780/:32:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"Web 应用设计原则 业务逻辑应写入独立与应用上下文的模块中，在视图函数中的代码应该保持简洁，仅发挥粘合剂的作用。 如何优化数据库性能： 查找数据库慢查询，优化索引； 在应用和数据库之间加入缓存； ","date":"2019-04-30","objectID":"/posts/94780/:33:0","tags":[],"title":"《Flask Web 开发》大纲","uri":"/posts/94780/"},{"categories":["Python"],"content":"在掘金看到一篇文章，讲 Python 中使用 round 函数进行浮点数四舍五入时不够精确的原因，总结一下。 不够精确的原因 对浮点数进行四舍五入不够精确的原因主要有两个： 在 Python 中浮点数本身不够精确； round 函数默认采用的数值修约规则是“四舍六入五成双”，不是“四舍五入”； 四舍六入五成双与奇进偶舍 举个例子，对于小数 a.bcd，保留两位小数。 ","date":"2019-04-07","objectID":"/posts/669c4/:0:0","tags":[],"title":"Python中的四舍五入","uri":"/posts/669c4/"},{"categories":["Python"],"content":"四舍六入五成双 ，四舍六入五成双的规则是： 如果 d 小于 5，舍去； 如果 d 大于 5，进位； 如果 d 等于 5，则遵循“奇进偶舍”； ","date":"2019-04-07","objectID":"/posts/669c4/:1:0","tags":[],"title":"Python中的四舍五入","uri":"/posts/669c4/"},{"categories":["Python"],"content":"奇进偶舍 如果 d 等于 5： d 后面没有数字时，需要看 c： 如果 c 是奇数，则进一位； 如果 c 是偶数，则舍去。 d 后面还有数字，则无论 c 是奇数还是偶数，都进一位。 解决方案 针对浮点数表示不够精确的问题，使用 decimal 类型进行精确表示。 使用 decimal 类型的 quantize 进行运算，并指定数值修约类型为 decimal.ROUND_HALF_UP。 注：默认的数值修约方式为 decimal.ROUND_HALF_EVEN，即四舍六入五成双。 \u003e\u003e\u003e from decimal import Decimal, ROUND_HALF_UP \u003e\u003e\u003e Decimal('0.315').quantize(Decimal('0.00'), rounding=ROUND_HALF_UP) Decimal('0.32') \u003e\u003e\u003e Decimal('0.325').quantize(Decimal('0.00'), rounding=ROUND_HALF_UP) Decimal('0.33') \u003e\u003e\u003e Decimal('0.32511').quantize(Decimal('0.00'), rounding=ROUND_HALF_UP) Decimal('0.33') 参考链接 为什么你需要少看垃圾博客以及如何在Python里精确地四舍五入 - 掘金 数值修约 - 维基百科，自由的百科全书 奇进偶舍 - 维基百科，自由的百科全书 ","date":"2019-04-07","objectID":"/posts/669c4/:2:0","tags":[],"title":"Python中的四舍五入","uri":"/posts/669c4/"},{"categories":["Python"],"content":"问题 pytz 是 Python 的一个时区库，可以方便的定义时区，弥补了 Python 自带 datetime 库的不足。例如： import pytz from pytz import timezone shanghai = timezone('Asia/Shanghai') amsterdam = timezone('Europe/Amsterdam') utc = pytz.UTC 但是如果将这些时区对象作为 tzinfo 传入 datetime 的构造函数中，则会发生时间的偏移。 from datetime import datetime d = datetime(2019, 1, 1, 12, 0, 0, tzinfo=shanghai) print(d) # 2019-01-01 12:00:00+08:06 可以看到，与正常的结果相比，差了 6 分钟。不只是东八区有这个问题，其他的时区或多或少都有差值。 pytz pytz 库文档中表示，上述使用方式是错误的。 ","date":"2019-03-16","objectID":"/posts/217d6/:0:0","tags":[],"title":"pytz中的时间偏移问题","uri":"/posts/217d6/"},{"categories":["Python"],"content":"tzinfo datetime 构造函数中的tzinfo 参数与大多数的 pytz 时区不兼容，即会发生时间漂移。唯一的例外是没有夏令时转换的 UTC 时区，是安全的。 It is safe for timezones without daylight saving transitions though, such as UTC. 在 pytz 中正确处理时区的方式有两种： ","date":"2019-03-16","objectID":"/posts/217d6/:1:0","tags":[],"title":"pytz中的时间偏移问题","uri":"/posts/217d6/"},{"categories":["Python"],"content":"localize 使用时区对象的 localize 方法，将一个 native 时间（不带时区）转换为带时区的时间。 from datetime import datetime from pytz import timezone t = datetime(2019, 1, 1, 12, 0, 0) amsterdam = timezone('Europe/Amsterdam') ams_dt = amsterdam.localize(t) print(ams_dt) # 2019-01-01 12:00:00+01:00 ","date":"2019-03-16","objectID":"/posts/217d6/:2:0","tags":[],"title":"pytz中的时间偏移问题","uri":"/posts/217d6/"},{"categories":["Python"],"content":"astimezone 使用 datetime 对象的 astimezone 方法，将一个带时区的时间，转换为另一个时区的时间。 shanghai = timezone('Asia/Shanghai') sh_dt = ams_dt.astimezone(shanghai) print(sh_dt) # 2019-01-01 19:00:00+08:00 解决 通过 pytz 库的文档，我们可以得出，如果想要构建一个 Asia/Shanghai 的本地时间，可以： 创建 Asia/Shanghai 的 native 时间，然后通过 localize 方法转换为本地时间； 使用 tzinfo=UTC 创建一个 UTC 时间，然后通过 astimezone 转换为本地时间。 参考链接 python中pytz，东8区，6分钟问题 - 老楠老楠 pytz · PyPI ","date":"2019-03-16","objectID":"/posts/217d6/:3:0","tags":[],"title":"pytz中的时间偏移问题","uri":"/posts/217d6/"},{"categories":["Python"],"content":"类型标注 类型标注，称为 Type Hints 或者 Type annotation，由以下几个 PEP 定义： PEP 3107，Python 3.0，增加了 function annotation syntax，但没有实现该语义； PEP 484，Python 3.5，增加了 provisional module 以支持该特性； PEP 526，Python 3.6，增加了 variable annotations syntax。 与静态语言的类型声明相比，Python 中的类型标注不会在运行时做类型检查。 基本语法 ","date":"2019-03-16","objectID":"/posts/54419/:0:0","tags":[],"title":"Python中的类型标注","uri":"/posts/54419/"},{"categories":["Python"],"content":"function annotation def greeting（name：str, age: int = 13） - \u003e str： return 'Hello'+ name + str(age) 类型标注可接受的类型有：内置类（包括标准库和第三方库中定义的类）、抽象基类、types 模块中定义的类型，用户定义的类。除此之外，还可以是 None、Any、 Union、 Tuple和 Callable 等类型。 ","date":"2019-03-16","objectID":"/posts/54419/:1:0","tags":[],"title":"Python中的类型标注","uri":"/posts/54419/"},{"categories":["Python"],"content":"variable annotation 全局变量声明，只声明但没有初始化的变量，在引用时会报错。 some_number: int # variable without initial value some_list: List[int] = [] # variable with initial value 类变量声明 class BasicStarship: captain: str = 'Picard' # instance variable with default damage: int # instance variable without default stats: ClassVar[Dict[str, int]] = {} # class variable ClassVar 是 Python 3.5 引入的 typing 模块中定义的。 类型检查工具 可以使用 mypy、pytype 等工具按照类型标注对代码进行检查。 PEP563 如下代码使用了类型标注，mypy 检查没有问题，但运行时会报错 NameError: name 'Subject' is not defined。 from typing import Union from dataclasses import dataclass import pymysql.cursors connection = pymysql.connect(host='localhost', user='root', password='', db='test', charset='utf8mb4') @dataclass class Subject: id: int cat_id: int title: str kind: int = 0 @classmethod def get(cls, id: int) -\u003e Union[Subject, None]: with connection.cursor() as cursor: cursor.execute( \"select id, cat_id, title, kind from subject where id=%s\", id) rs = cursor.fetchone() if not rs: return None return cls(*rs) 原因是类型注解部分求值太早了，那个时候类还没创建完！，详见 PEP 563。解决方案有三种： ","date":"2019-03-16","objectID":"/posts/54419/:2:0","tags":[],"title":"Python中的类型标注","uri":"/posts/54419/"},{"categories":["Python"],"content":"Python 3.7 延迟求值 如果 Python 是 3.7 版本，可以在文件开头加入： from __future__ import annotations 以启用延迟求值的特性。 ","date":"2019-03-16","objectID":"/posts/54419/:3:0","tags":[],"title":"Python中的类型标注","uri":"/posts/54419/"},{"categories":["Python"],"content":"使用字符串代替类名 将 get 方法中类名改为用字符串代替，参考 PEP484 中的讨论 def get(cls, id: int) -\u003e Union['Subject', None]: ... ","date":"2019-03-16","objectID":"/posts/54419/:4:0","tags":[],"title":"Python中的类型标注","uri":"/posts/54419/"},{"categories":["Python"],"content":"使用 pytype 做静态检查 pytype 还能够推断未做类型标注的 Python 代码的类型。 ➜ cat foo.py def make_greeting(user_id): return 'hello, user' + user_id def print_greeting(): print(make_greeting(0)) ➜ pytype-single foo.py File \"foo.py\", line 2, in make_greeting: unsupported operand type(s) for +: 'str' and 'int' [unsupported-operands] Function __add__ on str expects str Called from (traceback): line 5, in print_greeting For more details, see https://github.com/google/pytype/blob/master/docs/errors.md#unsupported-operands. 参考链接 PEP 3107 — Function Annotations | Python.org PEP 484 — Type Hints | Python.org PEP 526 — Syntax for Variable Annotations | Python.org PEP 563 — Postponed Evaluation of Annotations | Python.org from future import annotations - 小明明s à domicile ","date":"2019-03-16","objectID":"/posts/54419/:5:0","tags":[],"title":"Python中的类型标注","uri":"/posts/54419/"},{"categories":["Python"],"content":"简述 在 Python 编程过程中，有一些 class 是业务模型，用于存储数据，我们称为“数据类”，例如商品等。 attrs 是 Python 核心开发 Hynek Schlawack 设计并实现的一个项目，用于解决数据类定义和使用上的繁琐。 dataclasses 是 Python 3.7 中新增的类似 attrs 的标准库模块。 数据类的痛点 每个数据类在定义时，大多都要实现以下方法： __init__ 初始化大量参数； __repr__ 挑几个参数用于表示该类； __eq__ 和 __lt__ 等比较方法，其他比较方法可以使用 functools.total_ordering 装饰器实现； __hash__ 用户对对象去重； 给类定义 to_dict 或者 to_json 的方法，将类的属性便捷打包。 以上方法几乎每个数据类都要实现，所做的不过是定义某些参数用于某些方法，非常繁琐。我们希望能有一种便捷的方法定义参数和以上方法。 attrs ","date":"2019-03-16","objectID":"/posts/9b182/:0:0","tags":[],"title":"attrs和Python3.7的dataclasses","uri":"/posts/9b182/"},{"categories":["Python"],"content":"安装 pipenv install attrs ","date":"2019-03-16","objectID":"/posts/9b182/:1:0","tags":[],"title":"attrs和Python3.7的dataclasses","uri":"/posts/9b182/"},{"categories":["Python"],"content":"基本使用 import attr @attr.s(hash=True) class Product(object): id = attr.ib() author_id = attr.ib() brand_id = attr.ib() spu_id = attr.ib() title = attr.ib(repr=False, cmp=False, hash=False) item_id = attr.ib(repr=False, cmp=False, hash=False) n_comments = attr.ib(repr=False, cmp=False, hash=False) creation_time = attr.ib(repr=False, cmp=False, hash=False) update_time = attr.ib(repr=False, cmp=False, hash=False) source = attr.ib(default='', repr=False, cmp=False, hash=False) parent_id = attr.ib(default=0, repr=False, cmp=False, hash=False) ancestor_id = attr.ib(default=0, repr=False, cmp=False, hash=False) attr.s 装饰器是一个全局设置，决定了所有参数的情况。默认情况下，参数参与 repr、cmp 和 init ，不会参与 hash。 attr.ib 是函数参数级别的设置，优先级更高，默认情况下，参数参与 repr、cmp 和 init，不会参与 hash，没有默认值。 上面的例子中，所有参数都在 init 方法中，只有前 4 个参数参与了 repr、cmp 和 hash，只有最后三个参数拥有默认值。 ","date":"2019-03-16","objectID":"/posts/9b182/:2:0","tags":[],"title":"attrs和Python3.7的dataclasses","uri":"/posts/9b182/"},{"categories":["Python"],"content":"字段类型验证 attrs 也可以对字段类型进行验。 通过装饰器方式添加验证函数 import attr @attr.s class C(object): x = attr.ib() @x.validator def check(self, attribute, value): if value \u003e 42: raise ValueError(\"x must be smaller or equal to 42\") 通过属性参数方式添加验证函数，可以传一个验证函数列表 def x_smaller_than_y(instance, attribute, value): if value \u003e= instance.y: raise ValueError(\"'x' has to be smaller than 'y'!\") @attr.s class C(object): x = attr.ib(validator=[attr.validators.instance_of(int), x_smaller_than_y]) y = attr.ib() 上述代码首先验证了参数 x 的类型为 int，再验证 x \u003c y。 ","date":"2019-03-16","objectID":"/posts/9b182/:3:0","tags":[],"title":"attrs和Python3.7的dataclasses","uri":"/posts/9b182/"},{"categories":["Python"],"content":"属性类型转化 自动转化传入参数的类型： import attr @attr.s class C(object): x = attr.ib(converter=int) 传入 C 的参数会自动被转化为 int 型。 ","date":"2019-03-16","objectID":"/posts/9b182/:4:0","tags":[],"title":"attrs和Python3.7的dataclasses","uri":"/posts/9b182/"},{"categories":["Python"],"content":"包含元数据 属性可以包含元数据。 \u003e\u003e\u003e @attr.s ... class C(object): ... x = attr.ib(metadata={'my_metadata': 1}) \u003e\u003e\u003e attr.fields(C).x.metadata mappingproxy({'my_metadata': 1}) \u003e\u003e\u003e attr.fields(C).x.metadata['my_metadata'] 1 dataclasses 在 Python 3.7 中添加了新的 dataclasses 模块，基于 PEP 557。 Python 3.6 可以通过 pip 安装： pipenv install dataclasses 举个例子： from dataclasses import dataclass, field @dataclass(hash=True, order=True) class Product(object): id: int author_id: int brand_id: int spu_id: int title: str = field(hash=False, repr=False, compare=False) item_id: int = field(hash=False, repr=False, compare=False) n_comments: int = field(hash=False, repr=False, compare=False) creation_time: datetime = field(default=None, repr=False, compare=False,hash=False) update_time: datetime = field(default=None, repr=False, compare=False, hash=False) source: str = field(default='', repr=False, compare=False, hash=False) parent_id: int = field(default=0, repr=False, compare=False, hash=False) ancestor_id: int = field(default=0, repr=False, compare=False, hash=False) 同 attrs 类似，dataclass 是一个全局配置，默认函数参与 init、repr 和 eq，不参与 order、unsafe_hash。eq 和 order 的区别是：eq只实现 __eq__ 方法，order 还实现其他比较方法。 field 默认参与 init 和 compare，compare 即是 eq 和 order。 使用 Python 的 type annotations 特性进行字段类型验证。 参考链接 attrs 和 Python3.7 的 dataclasses - 董伟明 dataclasses — Data Classes - Python documentation attrs: Classes Without Boilerplate - attrs documentation ","date":"2019-03-16","objectID":"/posts/9b182/:5:0","tags":[],"title":"attrs和Python3.7的dataclasses","uri":"/posts/9b182/"},{"categories":["Python"],"content":"前几天在掘金上看到一篇文章 《Python 工匠： 异常处理的三个好习惯》，董伟明的 “Python 之美” 公众号也转发了，感觉不错。 文章主要讲了三个 Python 异常处理时的好习惯： 只做最精确的异常捕获； 别让异常破坏抽象一致性； 异常处理不应该喧宾夺主。 下面分别简要说明一下。 只做最精确的异常捕获 目的是不捕获到不必要的异常，不掩盖其他的问题。 精确包括两部分： 捕获精确，即只捕获那些可能会抛出异常的语句块； 类型精确，即错误类型而要尽可能的具体； 捕获精确使 try 中的代码最精确，类型精确使 except 中错误类型精确。 别让异常破坏抽象一致性 文章中介绍了一个特别好的想法，在 web 开发中利用 raise error 来返回错误消息，我感觉有几个好处： 可以将错误消息集中定义在某处，方便修改； 抛错的地方 import 很简洁，只需要 import 该种错误； 在接错误的地方，只要接错误类的父类的异常，就可以接到所有需要返回错误消息的场景； 在此之外，作者举了一个例子，阐述了抽象一致性的必要性。我们在进行错误处理时，要注意到： 让模块只抛出与当前抽象层级一致的异常； 在必要的地方进行异常包装与转换（参考 requests 库对 urllib3 库异常的封装）。 异常处理不应该喧宾夺主 这一条基本属于优化代码可读性。主要是说，不应该在代码中都是 try…except，而掩盖了正常的业务逻辑。 我认为，在代码中使用多个 try…except 并无不妥，文章提供的使用 with 上下文管理器来抛出异常的方式确实不错，但在同时接多个异常时，会造成单行代码过长的问题（其实也不是问题，可以通过改造管理器类传入错误类列表改善）。 不过还是把作者写的 demo 转过来： class raise_api_error: \"\"\"captures specified exception and raise ApiErrorCode instead :raises: AttributeError if code_name is not valid \"\"\" def __init__(self, captures, code_name): self.captures = captures self.code = getattr(error_codes, code_name) def __enter__(self): # 方法将在刚进入上下文时调用 return self def __exit__(self, exc_type, exc_val, exc_tb): # 该方法将在退出上下文时调用 # exc_type, exc_val, exc_tb 分别表示该上下文内抛出的 # 异常类型、异常值、错误栈 if exc_type is None: return False if exc_type == self.captures: raise self.code from exc_val return False 参考链接 one-python-craftsman/6-three-rituals-of-exceptions-handling.md at master · piglei/one-python-craftsman 文章版权归原作者所有。 ","date":"2019-03-14","objectID":"/posts/4215f/:0:0","tags":[],"title":"Python异常处理的优秀实践","uri":"/posts/4215f/"},{"categories":["Web 开发"],"content":"LDAP 概述 LDAP 数据结构为树形结构； LDAP 读性能很好，但写性能很差； LDAP 是一种开放 Internet 标准，LDAP 协议是跨平台的 Internet 协议 LDAP 基本概念 ","date":"2019-03-14","objectID":"/posts/a000b/:0:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"Entry 条目，也叫记录项，是 LDAP 中最基本的颗粒。 DN = Distinguished Name 唯一标识名，例如 cn=baby,ou=marketing,dc=mydomain,dc=org RDN 相对唯一标识名，如 cn=baby Base DN 目录树的最顶部，即根，如 dc=mydomain,dc=org DC = Domain Componen OU = Organization Unit 组织单元，单位（部门）名称 CN = Common Name 通用名 UID = User ID O = Organization 组织 C = Country 国家名 ","date":"2019-03-14","objectID":"/posts/a000b/:1:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"ObjectClass ","date":"2019-03-14","objectID":"/posts/a000b/:2:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"定义 对象类是属性的集合，LDAP 内置了很多人员机构中常见的对象。比如人员（person）含有姓（sn）、名（cn）、电话(telephoneNumber)、密码(userPassword)等属性，单位职工(organizationalPerson)是人员(person)的继承类，除了上述属性之外还含有职务（title）、邮政编码（postalCode）、通信地址(postalAddress)等属性。 ","date":"2019-03-14","objectID":"/posts/a000b/:2:1","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"作用 通过对象类可以方便的定义条目类型。每个条目可以继承多个对象类，就能拥有不同的属性。 ","date":"2019-03-14","objectID":"/posts/a000b/:2:2","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"分类 对象类分为三种：结构类型（Structural）、抽象类型(Abstract)和辅助类型（Auxiliary）： 结构类型规定了对象实体的基本属性，每个条目属于且仅属于一个结构型对象类， 抽象类型可以是结构类型或其他抽象类型父类，它将对象属性中共性的部分组织在一起，称为其他类的模板，条目不能直接集成抽象型对象类。 辅助类型规定了对象实体的扩展属性。 ","date":"2019-03-14","objectID":"/posts/a000b/:3:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"Schema 对象类（ObjectClass）、属性类型（AttributeType）、语法（Syntax）分别约定了条目、属性和值，他们之间的关系如下图所示。所有这些构成了模式(Schema)，即对象类的集合。 搭建 LDAP 测试服务器 使用 docker 安装 OpenLDAP 和 LAM(LDAP Account Manager)。 ","date":"2019-03-14","objectID":"/posts/a000b/:4:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"创建测试网络 docker network create --subnet=172.18.0.0/24 ldap ","date":"2019-03-14","objectID":"/posts/a000b/:5:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"搭建 OpenLDAP 服务 docker run -p 127.0.0.1:389:389 -p 127.0.0.1:636:636 \\ --env LDAP_ORGANISATION=\"dota2\" --env LDAP_DOMAIN=\"dota2.com\" \\ --env LDAP_ADMIN_PASSWORD=\"admin@123\" \\ --name ldap \\ --network ldap \\ --ip 172.18.0.2 \\ -d osixia/openldap ","date":"2019-03-14","objectID":"/posts/a000b/:6:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"搭建 LAM 服务 docker run -p 127.0.0.1:1810:80 \\ --name lam \\ --ip 172.18.0.3 \\ --network ldap \\ -d ldapaccountmanager/lam ","date":"2019-03-14","objectID":"/posts/a000b/:7:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"LAM 配置 打开 http://localhost:1810，在右上角点击 “configuration LAM configuration”，进行配置。默认登录密码为 lam。 在 General Settings 中： Server Settings：修改服务器地址为 ldap://172.18.0.2:389，修改 Tree suffix 为 dc=dota2,dc=com。 Security Settings：修改管理员用户 DN 为 cn=admin,dc=dota2,dc=com； 在 Active Types 中： 配置各 account 的 LDAP suffix 中的 dc 为上述 dc，保留 ou 不变； 保存后，回到主页面登录，使用搭建 OpenLDAP 服务时设置的管理员密码 admin@123 登录； 简单的 LDAP 登录集成 使用 admin 用户建立 LDAP 服务器的连接； 根据用户 ID 或 email 在指定搜索域中查找用户 DN； 校验用户的凭据； ","date":"2019-03-14","objectID":"/posts/a000b/:8:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Web 开发"],"content":"Python 使用 ldap3 库，ldap3 库是纯 Python 实现，没有依赖，另一个库 python-ldap 需要依赖系统安装 OpenLDAP client。 demo 代码如下： # coding=utf-8 from ldap3 import Connection, Server from ldap3.core.exceptions import LDAPBindError LDAP_SERVER = 'localhost' LDAP_PORT = 389 USE_SSL = False ADMIN_DN = 'cn=admin,dc=dota2,dc=com' ADMIN_PASSWORD = 'admin@123' SEARCH_DOMAIN = 'ou=dev,dc=dota2,dc=com' def login_user(usermail, password): server = Server(LDAP_SERVER, LDAP_PORT, USE_SSL) # search with Connection(server, ADMIN_DN, ADMIN_PASSWORD, auto_bind=True) as conn: found = conn.search( SEARCH_DOMAIN, f'(mail={usermail})', attributes=['cn', 'telephoneNumber'], ) if not found: return False entry = conn.entries[0] # verify try: with Connection(server, entry.entry_dn, password, auto_bind=True) as conn: pass except LDAPBindError: return False entry_data = entry.entry_attributes_as_dict return { 'username': entry_data['cn'][0] if entry_data['cn'] else None, 'phone': entry_data['telephoneNumber'][0] if entry_data['telephoneNumber'] else None, 'email': usermail, } if __name__ == \"__main__\": assert login_user('invoker@dota2.com', 'test') is True assert login_user('jugg@dota2.com', 'test123') is False 参考链接 LDAP服务器的概念和原理简单介绍 - Sean’s Notes - SegmentFault 思否 ldap3’s documentation 轻型目录访问协议 - 维基百科，自由的百科全书 ","date":"2019-03-14","objectID":"/posts/a000b/:9:0","tags":[],"title":"集成LDAP登录","uri":"/posts/a000b/"},{"categories":["Infrastructure"],"content":"DNS（Domain Name System，域名系统）是互联网的一项服务，提供根据域名查询 IP 地址，默认使用 TCP 和 UDP 的 53 端口。 当前，对于每一级域名长度的限制是63个字符，域名总长度则不能超过253个字符。 DNS 域名层级 早期在浏览器里输入域名时，必须在末尾加一个 .，因为所有的域名尾部，实际上都有一个根域名 root。例如 www.example.com 的真正域名是 www.example.com.root，简写为 www.example.com。因为，根域名 .root 对于所有域名都一样，所以平时是省略的。 根域名的下一级，称为 “顶级域名”（top-level domain，缩写为TLD），例如 .com； 再下一级叫做 “次级域名”（second-level domain，缩写为SLD），我们注册的一般都是 SLD； 再下一级是 “主机名”（host），又称为 “三级域名”。 DNS 分级查询 DNS 服务器根据域名的层级，进行分级查询。每一级域名都有自己的 NS 记录（NS 记录定义见下文），NS记录指向该级域名的域名服务器，这些服务器知道下一级域名的各种记录。 所谓”分级查询”，就是从根域名开始，依次查询每一级域名的 NS 记录，直到查到最终的 IP 地址，过程大致如下。 从”根域名服务器”查到 TLD 的 NS 记录和 A 记录（IP 地址） 从 TLD 查到 SLD 的 NS 记录和 A 记录（IP地址） 从 SLD 查出 host 的 IP 地址 目前，世界上一共有十三组根域名服务器，从 A.ROOT-SERVERS.NET 一直到 M.ROOT-SERVERS.NET。 DNS 的记录类型 域名与 IP 地址间的对应关系，称为“记录”（record）。根据使用场景，”记录”可以分成不同的类型（type）。 常见的 DNS 记录类型有： A 地址记录（Address），返回域名指向的 IP 地址； AAAA 与A记录对应，指向 IPV6 地址； NS 域名服务器记录（Name Server），返回保存下一级域名信息的服务器地址。该记录只能设置为域名，不能设置为IP地址。 MX 邮件记录（Mail eXchange），返回接收电子邮件的服务器地址。 CNAME 规范名称记录（Canonical Name），CNAME记录用于将某个别名指向到某个 A 记录上，返回该 A 记录域名。 PTR 逆向查询记录（Pointer Record），用于从 IP 地址查询域名，用于反垃圾邮件（验证发送邮件的 IP 地址是否真的有它所声称的域名）等； 由于 CNAME 记录就是一个替换，所以域名一旦设置 CNAME 记录以后，就不能再设置其他记录了（比如 A 记录和 MX 记录），这是为了防止产生冲突。 dig 命令 ","date":"2019-03-14","objectID":"/posts/af3ff/:0:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"查询域名 dig math.stackexchange.com 查询结果会输出六段信息。 第一部分是查询参数和统计 ; \u003c\u003c\u003e\u003e DiG 9.10.6 \u003c\u003c\u003e\u003e math.stackexchange.com ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 31393 ;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 0 第二部分是查询内容： ;; QUESTION SECTION: ;math.stackexchange.com. IN A 第三部分是 DNS 服务器的答复： ;; ANSWER SECTION: math.stackexchange.com. 300 IN A 151.101.193.69 math.stackexchange.com. 300 IN A 151.101.1.69 math.stackexchange.com. 300 IN A 151.101.129.69 math.stackexchange.com. 300 IN A 151.101.65.69 第四部分是域名的 NS 记录（MacOS 上的 dig 命令可能没有这部分） ;; AUTHORITY SECTION: stackexchange.com. 172800 IN NS ns-cloud-d1.googledomains.com. stackexchange.com. 172800 IN NS ns-cloud-d2.googledomains.com. stackexchange.com. 172800 IN NS ns-925.awsdns-51.net. stackexchange.com. 172800 IN NS ns-1029.awsdns-00.org. 第五部分是第四部分中域名服务器的 IP 地址 ;; ADDITIONAL SECTION: ns-925.awsdns-51.net. 139523 IN A 205.251.195.157 ns-1029.awsdns-00.org. 134932 IN A 205.251.196.5 ns-cloud-d1.googledomains.com. 305123 IN A 216.239.32.109 ns-cloud-d2.googledomains.com. 205394 IN A 216.239.34.109 第六部分是 DNS 的一些传输信息 ;; Query time: 383 msec ;; SERVER: 192.168.0.3#53(192.168.0.3) ;; WHEN: Thu Mar 14 13:02:36 CST 2019 ;; MSG SIZE rcvd: 314 ","date":"2019-03-14","objectID":"/posts/af3ff/:1:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"简化输出 dig +short math.stackexchange.com ","date":"2019-03-14","objectID":"/posts/af3ff/:2:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"显示 DNS 分级查询 可以显示DNS的整个分级查询过程。 dig +trace math.stackexchange.com ","date":"2019-03-14","objectID":"/posts/af3ff/:3:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"指定 DNS 服务器 dig @8.8.8.8 stackexchange.com ","date":"2019-03-14","objectID":"/posts/af3ff/:4:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"查询域名 NS 记录 dig ns com ","date":"2019-03-14","objectID":"/posts/af3ff/:5:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"查询 PTR 记录 dig -X 192.30.252.153 其他 DNS 工具 ","date":"2019-03-14","objectID":"/posts/af3ff/:6:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"host host 命令可以看作dig 命令的简化版本，返回当前请求域名的各种记录。 $ host github.com github.com has address 52.74.223.119 github.com has address 13.229.188.59 github.com has address 13.250.177.223 github.com mail is handled by 5 alt2.aspmx.l.google.com. github.com mail is handled by 10 alt3.aspmx.l.google.com. github.com mail is handled by 10 alt4.aspmx.l.google.com. github.com mail is handled by 1 aspmx.l.google.com. github.com mail is handled by 5 alt1.aspmx.l.google.com. 也可以用于逆向查询 IP 地址，等同于 dig -x \u003cip\u003e。 ","date":"2019-03-14","objectID":"/posts/af3ff/:7:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"whois 查询域名的 whois 信息，很多域名现在都有隐私保护了，只能查到注册商信息。 ","date":"2019-03-14","objectID":"/posts/af3ff/:8:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["Infrastructure"],"content":"nslookup 用于互动式地查询域名记录。 参考链接 域名系统 - 维基百科，自由的百科全书 DNS 原理入门 - 阮一峰的网络日志 ","date":"2019-03-14","objectID":"/posts/af3ff/:9:0","tags":[],"title":"DNS服务原理入门","uri":"/posts/af3ff/"},{"categories":["数学与算法"],"content":"第一章：0 的故事 ","date":"2019-02-06","objectID":"/posts/90a86/:0:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"计数法 计数法分为两类： 按位计数法：按位计数法表示的数字每一位权重不同，例如我们常用的二进制、八进制、十进制和十六进制计数法； 其他：比如罗马数字计数法，数位没有权重，罗马数字的值是所有数位值的和。 按位计数法更有效率，有限的数字能表示更大的数值。 ","date":"2019-02-06","objectID":"/posts/90a86/:1:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"指数法则 N**a * N**b = N**(a+b) 第二章：逻辑 ","date":"2019-02-06","objectID":"/posts/90a86/:2:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"常用逻辑 逻辑非 ¬； 逻辑与 ∩； 逻辑或 ∪； 逻辑异或 ⊕； 逻辑相等（同或）=； 逻辑蕴含 ⟹； 逻辑蕴含的真值表如下，即只要前提条件 A 为 false，则不论 B 的真假，“若 A 则 B”的值恒为 true。 A B A ⟹ B true true true true false false false true true false false true ","date":"2019-02-06","objectID":"/posts/90a86/:3:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"逻辑的表达方式 逻辑的几种表达方式： 逻辑表达式； 真值表； 文氏图（韦恩图）； 卡诺图； ","date":"2019-02-06","objectID":"/posts/90a86/:4:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"如何解决逻辑问题 由复杂的规则（现实）生成逻辑表达式（抽象）； 通过卡诺图、德·摩根定律等，简化逻辑表达式； 将简化的逻辑表达式（抽象）还原为简单的规则（现实）； ","date":"2019-02-06","objectID":"/posts/90a86/:5:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"未定义逻辑 三值逻辑包含 true、false 和 undefined。计算时采用优先运算原则。 逻辑与： A 为 true 时，看 B； A 为 false 时，恒为 false； A 为 undefined 时，恒为 undefined； 逻辑或： A 为 true 时，恒为 true； A 为 false 时，看 B； A 为 undefined 时，恒为 undefined； 逻辑非： 值为 undefined 时，逻辑非也为 undefined； 第三章：余数 ","date":"2019-02-06","objectID":"/posts/90a86/:6:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"余数的作用 余数可以用来解决周期性和奇偶性的问题。 主要作用： 利用周期性和奇偶性简化计算，例如 10**N 天后星期数具有 1-3-2-6-4-5 循环的规律。 用于奇偶校验； ","date":"2019-02-06","objectID":"/posts/90a86/:7:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"草席问题 在一个 8x8 的房间中，缺失左上角和右下角，问使用 1x2 的草席能够把房间铺满吗？ 将整个房间看做一个棋盘，间隔涂上黑白两色，一张 1x2 的草席可以认为是由一个黑色块和一个白色块组成。 计算得到，黑色块和白色块数量并不相等，因此 1x2 的草席不能够将房间铺满。 注意，反过来讲，假设黑色块和白色块数量相等，也不一定能够铺满整个房间。 ","date":"2019-02-06","objectID":"/posts/90a86/:8:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"柯尼斯堡七桥问题 问题详情见维基，类似的还有一笔画问题等。 使用图论，能够不重复走完全程（能够一笔画完）的条件为： 要么起点和终点相同，此时要求所有节点都是偶点； 要么起点和终点不同，此时要求有且只有两个奇点，其他都为偶点。 柯尼斯堡七桥问题中，共有 4 个顶点，度数分别为 3、5、3、3，不满足以上的条件，在给定条件下不能走完全程。 第四章 数学归纳法 数学归纳法用于证明 “对于 0 以上的所有整数 n 都成立的断言”。 ","date":"2019-02-06","objectID":"/posts/90a86/:9:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"证明数学归纳法 数学归纳法证明的步骤： 证明 p(0) 成立； 证明无论 k 为 0 以上的任何整数，若 p(k) 成立，则 p(k+1) 成立。 ","date":"2019-02-06","objectID":"/posts/90a86/:10:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"循环不变式 在编写循环时，每次循环时都成立的逻辑表达式称为循环不变式。 编写循环时，有两个注意点：“达到目的” 和 “适时结束循环”。 第五章：排列组合 处理排列组合问题时，要注意 “遗漏” 和 “重复”。 排列和组合的区别是，排列需要考虑顺序，组合不考虑顺序。 ","date":"2019-02-06","objectID":"/posts/90a86/:11:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"排列组合的几个法则 加法法则：当两个集合中没有重复元素的时候，适用加法法则 |A∪B| = |A| + |B|； 容斥原理：|A∪B| = |A| + |B| - |A∩B|； 乘法法则：当两个集合的维度性质不同时，适用乘法法则 |AxB| = |A| x |B|； ","date":"2019-02-06","objectID":"/posts/90a86/:12:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"排列 置换：集合中（n 个元素）所有元素进行排列，公式为 n!； 排列：从 n 个元素中取 m 个元素进行排列，公式为 P(n, m)； 可以看出，置换是 m = n 时排列的特殊情况。 可以通过树形图进行辅助排列。 ","date":"2019-02-06","objectID":"/posts/90a86/:13:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"组合 从 n 个元素中取 m 个元素进行组合，公式 C(n, m)。 ","date":"2019-02-06","objectID":"/posts/90a86/:14:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"排列与组合的关系 M 的置换 x N 取 M 的组合 = N 取 M 的排列 ","date":"2019-02-06","objectID":"/posts/90a86/:15:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"重复组合问题 有 A、B 和 C 三种药品，共取 100 粒，可重复，每种至少 1 粒，共有多少种组合？ 组合很明显不考虑顺序，可以认为是在 100 个盘子中间插入 2 个隔板，将盘子分为 A、B 和 C 共 3 组， 所以共有 C(99, 2) 种组合。 排列有重复时可以先正常求解，最后除以重复度。也要善于使用逻辑进行求解。 第六章：递归 求解递归问题的方法： 找出递归结构； 建立递推公式； ","date":"2019-02-06","objectID":"/posts/90a86/:16:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"斐波那契数列 一些问题可以使用斐波那契数列解决，注意初始值的取值。 ","date":"2019-02-06","objectID":"/posts/90a86/:17:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"摆砖头 将 1x2 的砖头摆放成纵长为 2，横长为 n 的长方形阵列，请问摆法有多少种。 分为两种情况： 左边竖立放置 1 块砖头时，右边砖头 n-1 块摆成 n-1 的长度； 左边横叠放置 2 块砖头时，右边砖头 n-2 块摆成 n-2 的长度； 即 F(n) = F(n-1) + F(n-2) ","date":"2019-02-06","objectID":"/posts/90a86/:17:1","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"其他类似问题 使用 4 分音符和 2 分音符创作旋律，在 4分音符打 n 拍的时间内，可以创作出多少种旋律。 一次走 1 阶或 2 阶台阶，爬 n 层台阶共有多少种方法。 ","date":"2019-02-06","objectID":"/posts/90a86/:17:2","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"杨辉三角 杨辉三角又称帕斯卡三角，该三角形的第 n 行第 m 个元素的值即是 C(n, m) 的值（从 0 开始）。 另外从杨辉三角可以得出： C(n, k) = C(n-1, k-1) + C(n-1, k) 可以从两种角度看： 从起点到终点的线路数量； 根据杨辉三角定义得出； ","date":"2019-02-06","objectID":"/posts/90a86/:18:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"递归图形 分形图，谢尔平斯基三角形（用颜色区分杨辉三角形中的奇数和偶数即可得到）。 ","date":"2019-02-06","objectID":"/posts/90a86/:19:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"如何寻找递归结构 从整体问题中隐去部分问题； 判断剩余部分是否和整体问题是同一类问题； 第七章：指数爆炸 指数增长是迅猛的，二分法是利用了指数爆炸的一种有效查找方法。 ","date":"2019-02-06","objectID":"/posts/90a86/:20:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"对数 对数图表：帮助把握指数爆炸发生时的增长情况； 通过对数用加法实现乘法： log(a*b, 10) = log(a, 10) + log(b, 10) 计算尺：使用对数进行乘法运算的工具。 等间距计算尺：指数相加； 非等间距计算尺：直接相乘。 ","date":"2019-02-06","objectID":"/posts/90a86/:21:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"密码 利用指数爆炸原理保护密码，使密码不能在现实时间内被暴力破解。 ","date":"2019-02-06","objectID":"/posts/90a86/:22:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"如何求解指数爆炸问题 极力求解：通过增强计算机性能，通过暴力方式求解； 变相求解：转换为简单问题，如柯尼斯堡七桥问题中，不需要列举出所有的线路，转而通过图论求解； 近似求解 概率求解 第八章：不可解问题 ","date":"2019-02-06","objectID":"/posts/90a86/:23:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"反证法 又称归谬法，分为两步： 首先假设命题的否定形式成立； 根据假设进行论证，推导出矛盾的结果； 注意，第二步中论证过程本身必须正确。 ","date":"2019-02-06","objectID":"/posts/90a86/:24:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"可数 “集合的元素是有限的，或者集合中的所有元素都与正整数一一对应” 时，这个集合就被定义为可数。 称为 countable 或 enumerable。 集合中所有元素都与正整数一一对应，即是元素可按一定规律既无遗漏也无重复地数出来。 ","date":"2019-02-06","objectID":"/posts/90a86/:25:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"可数集合举例 有限集合（满足集合中元素是有限的）； 0 以上的所有偶数的集合（满足一一对应）； 所有整数的集合（正负数交替编号，满足一一对应）； 所有有理数的集合（满足一一对应）； 程序的集合是可数的（编写程序的字符是有限的，其生成的排列组合有限）； 所有有理数的集合是可数的，是因为所有有理数都可以写成分数的形式，可以按照一定规律用正整数给它们编号。 ","date":"2019-02-06","objectID":"/posts/90a86/:25:1","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"不可数集合举例 所有实数的集合； 所有整数数列的集合； 所有函数的集合； ","date":"2019-02-06","objectID":"/posts/90a86/:25:2","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"对角论证法 采用反证法论证“所有整数数列的集合是不可数的”。 假设所有整数数列集合是可数的； 列一张表列出所有整数数列，该表为二维整数表； 取二维表左上角至右下角的对角线元素，组成新数列； 新数列不在表中，与表为所有整数数列的集合相矛盾； 第 3 步中取对角线元素来证明命题的方法，称为对角论证法。 ","date":"2019-02-06","objectID":"/posts/90a86/:26:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"不可解问题 不可解问题即是原则上不能用程序来解决的问题，也即是不包含在 “程序可解决问题” 集合中的问题。 不能写成程序的函数是存在的。 ","date":"2019-02-06","objectID":"/posts/90a86/:27:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["数学与算法"],"content":"停机问题 停机问题：判断某程序在给定数据下，是否会在有限时间内结束运行。 停机问题无解，可以通过反证法证明。 ","date":"2019-02-06","objectID":"/posts/90a86/:28:0","tags":[],"title":"《程序员的数学1》笔记","uri":"/posts/90a86/"},{"categories":["Python"],"content":"datetime.datetime.astimezone(tz=None) 返回一个使用新时区地方时的 datetime 对象。 from datetime import datetime, timezone, timedelta cst_zone = timezone(timedelta(hours=8)) cst_dt = datetime(2018, 12, 20, 8, 0, 0, tzinfo=cst_zone) utc_dt = cst_dt.astimezone(timezone.utc) utc_dt # datetime.datetime(2018, 12, 20, 0, 0, tzinfo=datetime.timezone.utc) os.path.realpath 返回不含有符号链接的文件的绝对路径。 例如在当前目录中，b 软链接到 a。 $ touch a $ ln -s a b $ ls -l -rw-r--r-- 1 chi staff 0B Dec 19 14:27 a lrwxr-xr-x 1 chi staff 1B Dec 19 14:27 b -\u003e a 与 abspath 对比： import os p = './b' r1 = os.path.realpath(p) r2 = os.path.abspath(p) # r1 /Users/chi/Projects/just4test/a # r2 /Users/chi/Projects/just4test/b raise exc from exc 一般用在 try...except... 的 except 中重新抛出错误。使用 from 会让两个错误信息中间提示不同： 不使用 from 时： During handling of the above exception, another exception occurred: 使用 from 时： The above exception was the direct cause of the following exception: pytz pytz Asia/Shanghai 时间差定义为 8 小时 6 分钟，不正确的使用会造成时间转换错误。例如： import pytz from datetime import datetime utc = pytz.timezone('UTC') # UTC shanghai = pytz.timezone('Asia/Shanghai') # \u003cDstTzInfo 'Asia/Shanghai' LMT+8:06:00 STD\u003e datetime(2019, 1, 1, 8, 0, 0, tzinfo=shanghai).astimezone(utc) # datetime.datetime(2018, 12, 31, 23, 54, tzinfo=\u003cUTC\u003e) datetime(2019, 1, 1, 0, 0, 0, tzinfo=utc).astimezone(shanghai) # datetime.datetime(2019, 1, 1, 8, 0, tzinfo=\u003cDstTzInfo 'Asia/Shanghai' CST+8:00:00 STD\u003e) os.path.expanduser(path) 在 Windows 和 Unix 系统中，将 ~ 开头的字符串路径转换为绝对路径。 import os os.path.expanduser('~') # '/home/invoker' unittest 中的 setUp 和 tearDown unitest 标准库中有三种级别的 setUp 和 tearDown： setUp() 和 tearDown() 实例方法，在每个测试方法运行前后调用； setUpClass() 和 tearDownClass() 类方法，在测试类所有方法运行前后调用一次； setUpModule() 和 tearDownModule() 函数，在模块中所有测试方法运行前后调用一次； 举个例子： # main.py from unittest import TestCase def setUpModule(): print('setUpModule') def tearDownModule(): print('tearDownModule') class TestA(TestCase): @classmethod def setUpClass(cls): print('TestA-\u003esetUpClass') @classmethod def tearDownClass(cls): print('TestA-\u003etearDownClass') def setUp(self): print('TestA-\u003esetUp') def tearDown(self): print('TestA-\u003etearDown') def test_method_a(self): print('TestA-\u003etest_method_a') def test_method_b(self): print('TestA-\u003etest_method_b') class TestB(TestCase): def test_method_c(self): print('TestB-\u003etest_method_c') 运行结果为： $ python -m unittest -q main.py setUpModule TestA-\u003esetUpClass TestA-\u003esetUp TestA-\u003etest_method_a TestA-\u003etearDown TestA-\u003esetUp TestA-\u003etest_method_b TestA-\u003etearDown TestA-\u003etearDownClass TestB-\u003etest_method_c tearDownModule ---------------------------------------------------------------------- Ran 3 tests in 0.000s OK ","date":"2019-02-02","objectID":"/posts/f6833/:0:0","tags":[],"title":"一些Python小技巧","uri":"/posts/f6833/"},{"categories":["Infrastructure"],"content":"deb 是 Debian 软件包格式，文件扩展名为 .deb，在 Debian 和 Ubuntu 中广泛使用。将应用打包成 deb 软件包可以方便分发、安装和卸载，提供更好的用户体验。 如果安装时文件已存在，不会覆盖原文件。 Debian 软件包结构 deb 包中主要包括三部分： debian-binary 二进制数据，包括格式版本号码等； control.tar.gz 元数据，包括对 deb 包的描述、脚本等； data.tar.* 实际安装的内容 其中，\"*“所指代的内容随压缩算法不同而不同。常见的可能值为xz、gz、或bz2。有时也会使用lzma。 打包目录结构 在 Ubuntu 或者 Debian 系统中，创建一个打包目录，按照要求放入内容，使用 dpkg -i 命令打包。 一个打包目录的示例结构如下： . ├── DEBIAN │ ├── changlog │ ├── conffiles │ ├── control │ ├── copyright │ ├── postinst │ ├── postrm │ ├── preinst │ ├── prerm │ └── postrm ├── lib │ └── systemd │ └── system │ ├── backend.service 其中： DEBIAN 目录存放 deb 包的描述和脚本等元数据，其内容最后会形成 control.tar.gz； 其他目录为具体安装目录（相对于安装时根目录而言）。举例来说，该目录下的 lib/systemd/system/backend.service 文件在安装 deb 包时会被复制到系统 /lib/systemd/system/ 目录中，并保留原文件的权限和属组。 DEBIAN 目录文件介绍 ","date":"2019-02-02","objectID":"/posts/e2e73/:0:0","tags":[],"title":"制作deb包","uri":"/posts/e2e73/"},{"categories":["Infrastructure"],"content":"control control 文件用于描述 deb 包信息，举例如下： Package: hello-world Version: 1.0 Architecture: amd64 Maintainer: Jack Ma \u003cemail@example.com\u003e Installed-Size: Pre-Depends: Depends: Recommends: Suggests: Section: devel Priority: optional Multi-Arch: foreign Homepage: www.yunify.com Description: hello world, man. 对一些属性的说明： Architecture：硬件架构平台，可选值 i386、amd64、m68k、sparc、alpha 和 powerpc 等； Pre-Depends：软件安装前必须安装、配置依赖性的软件包和库文件，它常常用于必须的预运行脚本需求； Depends：软件所依赖的其他软件包和库文件。如果是依赖多个软件包和库文件，彼此之间采用逗号隔开； Priority：申明软件对于系统的重要程度，如 required、standard、optional、extra 等； 另外，control 文件末尾要有一个空行。 ","date":"2019-02-02","objectID":"/posts/e2e73/:1:0","tags":[],"title":"制作deb包","uri":"/posts/e2e73/"},{"categories":["Infrastructure"],"content":"脚本文件 在 DEBIAN 目录中有四个 shell 脚本文件，分别在包安装和卸载的不同时刻运行： preinst 在 deb 包实际内容安装前运行； postinst 在 deb 包实际内容安装后运行； prerm 在 deb 包实际内容删除前运行； postrm 在 deb 包实际内容删除后运行； 比如安装一个安装后自动运行的软件包，可以在 preinst 中检查安装目录并清理旧文件，在 postinst 中启动服务，在 prerm 中停止服务，在 postrm 中清理日志文件。 ","date":"2019-02-02","objectID":"/posts/e2e73/:2:0","tags":[],"title":"制作deb包","uri":"/posts/e2e73/"},{"categories":["Infrastructure"],"content":"其他文件 copyright 版权信息； changlog 修订记录； 打包命令 dpkg -b \u003c打包目录\u003e hello-world-1.0.deb 安装和卸载 dpkg -i hello-world-1.0.deb dpkg -p hello-world 参考链接 deb - 维基百科，自由的百科全书 dpkg制作deb包 - 新月时刻 - 博客园 Ubuntu下制作deb包的方法详解 - AderStep - CSDN博客 ","date":"2019-02-02","objectID":"/posts/e2e73/:3:0","tags":[],"title":"制作deb包","uri":"/posts/e2e73/"},{"categories":["Web 开发"],"content":"什么是 JSON Schema JSON Schema 是基于 JSON 语法，用来描述 JSON 数据格式的一种规范。可以数据校验、生成接口文档，生成模拟数据等多种用途。 本质上，JSON 是由以下几种基本的数据结构组成的： 对象 objects 数组 array 数字 number 字符串 string 布尔值 boolean null JSON Schema 对这些类型都做了规定。同时，JSON Schema 的规范也在不断的迭代更新，下文讲解基于 Draft 4。 公共属性 ","date":"2019-02-01","objectID":"/posts/1fd99/:0:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"常用 type 定义数据类型； enum 定义可取值列表； default 定义默认值，默认值虽然有定义，但是不强制要求实现； ","date":"2019-02-01","objectID":"/posts/1fd99/:1:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"元数据 title 标题（可选） description 描述（可选） $schema 声明这是一个 schema，值一般为 http://json-schema.org/schema#，也可以为一个指向官网草案版本的链接，例如：http://json-schema.org/draft-06/schema# ","date":"2019-02-01","objectID":"/posts/1fd99/:2:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"组合验证属性 anyOf 传一个 schema 列表，只要满足其中一个就验证通过。 allOf 传一个 schema 列表，必须满足其中全部才能验证通过。 oneOf 传一个 schema 列表，仅仅满足其中一个时才验证通过。 not 传一个 schema，不满足时会验证通过。 验证 ","date":"2019-02-01","objectID":"/posts/1fd99/:3:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"验证 all 当 JSON Schema 为空时，任意内容都能通过验证 { } ","date":"2019-02-01","objectID":"/posts/1fd99/:4:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"验证 string {\"type\": \"string\"} 附加参数有： minLength 规定最小长度 maxLength 规定最大长度 pattern 正则表达式，建议使用 ^…$ 进行整行匹配； format 草案中规定的一些内置的格式，不强制要求实现； ","date":"2019-02-01","objectID":"/posts/1fd99/:5:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"验证 number number 有两种细分类型： integer 和 number ","date":"2019-02-01","objectID":"/posts/1fd99/:6:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"integer 用于验证整型 {\"type\": \"integer\"} ","date":"2019-02-01","objectID":"/posts/1fd99/:6:1","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"number {\"type\": \"number\"} 附加参数有： multipleOf 被验证值必须是该值的倍数，该值必须是正数。 minimum 最小值 exclusiveMinimum 传 bool 参数，最小值是否不包含边界值，默认包含，即 false maximum 最大值 exclusiveMaximum 传 bool 参数，最大值是否不包含边界值，默认包含，即 false 边界值参数 Draft 6 和 Draft 4 有很大不同。 ","date":"2019-02-01","objectID":"/posts/1fd99/:6:2","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"验证 object { \"type\": \"object\", \"properties\": { \"name\": {\"type\": \"string\"}, \"age\": {\"type\": \"integer\"}, \"gender\": { \"type\": \"string\", \"enum\": [\"male\", \"female\"] } } } **默认情况下，object 中不传某个属性或者多传某个属性都能够验证通过。**因此上述 Schema 对 {} 也能验证通过。 附加参数： properties 定义属性 additionalProperties True：允许附加属性 False：不允许附加属性 object：规定附加属性验证，例如 \"additionalProperties\": { \"type\": \"string\" } 规定附加属性必须是字符串。 required 一个元素唯一的非空列表（Draft 6 允许为空），规定必传参数； minProperties maxProperties dependencies 属性依赖，例如 \"dependencies\": {\"credit_card\": [\"billing_address\"]}表示，拥有 credit_card 属性时必须拥有 billing_address 属性； Schema 依赖，能够定义依赖变量的类型等，相当于内嵌 schema。 patternProperties 使用正则定义的属性列表。可以与 additionalProperties 配合使用，additionalProperties 只定义不希望被正则匹配的属性。 一个 Schema 依赖的例子： { \"type\": \"object\", \"properties\": { \"credit_card\": {\"type\": \"number\"}, \"name\": {\"type\": \"string\"} }, \"dependencies\": { \"credit_card\": { \"properties\": { \"billing_address\": {\"type\": \"string\"} }, \"required\": [\"billing_address\"] } }, \"required\": [\"name\"] } 一个 patternProperties 的例子： { \"additionalProperties\": false, \"patternProperties\": { \"^I_\": {\"type\": \"integer\"}, \"^S_\": {\"type\": \"string\"} }, \"type\": \"object\" } ","date":"2019-02-01","objectID":"/posts/1fd99/:7:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"验证 array {\"type\": \"array\"} 附加参数： items 用于 List validation 时值为 schema，所有元素都要满足验证条件，例如 'items': {‘type': 'number'} 要求所有元素都是数字类型； 用于 Tuple validation 时值为 schema 组成的列表，根据元素顺序依次验证每个元素，可以少传或者多传元素都能验证通过； additionalItems 在 Tuple validation 时可以定义额外元素的验证。 minItems maxItems uniqueItems 元素是否唯一 ","date":"2019-02-01","objectID":"/posts/1fd99/:8:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"验证 boolean {\"type\": \"boolean\"} 0 和 1，字符串 “True” 和 “False” 都不能验证通过。 ","date":"2019-02-01","objectID":"/posts/1fd99/:9:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"验证 null {\"type\": \"null\"} 复杂结构 ","date":"2019-02-01","objectID":"/posts/1fd99/:10:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"Reuse 使用 $ref 可以在一个 schema 中引用另一个 schema，这样可以定义部分公共 schema，其他 schema 重用这部分公共 schema 即可，避免重复定义。 举例说明，下面的 schema 在 definitions 中对地址数据进行了描述，在定义其他地址时，可以应用该地址描述。 { \"$schema\": \"http://json-schema.org/draft-04/schema#\", \"definitions\": { \"address\": { \"type\": \"object\", \"properties\": { \"street_address\": { \"type\": \"string\" }, \"city\": { \"type\": \"string\" }, \"state\": { \"type\": \"string\" } }, \"required\": [\"street_address\", \"city\", \"state\"] } }, \"type\": \"object\", \"properties\": { \"billing_address\": {\"$ref\": \"#/definitions/address\"}, \"shipping_address\": {\"$ref\": \"#/definitions/address\"} } } $ref 取值可以是： 同一 JSON Schema 文件中的定义，以 # 开头； 相对路径 URI，例如 definitions.json#/address； 绝对路径 URI； ","date":"2019-02-01","objectID":"/posts/1fd99/:11:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Web 开发"],"content":"递归模式 $ref 元素可用于创建引用自身的递归模式。例如，一个 person 包含的 children 数组，每个 children 也是 person 实例。 但请注意，$ref 相互引用的模式可能会导致解析器中的无限循环，不应该这样做。 { \"$schema\": \"http://json-schema.org/draft-06/schema#\", \"definitions\": { \"person\": { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\" }, \"children\": { \"type\": \"array\", \"items\": { \"$ref\": \"#/definitions/person\" }, \"default\": [] } } } }, \"type\": \"object\", \"properties\": { \"person\": { \"$ref\": \"#/definitions/person\" } } } 参考链接 Understanding JSON Schema — Understanding JSON Schema 6.0 documentation JSON Schema | The home of JSON Schema JSON Schema 介绍及应用 - 腾讯Web前端 IMWeb 团队社区 | blog | 团队博客 JSON Schema 那些事儿：基本概念 | Taobao FED | 淘宝前端团队 ","date":"2019-02-01","objectID":"/posts/1fd99/:12:0","tags":[],"title":"使用JSON Schema进行参数验证","uri":"/posts/1fd99/"},{"categories":["Python"],"content":"简介 pyenv 可以在主机上安装多个 Python 版本并轻松切换。主要特性有： 更改用户的全局 Python 版本； 为单个项目设置不同的 Python 版本； 使用环境变量覆盖 Python 版本设置； 一次从多个 Python 版本中搜索命令，这有助于使用 tox 测试。 安装 pyenv ","date":"2018-12-03","objectID":"/posts/a1719/:0:0","tags":[],"title":"pyenv:Python多版本管理","uri":"/posts/a1719/"},{"categories":["Python"],"content":"brew Mac 用户可以通过 brew 安装： brew update brew install pyenv ","date":"2018-12-03","objectID":"/posts/a1719/:1:0","tags":[],"title":"pyenv:Python多版本管理","uri":"/posts/a1719/"},{"categories":["Python"],"content":"Github Linux 用户可以通过 pyenv-installer 这个项目从 Github 安装： curl -L https://github.com/pyenv/pyenv-installer/raw/master/bin/pyenv-installer | zsh 安装完成后，需要在 shell 配置中添加一些内容。bash 用户添加到 .bashrc，zsh 用户添加到 .zshrc。 # pyenv export PATH=\"/home/chi/.pyenv/bin:$PATH\" eval \"$(pyenv init -)\" eval \"$(pyenv virtualenv-init -)\" 更新 pyenv pyenv update 安装依赖包 pyenv 本身并没有依赖包，但是由于其安装 Python 版本的方式是拉去源代码后本地编译，因此需要安装 Python 编译的依赖包： Ubuntu/Debian sudo apt install -y make build-essential libssl-dev zlib1g-dev libbz2-dev \\ libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \\ xz-utils tk-dev libffi-dev liblzma-dev macOS brew install readline xz 基本操作 查看已安装的 Python 版本 pyenv versions 设置全局 Python 版本 pyenv global 3.7.1 安装指定 Python 版本，如果版本不存在，pyenv 会提示版本号相近的可用版本 pyenv install 3.7 卸载指定 Python 版本 pyenv uninstall 3.7.1 查看指定 Python 版本的安装目录 pyenv prefix 3.7.1 为 shell 指定/取消指定 Python 版本 pyenv shell 3.7.1 pyenv shell --unset 卸载 pyenv 从 shell 配置文件中移除相关内容； 删除 pyenv 目录，一般是 ~/.pyenv； 参考链接 pyenv/pyenv: Simple Python version management pyenv/pyenv-installer: This tool is used to install pyenv and friends. Common build problems - pyenv/pyenv Wiki ","date":"2018-12-03","objectID":"/posts/a1719/:2:0","tags":[],"title":"pyenv:Python多版本管理","uri":"/posts/a1719/"},{"categories":["Infrastructure"],"content":"连接数据库 psql -U \u003cUSERNAME\u003e -d \u003cDBNAME\u003e -h \u003cHOSTNAME\u003e -p \u003cPORT\u003e 默认端口 5432。 psql命令存在简写形式。如果当前Linux系统用户，同时也是PostgreSQL用户，则可以省略用户名，同时也不需要输入密码。 命令行操作 以下命令末尾不需要加分号。 \\h \u003cSQL\u003e 查看 SQL 命令的解释，比如 \\h select； \\? 查看 psql 命令列表； \\l 列出所有数据库； \\c \u003cDBNAME\u003e 连接指定数据库； \\d 列出当前数据库的所有表； \\d \u003cTABLE_NAME\u003e 列出某张表的表结构； \\du 列出所有用户； \\e 打开文本编辑器； \\conninfo 列出当前数据库连接信息； \\passwd \u003cDBUSER\u003e 修改数据库用户密码； \\q 退出命令行。 用户和权限操作 ","date":"2018-11-30","objectID":"/posts/8e9fa/:0:0","tags":[],"title":"PostgreSQL基础操作","uri":"/posts/8e9fa/"},{"categories":["Infrastructure"],"content":"新建用户 CREATE USER dbuser WITH PASSWORD 'password'; ","date":"2018-11-30","objectID":"/posts/8e9fa/:1:0","tags":[],"title":"PostgreSQL基础操作","uri":"/posts/8e9fa/"},{"categories":["Infrastructure"],"content":"分配权限 GRANT ALL PRIVILEGES ON DATABASE dbname to dbuser; 数据库操作 ","date":"2018-11-30","objectID":"/posts/8e9fa/:2:0","tags":[],"title":"PostgreSQL基础操作","uri":"/posts/8e9fa/"},{"categories":["Infrastructure"],"content":"创建数据库 CREATE DATABASE exampledb OWNER dbuser; 表操作 # 创建新表 CREATE TABLE user_tbl(name VARCHAR(20), signup_date DATE); # 重命名表格 ALTER TABLE user_tbl RENAME TO backup_tbl; # 删除表格 DROP TABLE IF EXISTS backup_tbl; # 添加字段 ALTER TABLE user_tbl ADD email VARCHAR(40); # 更新字段 ALTER TABLE user_tbl ALTER COLUMN signup_date SET NOT NULL; # 重命名字段 ALTER TABLE user_tbl RENAME COLUMN signup_date TO signup; # 删除字段 ALTER TABLE user_tbl DROP COLUMN email; 数据（记录）操作 # 插入记录 INSERT INTO user_tbl(name, signup_date) VALUES('张三', '2013-12-22'); # 选择记录 SELECT * FROM user_tbl; # 更新记录 UPDATE user_tbl set name = '李四' WHERE name = '张三'; # 删除记录 DELETE FROM user_tbl WHERE name = '李四' ; ","date":"2018-11-30","objectID":"/posts/8e9fa/:3:0","tags":[],"title":"PostgreSQL基础操作","uri":"/posts/8e9fa/"},{"categories":["Web 开发"],"content":"简介 Let’s Encrypt 是一个免费，自动化和开放的证书颁发机构，由非营利性机构互联网安全研究组（ISRG）驱动。该机构可以为域名颁发免费的 HTTPS 证书，每次证书的有效期为 90 天。 其证书颁发基于 ACME 协议，其中默认使用 ACME v1 协议，泛域名证书需要使用 ACME v2 协议。通过在 Web 服务器上使用支持 ACME 协议的客户端来申请证书。官方推荐使用 Certbot。 安装 Certbot Certbot 是一个 ACME 协议客户端，它能够自动执行证书的颁发和安装，不会中断服务。 访问 Certbot 网站，选择使用的 Web 服务器和操作系统，网站会给出详细的安装指导。这里以在 Ubuntu 18.04 上使用 Nginx 为例。 sudo apt update sudo apt install software-properties-common sudo add-apt-repository ppa: certbot/certbot sudo apt update sudo apt install python-certbot-nginx 签发普通证书 sudo certbot --nginx certonly 或者使用 Certbot 提供的插件自动编辑 Nginx 的配置（不推荐）： sudo certbot --nginx 签发泛域名证书 泛域名证书只能使用 DNS 验证的方式，需要单独安装 dns-plugins。但是目前还没有国内云服务商和 DNS 服务商的 plugin，这里只能手动签发。 sudo certbot certonly \\ -d \"*.example.com\" \\ --manual \\ --preferred-challenges dns \\ --server https://acme-v02.api.letsencrypt.org/directory -d 指定域名； --manual 手动签发； --preferred-challenges 指定验证方式，泛域名只能选择 DNS 验证； --server 指定验证服务器 URL，默认为 ACME v1 协议地址，泛域名使用 ACME v2 协议，需要显式指定； 注意，签发泛域名证书会公开服务器的 IP 地址。 按照要求输入邮箱，同意协议，当看到下面信息时： ------------------------------------------------------------ Please deploy a DNS TXT record under the name _acme-challenge.example.com with the following value: JHkwGFgXq3OgedI-4RU1X0EcFUz7cxIPN7r1Qyw5JTw Before continuing, verify the record is deployed. ------------------------------------------------------------ Press Enter to Continue 暂停操作并在 DNS 服务商处配置 TXT 域名解析，记录为 _acme-challenge.example.com，结果为上述字符串。 使用以下命令在服务器上验证解析生效（一般需要几分钟）： dig -t txt _acme-challenge.example.com 生效后，回到 Certbot 申请中回车继续，即可签发成功。 续签证书 普通证书会自动续签，泛域名证书由于是手动生成的，并不能自动续签。 可以使用下面的命令在到期前 30 天手动续签： sudo certbot renew 重新签发证书 如果因为系统重置等原因，导致证书被删除，可以重新签发证书。 sudo certbot certonly --force-renewal -d example.com 撤销证书 如果证书不再使用，或者密钥被盗，可以撤销证书： sudo certbot revoke --cert-path /etc/letsencrypt/live/CERTNAME/cert.pem 注意两点： 撤销证书时，需要指定证书路径而不是域名； 指定的证书路径以 cert.pem 结尾，而不是证书的实际名称； 证书撤销后，要删除证书，否则还会自动续签： certbot delete --cert-name example.com 参考链接 Certbot Getting Started - Let’s Encrypt Let’s Encrypt泛域名证书 ","date":"2018-11-27","objectID":"/posts/3fad1/:0:0","tags":[],"title":"Let's Encrypt:免费生成HTTPS证书","uri":"/posts/3fad1/"},{"categories":["工欲善其事"],"content":"环境：Ubuntu 16.04.5 LTS。 更新 sudo apt update sudo apt upgrade sudo apt autoremove 安装底层软件 基本软件： sudo apt install git zsh autojump vim htop tree python3-pip pyenv 编译 Python 的依赖 sudo apt install -y build-essential libssl-dev zlib1g-dev libbz2-dev \\ libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \\ xz-utils tk-dev libffi-dev liblzma-dev python-openssl docker 的依赖 sudo apt install apt-transport-https ca-certificates curl gnupg-agent software-properties-common 安装常用 cli 工具 ","date":"2018-11-17","objectID":"/posts/505b5/:0:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"docker 卸载官方源中安装的 docker： sudo apt purge docker docker-engine docker.io containerd runc 添加 docker 维护的源： curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" 安装 docker-ce: sudo apt update sudo apt install docker-ce docker-ce-cli containerd.io 将当前用户添加到 docker 组中： sudo groupadd docker sudo usermod -aG docker $USER ","date":"2018-11-17","objectID":"/posts/505b5/:1:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"oh-my-zsh sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" 配置，编辑 ~/.zshrc 文件： # 以下是修改已经存在的配置 ZSH_THEME=\"agnoster\" plugins=(git autojump docker adb pyenv python) # 新增配置 DEFAULT_USER=\"chi\" export LANG=en_US.UTF-8 export LC_ALL=en_US.UTF-8 # pyenv if command -v pyenv 1\u003e/dev/null 2\u003e\u00261; then eval \"$(pyenv init -)\" fi export PYENV_ROOT=\"$HOME/.pyenv\" export PATH=\"$PYENV_ROOT/bin:$PATH\" # pipenv export PIPENV_VENV_IN_PROJECT=true 注意：注销后重新登录才会开始自动启用 zsh。 ","date":"2018-11-17","objectID":"/posts/505b5/:2:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"pyenv curl https://pyenv.run | zash ","date":"2018-11-17","objectID":"/posts/505b5/:3:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"Python CLI 工具 由于 Linuxbrew 在 Ubuntu 上遇到了诸多问题，因此这些 Python 语言编写的工具将不再使用 Linuxbrew 安装，而是使用 pip3 安装到全局 Python3 上。 pip install tldr httpie pipenv you-get mitmproxy 安装桌面软件和字体 ","date":"2018-11-17","objectID":"/posts/505b5/:4:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"桌面软件 下载安装包或添加 apt 源安装： Chrome VSCode Skype Zeal etcher Typora Wireshark Gnome Terminator wewechat 从 Ubuntu 软件中心安装 Postman Bitwarden calibre ","date":"2018-11-17","objectID":"/posts/505b5/:5:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"字体 Fira Code Cascadia Code JetBrains Mono 思源黑体 配置 ","date":"2018-11-17","objectID":"/posts/505b5/:6:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"终端 Gnome Terminator 的配置文件路径为 /home/chi/.config/terminator/config，内容为 [global_config] always_split_with_profile = True broadcast_default = off inactive_color_offset = 1.0 title_font = JetBrains Mono 12 title_hide_sizetext = True title_transmit_bg_color = \"#68aa13\" title_use_system_font = False [keybindings] next_tab = \u003cPrimary\u003eTab paste = \u003cPrimary\u003e\u003cShift\u003ev prev_tab = \u003cPrimary\u003e\u003cShift\u003eTab [layouts] [[default]] [[[child1]]] parent = window0 type = Terminal [[[window0]]] parent = \"\" type = Window [plugins] [profiles] [[default]] background_darkness = 0.76 background_image = None background_type = transparent copy_on_selection = True font = JetBrains Mono 12 foreground_color = \"#dcdcdc\" palette = \"#000000:#cc0000:#4e9a06:#c4a000:#3465a4:#75507b:#06989a:#d3d7cf:#555753:#ef2929:#8ae234:#fce94f:#729fcf:#ad7fa8:#34e2e2:#eeeeec\" scrollback_lines = 8192 use_system_font = False 设置 Gnome Terminitor 为默认终端 sudo update-alternatives --config x-terminal-emulator gsettings set org.gnome.desktop.default-applications.terminal exec 'terminator' ","date":"2018-11-17","objectID":"/posts/505b5/:7:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"git touch ~/.gitconfig [user] name = foo email = name@email.com [core] quotepath = false editor = vim quotepath = false 可以使 shell 中的 git 能够显示中文路径和文件名。 ","date":"2018-11-17","objectID":"/posts/505b5/:8:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"vim touch ~/.vimrc syntax on set number 改善易用性 ","date":"2018-11-17","objectID":"/posts/505b5/:9:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"安装主题、图标包和鼠标指针 安装 Flatabulous 主题 和 ultra-flat-icons 图标包 sudo add-apt-repository ppa:noobslab/themes sudo add-apt-repository ppa:noobslab/icons sudo apt update sudo apt install flatabulous-theme ultra-flat-icons 下载鼠标指针 Bibata，解压后： sudo mv Bibata_* /usr/share/icons ","date":"2018-11-17","objectID":"/posts/505b5/:10:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"安装 unity-tweak-tool 并美化 安装 unity-tweak-tool，unity-tweak-tool 是一个 Unity 桌面的配置工具。 sudo apt install unity-tweak-tool 打开 unity-tweak-tool 工具，打开 Appearance 分类下的 Theme，设置： 在 Theme 选项卡，选择使用 Flatabulous 主题； 在 Icon 选项卡，选择使用 Ultra-flat 图标包； 在 Cursor 选项卡，选择使用 Bibata 系列鼠标指针； 在 Fonts 选项卡，将默认字体设置为思源黑体，默认等宽字体设置为 JetBrains Mono，文字缩放比例改为 1.25； ","date":"2018-11-17","objectID":"/posts/505b5/:11:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"中文输入 进入 [System Settings] - [Language Support]，在 Language 选项卡中选择 [Install / Remove Languages…]，添加 Chinese(simplified) 语言，将汉语拖动到列表第一位置。并选择 [Keyboard input method system] 为 fcitx，重启电脑； 进入 [System Settings] - [Text Entry]，点击 [+] 添加输入源，以“pinyin”为关键字搜索，添加 Google Pinyin(Fcitx) 输入源。 不要尝试卸载 ibus，否则会造成 unity 桌面菜单空白。 ","date":"2018-11-17","objectID":"/posts/505b5/:12:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"显卡驱动 进入 [System Settings] - [Software \u0026 Updates]，在 [Additional Drivers] 选项卡中，选择已经经过测试的 NVIDIA 闭源驱动。 ","date":"2018-11-17","objectID":"/posts/505b5/:13:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"系统增强 安装 indicator-sysmonitor，在状态栏上展示系统信息。 安装 sudo add-apt-repository ppa:fossfreedom/indicator-sysmonitor sudo apt update sudo apt install indicator-sysmonitor 搜索 system monitor indicator 打开软件。勾选开机自启动，我的配置为： | cpu {cpu} {cputemp} | mem {mem} | {net} | ","date":"2018-11-17","objectID":"/posts/505b5/:14:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"改键 在 Ubuntu 中 ALT 键用于显示 HUD 界面，打游戏很不方便。 打开 [System Settings] - [Keyboard] - [Shortcuts] - [Launchers]，修改 [Key to show the HUD] 为右 ALT 键。 参考链接 Ubuntu16.04更换漂亮绚丽flatabulous主题 - tongqingliu的专栏 - CSDN博客 anmoljagetia/Flatabulous: This is a Flat theme for Ubuntu and other Gnome based Linux Systems. pyenv/pyenv: Simple Python version management pyenv/pyenv-installer: This tool is used to install `pyenv` and friends. Install Docker Engine on Ubuntu | Docker Documentation ","date":"2018-11-17","objectID":"/posts/505b5/:15:0","tags":[],"title":"Ubuntu开发环境搭建","uri":"/posts/505b5/"},{"categories":["工欲善其事"],"content":"MacBook 使用 Retina 技术的屏幕，用久了之后外接的 2K 显示屏（分辨率 2560 * 1440）字很小，感觉很模糊。如果开启显示器的 HiDPI，分辨率会降到 1920 * 1080，但能获得和 MacBook 内置的 Retina 屏幕相似的显示效果。 以下内容在 MacOS Mojave 10.14.1 测试通过。 暂时关闭 SIP SIP 全称 System Integrity Protection，即系统完整性保护。该机制保护系统核心文件和目录不被修改，即使 root 用户也不行。对显示器配置文件进行修改，首先需要关闭 SIP。 重启 MacBook，在开机时按住 Command + R，进入恢复模式。在终端中执行 csrutil disable 然后重启 MacBook。 注意：关闭 SIP 是不安全的，最后一定要记得重新开启。 开启 HiDPI sudo defaults write /Library/Preferences/com.apple.windowserver.plist DisplayResolutionEnabled -bool true 获取显示器信息 这一步需要获取外接显示器的 DisplayVendorID 和 DisplayProductID。使用这两个命令： ioreg -l | grep \"DisplayVendorID\" ioreg -l | grep \"DisplayProductID\" 首先不外接显示器，输入以上命令，获取 MacBook 自己屏幕的 ID。然后外接显示器，输入同样的命令，多出的 DisplayVendorID 和 DisplayProductID 即是外接显示器的 ID。 注意：这里获取到的 ID 都是十进制的。 生成配置文件 打开 Scaled Resolutions for your MacBooks external Monitor 网站，按照提示填写内容。 DisplayProductName：在系统偏好设置中展示的显示器名称； DisplayProductID：上一步中获取到的 DisplayProductID 的十六进制； DisplayVendorID：上一步中获取到的 DisplayVendorID 的十六进制； Scale Resolutions：这里选择分辨率，注意 HiDPI 要选择双倍的分辨率，例如 1920 * 1080 的 HiDPI，应该选择 3840 * 2160 分辨率，并勾选 HiDPI。我这里选择了两种分辨率：2560 * 1440 和 3840 * 2160 + HiDPI； 复制生成的内容。 写入系统配置 注意，若操作系统为 Catalina，系统文件是一个只读的文件系统，直接执行下面的命令会报错 Read-only file system，需要先将根目录以可写的权限挂载： sudo mount -uw / cd /System/Library/Displays/Contents/Resources/Overrides/ sudo mkdir DisplayVendorID-XXXX cd DisplayVendorID-XXXX sudo touch DisplayProductID-YYYY sudo vi DisplayProductID-YYYY 此处，XXXX 是 DisplayVendorID 的十六进制表示，YYYY 是 DisplayProductID 的十六进制表示。将上一步生成的内容写入到该文件中，重启电脑。 使用 RDM 切换分辨率 下载 RDM 并安装，连接显示器，即可在 RDM 中为外接显示器选择 HiDPI 分辨率（带有 ⚡️ 标识）。注意只能选择已经写入到配置文件中的 HiDPI 分辨率，否则无效。 开启 HiDPI 后，可以退出 RDM，以后每次连接显示器仍然有效。 重新开启 SIP 重启 MacBook，在开机时按住 Command + R，进入恢复模式。在终端中执行 csrutil enable 然后重启 MacBook。 参考链接 Macbook外接2K显示器时，如何开启HiDPI? - 知乎 【iOS学习】Macbook外接2k显示器开启hidpi的方法 - 知乎 Scaled Resolutions for your MacBooks external Monitor | by Comsysto Reply GitHub - avibrazil/RDM ","date":"2018-11-11","objectID":"/posts/a49ce/:0:0","tags":[],"title":"MacBook外接2K显示器开启HiDPI","uri":"/posts/a49ce/"},{"categories":["Python"],"content":"PyYAML 是一个用于解析和生成 YAML 格式的 Python 库。 PyYAML 相比 json，不仅能够解析数据，也能解析 Python 对象（非 YAML 标准语法）。 本文基于 PyYAML 3.13 版本。 QuickStart 安装纯 Python 实现版本 pipenv install pyyaml PyYAML 还有一个依赖 LibYAML 的版本，处理起来比纯 Python 版本要快，可以参考文档安装。 解析 yaml： import yaml document = \"\"\" a: 1 b: c: 3 d: 4 \"\"\" print(yaml.load(document)) # {'a': 1, 'b': {'c': 3, 'd': 4}} FAQ ","date":"2018-11-01","objectID":"/posts/444aa/:0:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"没有嵌套集合的字典经过 dump 后格式错误？ 如下的实例，字典中 b 字典的元素没有嵌套集合。 import yaml d = {'a': 1, 'b': {'c': 3, 'd': 4}} print(yaml.dump(d)) 结果为： a:1b:{c: 3, d:4} 而不是我们期望的： a:1b:c:3d:4 按照官方文档的说法，这是正常的： By default, PyYAML chooses the style of a collection depending on whether it has nested collections. If a collection has nested collections, it will be assigned the block style. Otherwise it will have the flow style. 如果想总是输出 block style（即后者），可以在 dump 时将 default_flow_style 参数置为 False。 yaml.dump(d, default_flow_style=False) YAML → Python ","date":"2018-11-01","objectID":"/posts/444aa/:1:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"yaml.load 该函数将 YAML 文档转换为 Python 对象。 **注意，对不受信任的数据直接进行转换会造成安全隐患，yaml.load 和 pickle.load 一样强大，可以调用任意 Python 函数。**对于这种情况，请使用 yaml.safe_load。 \u003e\u003e\u003e yaml.load(\"\"\" ... - Hesperiidae ... - Papilionidae ... - Apatelodidae ... - Epiplemidae ... \"\"\") ['Hesperiidae', 'Papilionidae', 'Apatelodidae', 'Epiplemidae'] yaml.load 可以传入 字节字符串、Unicode 字符串、二进制文件对象和文本文件对象。对于 字节字符串和文件，要求必须是 utf-8、utf-16-be或utf-16-le编码。yaml.load 通过检查字符串和文件开头的 BOM 来检测编码，如果没有 BOM 则认为是 utf-8 编码。 ","date":"2018-11-01","objectID":"/posts/444aa/:2:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"yaml.load_all 如果字符串或文件包含多个 YAML 块，则可以使用 yaml.load_all 函数加载全部。 \u003e\u003e\u003e documents = \"\"\" ... --- ... name: The Set of Gauntlets 'Pauraegen' ... description: \u003e ... A set of handgear with sparks that crackle ... across its knuckleguards. ... --- ... name: The Set of Gauntlets 'Paurnen' ... description: \u003e ... A set of gauntlets that gives off a foul, ... acrid odour yet remains untarnished. ... --- ... name: The Set of Gauntlets 'Paurnimmen' ... description: \u003e ... A set of handgear, freezing with unnatural cold. ... \"\"\" \u003e\u003e\u003e for data in yaml.load_all(documents): ... print(data) {'description': 'A set of handgear with sparks that crackle across its knuckleguards.\\n', 'name': \"The Set of Gauntlets 'Pauraegen'\"} {'description': 'A set of gauntlets that gives off a foul, acrid odour yet remains untarnished.\\n', 'name': \"The Set of Gauntlets 'Paurnen'\"} {'description': 'A set of handgear, freezing with unnatural cold.\\n', 'name': \"The Set of Gauntlets 'Paurnimmen'\"} ","date":"2018-11-01","objectID":"/posts/444aa/:3:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"构造任意类型 Python 对象 PyYAML允许构造任何类型的Python对象，如下，注意 None 和 Bool type 都由多种值转换而来。 \u003e\u003e\u003e yaml.load(\"\"\" ... none: [~, null] ... bool: [true, false, on, off] ... int: 42 ... float: 3.14159 ... list: [LITE, RES_ACID, SUS_DEXT] ... dict: {hp: 13, sp: 5} ... \"\"\") {'none': [None, None], 'int': 42, 'float': 3.1415899999999999, 'list': ['LITE', 'RES_ACID', 'SUS_DEXT'], 'dict': {'hp': 13, 'sp': 5}, 'bool': [True, False, True, False]} 还可以使用标记 !!python/object 构建 Python 类的实例： \u003e\u003e\u003e class Hero: ... def __init__(self, name, hp, sp): ... self.name = name ... self.hp = hp ... self.sp = sp ... def __repr__(self): ... return \"%s(name=%r, hp=%r, sp=%r)\" % ( ... self.__class__.__name__, self.name, self.hp, self.sp) \u003e\u003e\u003e yaml.load(\"\"\" ... !!python/object:__main__.Hero ... name: Welthyr Syxgon ... hp: 1200 ... sp: 0 ... \"\"\") Hero(name='Welthyr Syxgon', hp=1200, sp=0) ","date":"2018-11-01","objectID":"/posts/444aa/:4:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"yaml.safe_load safe_load 只识别标准 YAML 语法的 tag，不解析 Python 对象。 如果输入含有 python 对象，则会报错。 Python → YAML ","date":"2018-11-01","objectID":"/posts/444aa/:5:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"yaml.dump yaml.dump 函数接受 Python 对象并生成 YAML 文档。 \u003e\u003e\u003e print yaml.dump({'name': 'Silenthand Olleander', 'race': 'Human', ... 'traits': ['ONE_HAND', 'ONE_EYE']}) name: Silenthand Olleander race: Human traits: [ONE_HAND, ONE_EYE] 该函数可接受第二个参数，该参数必须为文本文件对象或二进制文件对象。此时，函数将生成的 YAML 文档写入文件中，否则作为函数返回值返回。 除了普通的数据对象，PyYAML 也可以 dump Python 对象。 \u003e\u003e\u003e class Hero: ... def __init__(self, name, hp, sp): ... self.name = name ... self.hp = hp ... self.sp = sp ... def __repr__(self): ... return \"%s(name=%r, hp=%r, sp=%r)\" % ( ... self.__class__.__name__, self.name, self.hp, self.sp) \u003e\u003e\u003e print(yaml.dump(Hero(\"Galain Ysseleg\", hp=-3, sp=2))) !!python/object:__main__.Hero {hp: -3, name: Galain Ysseleg, sp: 2} ","date":"2018-11-01","objectID":"/posts/444aa/:6:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"yaml.dump_all 该函数将多个 yaml 文档 dump 到单个流中，此时传入列表或者生成器等可迭代对象。 \u003e\u003e\u003e print yaml.dump([1,2,3], explicit_start=True) --- [1, 2, 3] \u003e\u003e\u003e print yaml.dump_all([1,2,3], explicit_start=True) --- 1 --- 2 --- 3 ","date":"2018-11-01","objectID":"/posts/444aa/:7:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"自定义输出格式 yaml.dump 支持许多关键字参数，用于指定输出的格式详细信息。 width 设置行宽 indent 设置缩进 default_flow_style 默认使用 flow style，不使用 block style。 default_style 设置字符串的表示符号，单引号还是双引号。 例如，设置行宽和缩进。 \u003e\u003e\u003e print(yaml.dump(range(50), width=50, indent=4)) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49] 自定义 Python 对象转换 ","date":"2018-11-01","objectID":"/posts/444aa/:8:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"yaml.YAMLObject 你可以控制 Python 对象拥有自己的输出格式，最简单的方式是定义一个子类从 yaml.YAMLObject 继承。 yaml.YAMLObject 通过元类“魔法”，注册一个 constructor，用于转换 YAML 节点到 Python 类实例；一个 representer，用于转换 Python 类实例到 YAML 节点。 \u003e\u003e\u003e class Monster(yaml.YAMLObject): ... yaml_tag = u'!Monster' ... def __init__(self, name, hp, ac, attacks): ... self.name = name ... self.hp = hp ... self.ac = ac ... self.attacks = attacks ... def __repr__(self): ... return \"%s(name=%r, hp=%r, ac=%r, attacks=%r)\" % ( ... self.__class__.__name__, self.name, self.hp, self.ac, self.attacks) 上面的类在 dump 时 \u003e\u003e\u003e print(yaml.dump(Monster( ... name='Cave lizard', hp=[3,6], ac=16, attacks=['BITE','HURT']))) !Monster ac: 16 attacks: [BITE, HURT] hp: [3, 6] name: Cave lizard 同时如果 load 一个 Monster 对象，YAML 格式为： \u003e\u003e\u003e yaml.load(\"\"\" ... --- !Monster ... name: Cave spider ... hp: [2,6] # 2d6 ... ac: 16 ... attacks: [BITE, HURT] ... \"\"\") Monster(name='Cave spider', hp=[2, 6], ac=16, attacks=['BITE', 'HURT']) ","date":"2018-11-01","objectID":"/posts/444aa/:9:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"yaml.add_constructor 和 yaml.add_representer 如果不想使用元类继承的方式，也可以使用函数 yaml.add_constructor 注册构造函数，使用 yaml.add_repersenter 注册表现函数。 举例说明，我们有这样一个类 \u003e\u003e\u003e class Dice(tuple): ... def __new__(cls, a, b): ... return tuple.__new__(cls, [a, b]) ... def __repr__(self): ... return \"Dice(%s,%s)\" % self \u003e\u003e\u003e print(Dice(3,6)) Dice(3,6) 默认情况下转换为 YAML 格式后，不够优雅 \u003e\u003e\u003e print(yaml.dump(Dice(3,6))) !!python/object/new:__main__.Dice - !!python/tuple [3, 6] 假如我们想让 Dice(3, 6) 在 YAML 中表示为 3d6，可以这样： import yaml def dice_representer(dumper, data): return dumper.represent_scalar('!dice', '%sd%s' % data) # 注册表现函数 yaml.add_representer(Dice, dice_representer) 此时再 dump 一个 Dice 对象 \u003e\u003e\u003e print(yaml.dump({'gold': Dice(10,6)})) {gold: !dice '10d6'} 对于 load 我们也可以做相同的自定义： def dice_constructor(loader, node): ... value = loader.construct_scalar(node) ... a, b = map(int, value.split('d')) ... return Dice(a, b) \u003e\u003e\u003e yaml.add_constructor('!dice', dice_constructor) 此时再 load 一个 YAML 节点： \u003e\u003e\u003e print(yaml.load(\"\"\" ... initial hit points: !dice 8d4 ... \"\"\")) {'initial hit points': Dice(8,4)} ","date":"2018-11-01","objectID":"/posts/444aa/:10:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"yaml.add_implicit_resolver 如果你想在不指定 !dice 标记的情况下将 XdY 的格式转换为 Dice 类的对象，可以使用 add_implicit_resolver。 \u003e\u003e\u003e import re \u003e\u003e\u003e pattern = re.compile(r'^\\d+d\\d+$') \u003e\u003e\u003e yaml.add_implicit_resolver(u'!dice', pattern) 这时转换就不再需要指定 !dice 。 \u003e\u003e\u003e print(yaml.dump({'treasure': Dice(10,20)})) {treasure: 10d20} \u003e\u003e\u003e print(yaml.load(\"\"\" ... damage: 5d10 ... \"\"\")) {'damage': Dice(5,10)} 转换映射参考表 YAML tag Python type Standard YAML tags !!null None !!bool bool !!int int or long (int in Python 3) !!float float !!binary str (bytes in Python 3) !!timestamp datetime.datetime !!omap, !!pairs list of pairs !!set set !!str str or unicode (str in Python 3) !!seq list !!map dict Python-specific tags !!python/none None !!python/bool bool !!python/bytes (bytes in Python 3) !!python/str str (str in Python 3) !!python/unicode unicode (str in Python 3) !!python/int int !!python/long long (int in Python 3) !!python/float float !!python/complex complex !!python/list list !!python/tuple tuple !!python/dict dict Complex Python tags !!python/name:module.name module.name !!python/module:package.module package.module !!python/object:module.cls module.cls instance !!python/object/new:module.cls module.cls instance !!python/object/apply:module.f value of f(...) 参考链接 PyYAML - Documentation ","date":"2018-11-01","objectID":"/posts/444aa/:11:0","tags":[],"title":"PyYAML-YAML格式Python处理库","uri":"/posts/444aa/"},{"categories":["Python"],"content":"RQ 是一个基于 Redis 的轻量级任务队列，依赖 Redis \u003e= 2.7.0。RQ 将任务、执行结果 pickle 序列化后存储于 Redis 当中，在较小规模的应用中可以替代 Celery 执行异步任务。 另外我觉得比较好的一点是，RQ 的 worker 不会预先读取任务函数。因此，任务函数更改后，不需要重启 RQ 的 worker。同时，推荐以下基于 RQ 的项目： rq-scheduler 基于 RQ 的定时任务； Flask-RQ2 在 Flask 中集成 RQ 的扩展； rq-dashboard RQ 的 web 监控工具，使用 Flask 开发，可以方便的集成到 Flask 应用中。 RQ 的不足在于，依赖于 fork() 进程，因此不能在 Windows 系统中使用。 本文基于 RQ 0.12.0 版本。 QuickStart 安装 RQ： pipenv install rq 编写任务函数： import requests def count_words_at_url(url): resp = requests.get(url) return len(resp.text.split()) 创建 RQ 队列： from redis import Redis from rq import Queue q = Queue(connection=Redis()) 调用任务函数 from my_module import count_words_at_url result = q.enqueue(count_words_at_url, 'http://python-rq.org') 启动 RQ worker： $ rq worker 22:52:34 RQ worker 'rq:worker:InvokerPro.10689' started, version 0.12.0 22:52:34 *** Listening on default... 22:52:34 Cleaning registries for queue: default 22:52:34 default: job.count_words_at_url('http://python-rq.org') (c3b8fcab-347f-4529-ab4f-0865407fbaa2) 22:52:34 default: Job OK (c3b8fcab-347f-4529-ab4f-0865407fbaa2) 22:52:34 Result is kept for 500 seconds 获取结果（需要延时一段时间使异步任务执行完成） import time for i in range(20): if result. while result.status != 'finished': time.sleep(1) print(result.result) Queue 队列 任务（job）是一个供 RQ 后台 worker 调用的 Python 函数对象。把该函数和运行参数压入队列的过程称为入队（enqueue）。 ","date":"2018-10-30","objectID":"/posts/2e36d/:0:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"新建队列 首先，声明一个任务函数，这里不再赘述。 新建队列（Queue），可以在实例化时根据需要指定 Queue 名称，常见的命名模式是按照优先级命名队列（例如 high，medium，low）。 q = Queue('low', connection=redis_conn) ","date":"2018-10-30","objectID":"/posts/2e36d/:1:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"入队：enqueue 和 enqueue_call 使用 enqueue(f, *args, **kwargs) 方法将任务入队： q.enqueue(job_func, job_arg1, job_arg2, job_kwarg1=value) 除此之外，使用 enqueue 入队时，可以接收以下参数控制任务执行： timeout 任务超时时间，超时后将会被标记为 failed 状态。默认单位为秒，可以传入整数，或者能够被转换为整数的字符串，例如 2 或者 '2’。另外，也可以传入包含时分秒单位的字符串，例如 1h、3m 和 10s。 result_ttl 在 Redis 中存储的任务结果的过期时间，过期后任务结果会被删除，默认 500 秒。 ttl 任务加入队列后，被取消之前的等待执行时间；超过该时间后任务会被取消执行。如果设置为 -1，任务将永远不会被取消，一直等待。 depends_on 指定另一个依赖任务（或者 job ID），依赖任务执行完毕后，当前任务才会入队。 job_id 指定 job_id。 at_front 将任务放在队列的前面，即优先插队执行。 kwargs 和 args 存放传入任务函数的关键字参数和可变参数。 举个例子： q.enqueue_call( func=count_words_at_url, args=('http://nvie.com',), timeout=30 ) 另外，在一些场景中，入队任务进程可能无法访问在 worker 中运行的源代码，此时该函数也可以传入字符串： q.enqueue('my_package.my_module.my_func', 3, 4) ","date":"2018-10-30","objectID":"/posts/2e36d/:2:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"队列使用 这里介绍一些 Queue 实例的其他 method。 获取队列中任务数量： len(q) 获取队列中任务 job id 列表： q.job_ids 获取任务实例列表： q.jobs 根据 job id 获取任务实例： q.fetch_job('my_id') 删除队列： q.delete(delete_jobs=True) # delete_jobs=True时，也会删除队列中的所有任务 RQ 依赖于 pickle 来序列化任务存入 Redis，因此只适用于 Python 系统。 ","date":"2018-10-30","objectID":"/posts/2e36d/:3:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"获取执行结果 当任务入队时，该 queue.enqueue() 方法返回一个 Job 实例。这是一个可以用来检查运行结果的 proxy 对象。 该实例的 result 属性，在任务未完成时返回 None，在任务完成后返回任务函数的返回值（前提是有返回值）。 ","date":"2018-10-30","objectID":"/posts/2e36d/:4:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"@job 装饰器 使用 Celery @task 的任务函数装饰器。（RQ \u003e= 0.3） from rq.decorators import job @job('low', connection=my_redis_conn, timeout=5) def add(x, y): return x + y job = add.delay(3, 4) time.sleep(1) print(job.result) ","date":"2018-10-30","objectID":"/posts/2e36d/:5:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"同步执行 不经过 worker，直接在当前进程中同步阻塞执行任务函数。（RQ \u003e= 0.3.1） 需要在 Queue 实例化时传递参数 is_async=False。 \u003e\u003e\u003e q = Queue('low', is_async=False, connection=my_redis_conn) \u003e\u003e\u003e job = q.enqueue(fib, 8) \u003e\u003e\u003e job.result 21 注意这种情况下，仍然要建立 Redis 连接以存储任务执行状态。 ","date":"2018-10-30","objectID":"/posts/2e36d/:6:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"链式执行 在任务入队时传入 depends_on 参数以保证任务链式执行。（RQ \u003e= 0.4.0） q = Queue('low', connection=my_redis_conn) report_job = q.enqueue(generate_report) q.enqueue_call(func=send_report, depends_on=report_job) ","date":"2018-10-30","objectID":"/posts/2e36d/:7:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"任务注意事项 确保该函数的 __module__ 能够被 worker 导入。这意味着无法将 __main__ 模块中声明的函数作为任务入队。 确保 worker 和 worker 生成器共享完全相同的源代码。 确保函数调用不依赖于其上下文。不要在任务函数中使用全局变量、Web应用程序中的 current_user 或者 current_request 对象。当 worker 运行任务函数时，函数所依赖的任何状态都不存在。如果要访问这些信息，应该将这些信息作为参数传递给 worker。 Worker 工作进程 工作进程（worker）是一个通常在后台运行的用于执行阻塞或长时任务的 Python 进程。 启动 RQ worker 基于 fork() 创建新进程。如果不使用 Windows Subsystem for Linux 并在 shell 中运行，那么 RQ 无法在 Windows 系统上执行任务。 ","date":"2018-10-30","objectID":"/posts/2e36d/:8:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"启动 Worker 在项目根目录执行： $ rq worker high normal low 09:07:05 RQ worker 'rq:worker:InvokerPro.11898' started, version 0.12.0 09:07:05 *** Listening on high, normal, low... 09:07:05 Cleaning registries for queue: high 09:07:05 Cleaning registries for queue: normal 09:07:05 Cleaning registries for queue: low Worker 将会在无限循环中从给定的 Queue 中依次读取任务，因此启动 Worker 时 Queue 参数的顺序很重要，应该让高优先级任务 Queue 排在前面。 一个 Worker 每次只能执行一个任务，不能并发处理。如果要同时执行任务，只需要启动多个 worker 即可。 ","date":"2018-10-30","objectID":"/posts/2e36d/:9:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"Burst mode 突发模式 默认情况下，Worker 启动后会立即开始处理任务，处理完成后阻塞等待新任务。 使用 —-burst 参数可以让 Worker 以突发模式启动。在此模式下，Worker 会在给定队列清空（即完成所有任务）后退出。 $ rq worker --burst high normal low 09:24:03 RQ worker 'rq:worker:InvokerPro.13525' started, version 0.12.0 09:24:03 *** Listening on high, normal, low... 09:24:03 Cleaning registries for queue: high 09:24:03 Cleaning registries for queue: normal 09:24:03 Cleaning registries for queue: low 09:24:03 RQ worker 'rq:worker:InvokerPro.13525' done, quitting 突发模式可以应用于： 定期执行的批量任务，单独开 Worker 执行，在执行完毕后退出； 在任务积压时，临时增加 Worker； ","date":"2018-10-30","objectID":"/posts/2e36d/:9:1","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"启动参数 除 —-burst 外，Worker 还支持以下启动参数： —-url -u 指定 Redis 数据库连接，例如 redis://:secrets@example.com:1234/9 —-path -p 指定 import 路径，可以传多个值； —-config -c 指定配置文件路径； —-worker-class -w 指定使用的 RQ Worker 类； --job-class -j 指定使用的 RQ Job 类； --queue-class 指定使用的 RQ Queue 类； —-connection-class 指定要使用的 Redis 连接类，默认 redis.StrictRedis； —-log-format 指定 Worker 日志格式，默认为 '%(asctime)s %(message)s'； --date-format 指定 Worker 日志的日期时间格式，默认为 '%H:%M:%S'； ","date":"2018-10-30","objectID":"/posts/2e36d/:9:2","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"生命周期 Worker 的生命周期包括几个阶段： Boot。加载Python环境。 Birth registration。Worker 将自己注册到系统。 Start listening。从给定的 Redis 队列中取出任务。若所有队列都为空，如果 Worker 以突发模式运行则 Worker 结束运行，否则阻塞等待任务。 Prepare job execution。Worker 把要执行的任务状态设置为 busy，并在 StartedJobRegistry 中注册该任务，告知系统准备执行该任务 Fork a child process。Fork 一个子进程（被称为 work horse），该子进程在故障安全上下文（fail-safe context）中执行任务。 Process work。子进程执行任务。 Cleanup job execution。Worker 将任务状态设置为 idle，将任务结果结果存储到 Redis 中并根据 result_ttl 设置过期时间。把任务从 StartedJobRegistry 中删除，如果执行成功将任务添加到 FinishedJobRegistry 中，如果执行失败将任务添加到 FailedQueue 中。 Loop。从第3步开始重复。 ","date":"2018-10-30","objectID":"/posts/2e36d/:10:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"提升性能 RQ Worker shell 脚本基本上是一个 fetch-fork-execute 循环。这样做的好处是 RQ 不会泄露内存。但当任务需要进行冗长的设置，或任务都依赖于相同的模块时，每次运行任务都要耗费这一部分时间（因为要在 fork 出新进程后再进行 import）。 可以在 fork 之前就 import 必要的模块，以改进性能。RQ Worker 没有这样的设置项，但你可以在开始 worker loop 之前进行 import。 为此，你要自己实现 Worker 启动脚本，而不是使用 rq worker。举个例子： #!/usr/bin/env python import sys from rq import Connection, Worker # 提前导入必要模块 import library_that_you_want_preloaded # qs 用于获取 Queue 名 with Connection(): qs = sys.argv[1:] or ['default'] w = Worker(qs) w.work() ","date":"2018-10-30","objectID":"/posts/2e36d/:11:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"Worker 信息 Worker 名称一般是主机名和当前 PID 的组合，也可以在启动时通过 —-name 指定。 Worker 实例的运行时信息存储于 Redis 中，可以使用 rq.Worker.all 查询。注意每次查询都会从 Redis 中取信息构建 Worker 实例，也就是说，每次查询得到的实例不是同一内存对象。 from redis import Redis from rq import Queue, Worker redis = Redis() # 返回当前 Redis 连接中注册的所有 Worker workers = Worker.all(connection=redis) # 返回指定 Queue 的所有 Worker（RQ \u003e= 0.10.0） queue = Queue('queue_name', connection=redis) workers = Worker.all(queue=queue) 如果只是想得到 Worker 数量，可以使用 rq.Worker.count 方法（RQ \u003e= 0.10.0）： from redis import Redis from rq import Queue, Worker redis = Redis() workers = Worker.count(connection=redis) queue = Queue('queue_name', connection=redis) workers = Worker.count(queue=queue) 另外还可以通过 Worker 实例获得一些统计信息（RQ \u003e= 0.9.0）。首先通过 Worker.find_by_key 方法获得 Worker 实例，传参为 Redis key，格式为 rq:worker:\u003cname\u003e。再通过实例属性查看统计信息。 from rq.worker import Worker worker = Worker.find_by_key('rq:worker:name') worker.successful_job_count # 执行成功任务数量 worker.failed_job_count. # 执行失败任务数量 worker.total_working_time # 总执行时间 ","date":"2018-10-30","objectID":"/posts/2e36d/:12:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"停止 Worker 当 Worker 收到 SIGINT 信号（通过 Ctrl + C）或 SIGTERM 信号（通过 kill）时，会等待当前任务运行结束后，结束任务循环并注册自己的死亡。 如果在等待期间再次收到 SIGINT 或者 SIGTERM 信号，Worker 将会发送 SIGKILL 信号强行中止子进程，但仍然会尝试注册自己的死亡。 ","date":"2018-10-30","objectID":"/posts/2e36d/:13:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"使用配置文件 要求 RQ \u003e= 0.3.2。 配置文件需要为 Python 文件，在启动 Worker 时通过 -c 参数指定从哪个模块读取配置。以下是配置文件支持的配置项： REDIS_URL = 'redis://localhost:6379/1' # 或者通过以下参数指定 Redis 数据库 # REDIS_HOST = 'redis.example.com' # REDIS_PORT = 6380 # REDIS_DB = 3 # REDIS_PASSWORD = 'very secret' # 指定监听的 Queue QUEUES = ['high', 'normal', 'low'] # Sentry 设置 # The 'sync+' prefix is required for raven: https://github.com/nvie/rq/issues/350#issuecomment-43592410 SENTRY_DSN = 'sync+http://public:secret@example.com/1' # 自定义 Worker 名称 NAME = 'worker-1024' 注意： QUEUES 和 REDIS_PASSWORD 设置是0.3.3以后的新设置。 指定配置文件： $ rq worker -c settings ","date":"2018-10-30","objectID":"/posts/2e36d/:14:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"自定义DeathPenalty类 当任务超时时，Worker 将尝试使用 death_penalty_class（默认值 UnixSignalDeathPenalty）提供的方法将其终止。如果您希望尝试以特定应用程序或“更干净”的方式杀死任务，则可以覆盖此项。 DeathPenalty 类使用以下参数构造 BaseDeathPenalty(timeout, JobTimeoutException, job_id=job.id) ","date":"2018-10-30","objectID":"/posts/2e36d/:15:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"自定义异常处理程序 要求 RQ \u003e= 0.5.5。 如果要针对不同类型的作业以不同方式处理错误，或者想自定义 默认的错误处理，可以使用 --exception-handler 指定错误处理类： $ rq worker --exception-handler 'path.to.my.ErrorHandler' # Multiple exception handlers is also supported $ rq worker --exception-handler 'path.to.my.ErrorHandler' --exception-handler 'another.ErrorHandler' Result 执行结果 ","date":"2018-10-30","objectID":"/posts/2e36d/:16:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"处理结果 如果一个任务有非 None 的返回值，Worker 会把返回值经过 pickle 序列化后，写入到任务在 Redis 中对应记录（key 为 rq:job:[hash] 格式，value 为 Hash 类型）的 result 字段中，默认将会在 500 秒后失效。 将任务入队时返回的 Job 实例是一个代理对象，绑定了任务 ID，以便能从任务执行结果中取到数据。 若 RQ \u003e= 0.3.1 版本，可以在调用 enqueue 和 enqueue_call 入队时，使用 result_ttl 参数指定存储结果删除时间： 不设置，使用默认值 500，500 秒后删除； 设置为 0，立即删除； 设置为 -1，永不删除，此时要注意自己清理 Redis，以免 Redis 无限增长； 设置为其他正整数数值 N，在 N 秒后删除； q.enqueue(foo) # result expires after 500 secs (the default) q.enqueue(foo, result_ttl=86400) # result expires after 1 day q.enqueue(foo, result_ttl=0) # result gets deleted immediately q.enqueue(foo, result_ttl=-1) # result never expires--you should delete jobs manually 文档中的这一段与实际测试结果不符，实际测试没有返回值的情况下也使用默认的 500 秒的超时时间。 Additionally, you can use this for keeping around finished jobs without return values, which would be deleted immediately by default. q.enqueue(func_without_rv, result_ttl=500) # job kept explicitly ","date":"2018-10-30","objectID":"/posts/2e36d/:17:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"异常处理 任务执行失败时会抛出异常，为了引起足够的注意，失败任务在 Redis 中的记录永不过期。RQ 目前没有可靠的或自动的方法判断某些失败的任务能否安全重试。 失败任务中抛出的异常，会被 Worker 捕获，pickle 序列化后存储到任务在 Redis 中记录的 exc_info 字段中，而 失败任务的 Job 对象则会放入 failed 队列中。 Job 对象本身有一些有用的属性，可以用于辅助检查： 任务原始创建时间； 最后入队日期； 入队始发队列； 函数调用的文本描述； 异常信息； 可以根据这些信息手动检查和判断问题并可以重新提交任务。 ","date":"2018-10-30","objectID":"/posts/2e36d/:18:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"中断处理 当 Worker 进程被以“礼貌的”方式杀死时（Ctrl + C 或 kill），RQ 会努力不丢失任何任务，会在当前任务处理完成后停止处理新的任务。 但是，Worker 进程也可以通过 kill -9 的方式强行杀死，此时 Worker 不能“优雅地”完成工作，没有时间把任务加入 failed 队列中。因此，强行杀死进程可能会导致异常。 ","date":"2018-10-30","objectID":"/posts/2e36d/:19:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"超时处理 默认情况下，任务应该在 180 秒内执行完毕。否则，Worker 会杀死 work horse 进程，并将任务加入到 failed 队列中，表明工作超时。 根据任务需要，我们可以自定义超时时间。 在 Job 维度，入队时使用 timeout 参数设置： q = Queue() q.enqueue_call(mytask, args=(foo,), kwargs={'bar': qux}, timeout=600) # 10 mins 在 Queue 维度，新建 Queue 时使用 timeout 参数设置，对队列中所有任务都有效。 # High prio jobs should end in 8 secs, while low prio # work may take up to 10 mins high = Queue('high', default_timeout=8) # 8 secs low = Queue('low', default_timeout=600) # 10 mins Job 维度的设置项优先级高于 Queue 维度。 Jobs 任务 ","date":"2018-10-30","objectID":"/posts/2e36d/:20:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"从 Redis 中获取 Job 所有的任务信息都存储于 Redis 中，可以使用 Job.fetch(id, connection=redis) 方法获取 Job 实例： from redis import Redis from rq.job import Job connection = Redis() job = Job.fetch('my_job_id', connection=redis) print('Status: %s' $ job.get_status()) 该 Job 对象的一些属性包括： job.status job.func_name job.args job.kwargs job.result job.enqueued_at job.started_at job.ended_at job.exc_info ","date":"2018-10-30","objectID":"/posts/2e36d/:21:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"读写当前 Job 实例 由于任务函数是常规的 Python 函数，因此在任务函数中，只能通过 RQ 的 get_current_job 函数获得当前 Job 的实例。 from rq import get_current_job def add(x, y): job = get_current_job() print('Current job: %s' % (job.id,)) return x + y 通过 Job 实例的 meta 属性 和 save_meta() 方法，可以向 Job 实例中写入数据。（RQ \u003e= 0.8.0） def add(x, y): job = get_current_job() job.meta['timestamp'] = time.time() job.save_meta() # do more work time.sleep(1) return x + y 注意，以上内容只在任务函数中有效。 ","date":"2018-10-30","objectID":"/posts/2e36d/:22:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"Job 的等待执行时间 一个任务有两个 TTL：一个用于执行结果，另一个用于任务 Job 本身。后者表示任务在队列中等待多久后会被取消。该 TTL 可以在创建任务或入队时指定： from rq.job import Job # 在任务创建时指定 job = Job.create(func=say_hello, ttl=100) # 在任务入队时指定 job = q.enqueue(count_words_at_url, 'http://nvie.com', ttl=43) 设置为 -1 时任务将一直等待，不会被取消。被取消的 Job 会立即被从 Redis 中立即删除。 ","date":"2018-10-30","objectID":"/posts/2e36d/:23:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"执行失败的 Job 如果任务执行失败，Worker 会把任务放入 failed 队列中，同时 Redis 中 Job 实例的 is_failed 属性会被置为 True。使用 get_failed_queue 可以获取所有失败的任务。 from redis import StrictRedis from rq import push_connection, get_failed_queue, Queue from rq.job import Job con = StrictRedis() push_connection(con) def div_by_zero(x): return x / 0 job = Job.create(func=div_by_zero, args=(1, 2, 3)) job.origin = 'fake' job.save() # 获取 failed queue 对象 fq = get_failed_queue() # 把 job 加入到 failed queue 中 fq.quarantine(job, Exception('Some fake error')) assert fq.count == 1 # 把 job 重新加入到执行队列中，并从 failed queue 中删除 fq.requeue(job.id) assert fq.count == 0 assert Queue('fake').count == 1 Monitoring 监控 ","date":"2018-10-30","objectID":"/posts/2e36d/:24:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"rq-dashboard RQ dashboard 是一个单独分发的，轻量级的 Web 前端监控工具，基于 Flask 开发。 安装方式如下： pip install rq-dashboard 运行： rq-dashboard 与 Flask 集成 from flask import Flask import rq_dashboard app = Flask(__name__) app.config.from_object(rq_dashboard.default_settings) app.register_blueprint(rq_dashboard.blueprint, url_prefix=\"/rq\") @app.route(\"/\") def hello(): return \"Hello World!\" if __name__ == \"__main__\": app.run() ","date":"2018-10-30","objectID":"/posts/2e36d/:25:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"Console 工具 RQ 自带了 console 监控工具，启动命令为 rq info： $ rq info failed |██ 2 default | 0 2 queues, 2 jobs total InvokerPro.53243 idle: default 1 workers, 2 queues Updated: 2018-10-29 23:03:07.478540 ","date":"2018-10-30","objectID":"/posts/2e36d/:26:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"查询指定队列 通过 rq info queue1 queue2 … 可以返回指定队列的信息： $ rq info default default | 0 1 queues, 0 jobs total InvokerPro.53243 idle: default 1 workers, 1 queues Updated: 2018-10-29 23:22:17.640684 ","date":"2018-10-30","objectID":"/posts/2e36d/:26:1","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"按队列展示 默认情况下，rq info 输出活跃 Worker 和它们监听的 Queue。 通过设置 -R 或者 --by-queue，可以让 RQ 按照队列组织展示，即展示队列和监听队列的 Worker。 $ rq info -R failed |██ 2 default | 0 2 queues, 2 jobs total failed: – default: InvokerPro.53243 (idle) 1 workers, 2 queues Updated: 2018-10-29 23:33:58.255413 ","date":"2018-10-30","objectID":"/posts/2e36d/:26:2","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"定时轮询 默认情况下，rq info 打印信息后就会退出。可以使用 —-interval 参数指定轮询间隔，以不断刷新监控信息。 $ rq info --interval 1 注意，如果 interval 设置的过低，会加重 Redis 的负载。 Connection 连接 **RQ 维护一个 Redis 连接堆栈，每个 RQ 对象实例在创建时，会使用堆栈最顶层的 Redis 连接。**因此我们可以使用 with 上下文管理器创建连接，并在其中新建 RQ 对象实例。 from rq import Queue, Connection from redis import Redis with Connection(Redis()): q = Queue() 或者新建 RQ 对象实例时显式地指定连接： from rq import Queue from redis import Redis conn = Redis('localhost', 6379) q = Queue('foo', connection=conn) ","date":"2018-10-30","objectID":"/posts/2e36d/:26:3","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"多 Redis 连接 使用显式连接实现——准确但乏味： from rq import Queue from redis import Redis conn1 = Redis('localhost', 6379) conn2 = Redis('remote.host.org', 9836) q1 = Queue('foo', connection=conn1) q2 = Queue('bar', connection=conn2) 使用 with 上下文管理器实现： from rq import Queue, Connection from redis import Redis with Connection(Redis('localhost', 6379)): q1 = Queue('foo') with Connection(Redis('remote.host.org', 9836)): q2 = Queue('bar') q3 = Queue('qux') assert q1.connection != q2.connection assert q2.connection != q3.connection assert q1.connection == q3.connection ","date":"2018-10-30","objectID":"/posts/2e36d/:27:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"push/pop 连接 如果代码不允许使用 with 语句（例如在单元测试中），则可以使用 push_connection() 和 pop_connection() 方法替代上下文管理器。 import unittest from rq import Queue from rq import push_connection, pop_connection class MyTest(unittest.TestCase): def setUp(self): # 将新连接压入连接堆栈 push_connection(Redis()) def tearDown(self): # 从连接堆栈中丢弃连接 pop_connection() def test_foo(self): \"\"\"Any queues created here use local Redis.\"\"\" q = Queue() ... ","date":"2018-10-30","objectID":"/posts/2e36d/:28:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"结合 Sentinel 要使用 redis sentinel，必须在配置文件中指定字典。将此设置与带有自动重启选项的 systemd 或 docker 容器结合使用，以便允许 worker 和 RQ 通过容错连接（fault-tolerant connection）连接 Redis。 SENTINEL:{'INSTANCES':[('remote.host1.org',26379),('remote.host2.org',26379),('remote.host3.org',26379)],'SOCKET_TIMEOUT':None,'PASSWORD':'secret','DB':2,'MASTER_NAME':'master'} Exception 异常处理 任务在发生异常时会执行失败，当 RQ Worker 在后台运行时，你怎么才能知道任务失败了呢？ ","date":"2018-10-30","objectID":"/posts/2e36d/:29:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"failed 队列 默认情况下，RQ 会将失败的任务放入到 failed 队列中，包含了它们的异常信息（类型，值，堆栈）。这只能被动保存发生的异常，但不会有任何主动通知。 ","date":"2018-10-30","objectID":"/posts/2e36d/:30:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"自定义异常处理 RQ支持注册自定义异常处理程序（RQ \u003e= 0.3.1）。这样就可以在发生异常时采取其他步骤，或者替换默认地将失败任务发送到 failed 队列的行为。 在创建 Worker 时，使用 exception_handlers 参数指定异常处理程序列表。 from rq.handlers import move_to_failed_queue # RQ 默认的异常处理行为——发送任务到 failed 队列 w = Worker([q], exception_handlers=[my_handler, move_to_failed_queue]) ... 异常处理 handler 是一个函数，其参数为： job 任务对象 exc_type 异常类型 exc_value 异常值 traceback 异常堆栈 def my_handler(job, exc_type, exc_value, traceback): # do custom things here # for example, write the exception info to a DB ... 或者使用可变参数定义：job 和 *exc_info。 def my_handler(job, *exc_info): # do custom things here ... ","date":"2018-10-30","objectID":"/posts/2e36d/:31:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"链式异常处理 异常处理程序可以决定是否完成处理异常，还是由堆栈中的后续程序继续处理异常。这通过返回值来控制： 若返回 True 表示继续，并进入下一个异常处理程序； 若返回 False 表示停止处理异常； 若没有返回值，即返回 None，则认为是 True，继续进入下一个异常处理程序； 如果要替换默认的错误处理行为，错误处理程序应该返回 False。 def black_hole(job, *exc_info): return False Testing 测试 ","date":"2018-10-30","objectID":"/posts/2e36d/:32:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"单元测试中的 Worker 许多框架在执行单元测试时使用内存数据库，这些数据库与 RQ 默认使用的 fork() 不太兼容。 因此在单元测试用，应该使用 SimpleWorker 类来避免 fork()，且建议以突发模式运行。 from redis import Redis from rq import SimpleWorker, Queue queue = Queue(connection=Redis()) queue.enqueue(my_long_running_job) worker = SimpleWorker([queue], connection=queue.connection) worker.work(burst=True) # Runs enqueued job # Check for result... ","date":"2018-10-30","objectID":"/posts/2e36d/:33:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Python"],"content":"在单元测试中执行任务 另一种解决方案是，在创建队列时使用 is_async=False 参数，使任务在同一个线程中立即执行，而不是将其分配给 Worker。此时不需要启动 RQ worker。 除此之外，还可以使用 FakeStrictRedis 替代 Redis，也不必再启动 Redis 服务器，FakeStrictRedis 的实例可以直接作为连接参数传递给队列。 from fakeredis import FakeStrictRedis from rq import Queue queue = Queue(is_async=False, connection=FakeStrictRedis()) job = queue.enqueue(my_long_running_job) assert job.is_finished 参考链接 RQ: Documentation GitHub - rq/rq GitHub - eoranged/rq-dashboard ","date":"2018-10-30","objectID":"/posts/2e36d/:34:0","tags":[],"title":"RQ-轻量级Python任务队列","uri":"/posts/2e36d/"},{"categories":["Web 开发"],"content":"2FA 概念 认证（authentication）即是确认用户身份，密码是最常见的认证方法。但是密码容易泄露和冒充，因此越来越多的网站开始采用双因素认证（Two-factor authentication，简称 2FA）。即通过使用除密码外的其他因素，来确认用户身份，增加冒充的难度。 常用的认证因素可以分为以下几类： 秘密信息：只有该用户知道、其他人不知道的某种信息，比如密码。 个人物品：该用户的私人物品，比如身份证、钥匙、U 盾等。 生理特征：该用户的遗传特征，比如指纹、相貌、虹膜等等。 因素越多，证明力就越强，身份就越可靠。要求更高的的系统可以采用多因素认证（MFA）。 2FA 认证方案 常见的 2FA 认证方案有： 基于硬件的方式，密码 + 某种个人物品，例如 网银 U 盾、智能卡等，缺点要随身携带； 基于手机 SMS 的方式，密码 + 短信验证码，缺点是 容易被拦截和伪造（ss7信令漏洞），手机丢失或更换手机号成本较高； 基于一次性密码（One Time Password，简称OTP）； OTP 密码不易泄露，即是泄漏也难以受到重放攻击，另外其公开协议 + 高强度算法方式也难以猜测，是 2FA 方案的首选。 OTP 有两种： HOTP（HMAC-Based One-Time Password）基于 HMAC 的一次性密码，使用计数器计算下一个密码值。标准写入 RFC4226； TOTP（Time-Based One-Time Password）基于时间的一次性密码，使用时间计算下一个密码值。标准写入 RFC6238； TOTP 从 HOTP 发展而来，目前已经成为主流的验证方式。 TOTP ","date":"2018-10-24","objectID":"/posts/a18b7/:0:0","tags":[],"title":"双因素认证2FA","uri":"/posts/a18b7/"},{"categories":["Web 开发"],"content":"使用步骤 用户开启双因素认证后，服务器生成一个密钥； 服务器提示用户扫描二维码（或其他方式），用户保存该密钥到硬件生成器或软件生成器中，此时服务器和用户拥有了相同的密钥； 用户登录时，手机客户端使用这个密钥和当前时间戳，生成一个哈希，有效期默认为30秒。用户在有效期内，把这个哈希提交给服务器。 服务器也使用密钥和当前时间戳，生成一个哈希，跟用户提交的哈希比对。只要两者不一致，就拒绝登录。 实际应用过程中，还要做到： 提供备用的固定哈希代码，用于 TOTP 密钥丢失的情况； 在第2步用户绑定密钥时，就让用户输入一次哈希，验证绑定正确，用户与服务器使用了同一个密钥。 ","date":"2018-10-24","objectID":"/posts/a18b7/:1:0","tags":[],"title":"双因素认证2FA","uri":"/posts/a18b7/"},{"categories":["Web 开发"],"content":"算法原理 首先计算时间计数器 TC，TOTP 用 TC 代替了 HOTP 中的计数器。 TC = floor((unixtime(now) − unixtime(T0)) / TS) unixtime(now)是当前 Unix 时间戳，unixtime(T0)是约定的起始时间点的时间戳，默认是0，也就是1970年1月1日。TS 则是哈希有效期的时间长度，默认是30秒。通过整除，能够保证在 30 秒内，TC 都是同一个值。 然后使用 TC 计算哈希： TOTP = HASH(SecretKey, TC) HASH就是约定的哈希函数，默认是 SHA-1。 根据TOTP的算法特性，服务器时间与 TOTP 客户端时间差如果超过 TC ，那么一定无法生成一致的哈希。实际应用中最好能够保持时间同步。 ","date":"2018-10-24","objectID":"/posts/a18b7/:2:0","tags":[],"title":"双因素认证2FA","uri":"/posts/a18b7/"},{"categories":["Web 开发"],"content":"TOTP 客户端 TOTP 客户端可以分为 TOTP 硬件生成器 和 TOTP 软件生成器。软件生成器与硬件生成器相比，优势在于： 可以绑定多个密钥； 可以方便的绑定解绑； 时间准确性高； 常用 TOTP 软件生成器： Google Authenticator Microsoft Authenticator（可为微软系网站生成8位字符令牌，为其他网站生成6位字符令牌） FreeOTP ","date":"2018-10-24","objectID":"/posts/a18b7/:3:0","tags":[],"title":"双因素认证2FA","uri":"/posts/a18b7/"},{"categories":["Web 开发"],"content":"服务端 Python 实现 Python 可以选择使用 PyOTP 库，该库实现了 HOTP 和 TOTP。可以通过 pip 安装： pip install pyotp TOTP 示例： totp = pyotp.TOTP('base32secret3232') # 字符串长度一定要是16 totp.now() # =\u003e '492039' # OTP verified for current time totp.verify('492039') # =\u003e True time.sleep(30) totp.verify('492039') # =\u003e False HOTP 示例： hotp = pyotp.HOTP('base32secret3232') # 字符串长度一定要是16 # HOTP 计算时要传入计数值 hotp.at(0) # =\u003e '260182' hotp.at(1) # =\u003e '055283' hotp.at(1401) # =\u003e '316439' # OTP verified with a counter hotp.verify('316439', 1401) # =\u003e True hotp.verify('316439', 1402) # =\u003e False 生成 base32 随机密钥： # 返回 16 长度的 base32 密钥，与 Google Authenticator 和其他 OTP 客户端兼容 pyotp.random_base32() 生成 Google Authenticator 兼容链接： totp = pyotp.TOTP('JBSWY3DPEHPK3PXP') totp.provisioning_uri(\"alice@google.com\", issuer_name=\"Secure App\") \u003e\u003e\u003e 'otpauth://totp/Secure%20App:alice%40google.com?secret=JBSWY3DPEHPK3PXP\u0026issuer=Secure%20App' hotp = pyotp.HOTP('JBSWY3DPEHPK3PXP') hotp.provisioning_uri(\"alice@google.com\", initial_count=0, issuer_name=\"Secure App\") \u003e\u003e\u003e 'otpauth://hotp/Secure%20App:alice%40google.com?secret=JBSWY3DPEHPK3PXP\u0026issuer=Secure%20App\u0026counter=0' Google Authenticator 需要传入账户名称和签发机构 issuer_name 参数。得到的链接可以生成二维码供 Google Authenticator 扫描。 2FA 缺点 双因素认证有一个最大的问题，那就是帐户的恢复。一旦密钥丢失，想要恢复登录，势必就要绕过双因素认证，这就形成了一个安全漏洞。除非准备两套双因素认证，一套用来登录，另一套用来恢复账户（前文所说的备用哈希代码）。 参考链接 一次性密碼 - 维基百科，自由的百科全书 双因素认证（2FA）教程 - 阮一峰的网络日志 基于时间的一次性密码算法 - 维基百科，自由的百科全书 RFC 4226 - HOTP: An HMAC-Based One-Time Password Algorithm HOTP和TOTP算法图解 - 简书 GitHub - pyotp/pyotp ","date":"2018-10-24","objectID":"/posts/a18b7/:4:0","tags":[],"title":"双因素认证2FA","uri":"/posts/a18b7/"},{"categories":["Python"],"content":"Flask-RESTful 是一个 Flask 扩展，用于快速构建 REST API。本文基于 Flask-RESTful 0.3.6 版本。 安装 安装： pipenv install flask-restful Minimal App: from flask import Flask from flask_restful import Resource, Api app = Flask(__name__) api = Api(app) class HelloWorld(Resource): def get(self): return {'hello': 'world'} api.add_resource(HelloWorld, '/') if __name__ == '__main__': app.run(debug=True) 运行： python3 app.py 集成 ","date":"2018-10-23","objectID":"/posts/e5c6e/:0:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"与 Flask App 集成 from flask import Flask from flask_restful import Api app = Flask(__name__) api = Api(app) 使用 factory function 时，可调用 flask_restful.Api 的 init_app 方法： from flask import Flask from flask_restful import Api api = Api() def create_app(): app = Flask(__name__) api.init_app(app) app = create_app() ","date":"2018-10-23","objectID":"/posts/e5c6e/:1:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"与 Blueprint 集成 from flask import Blueprint, Flask from flask_restful import Api app = Flask(__name__) bp_api = Blueprint('bp_api', __name__, url_prefix='/api') api = Api(bp_api) app.register_blueprint(api_bp) 路由 Flask-RESTful 使用了 Flask 中的 即插视图（Pluggable Views），可参考董伟明老师《Python Web 开发实践》P40。 Flask-RESTful 中的路由以资源为中心，视图类继承自 flask_restful.Resource。 from flask import Flask, request from flask_restful import Resource, Api app = Flask(__name__) api = Api(app) todos = {} class TodoSimple(Resource): def get(self, todo_id): return {todo_id: todos[todo_id]} def put(self, todo_id): todos[todo_id] = request.form['data'] return {todo_id: todos[todo_id]} api.add_resource(TodoSimple, '/\u003cstring:todo_id\u003e') if __name__ == '__main__': app.run(debug=True) 解析请求参数 ","date":"2018-10-23","objectID":"/posts/e5c6e/:2:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"基本用法 Flask-RESTful 的请求解析器会在 2.0 版本被删除。 一个 demo 如下： from flask_restful import reqparse parser = reqparse.RequestParser() parser.add_argument('rate', type=int, help='Rate cannot be converted') parser.add_argument('name') args = parser.parse_args() 首先新建解析器 reqparse.RequestParser 对象，然后使用 add_argument 方法添加参数，最后在路由方法中使用 parse_args 方法解析参数。 默认情况下，参数都是可选参数，在解析器中声明但未传入的参数值为 None。 ","date":"2018-10-23","objectID":"/posts/e5c6e/:3:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"Argument 常见参数 add_argument 接受 reqparse.Argument 实例，或传递给 reqparse.Argument 构造函数的参数。 构造函数常用参数有： name 参数名称 type 参数类型 required 必传参数，默认非必传 default 默认值 dest 添加到返回对象中的参数名 action 默认 “store”，设置为 “append” 即可将同名参数接收为一个列表 choices 参数可选值列表 trim 去掉参数头尾空格，默认不处理 nullable 允许参数为 None，默认不允许 help 参数的简短描述，在参数无效时替换默认的错误消息在响应中返回，替换默认的错误消息。可以使用 “{error_msg}” 来包含默认的错误消息。 location 从何种 flask.Request 对象属性中获取参数，默认为 “json” 和 “value”。多个 location 的参数会被组成为 MultiDict 对象。 ","date":"2018-10-23","objectID":"/posts/e5c6e/:4:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"自定义参数检查 可以传递一个函数给 type，在函数中对参数进行检查和处理。若参数不符合要求可抛出 ValueError，ValueError 的错误消息将在响应中返回。 parser = reqparse.RequestParser() def odd_number(value): if value % 2 == 0: raise ValueError(\"Value is not odd\") return value parser.add_argument('OddNumber', type=odd_number) parser.parse_args() 函数也可接收两个参数——参数值和参数名。方便于在错误消息中引用参数名。 def odd_number(value, name): if value % 2 == 0: raise ValueError(f\"The parameter '{name}' is not odd. You gave us the value: {value}\") return value 定义输出字段 ","date":"2018-10-23","objectID":"/posts/e5c6e/:5:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"基本用法 首先定义输出格式 dict，dict 中字段类型从设置为 fields中类型（会自动转换输出值）。其键是要呈现的对象上的属性或键的名称，其值是将格式化并返回该字段的值的类。 然后使用 marshal_with 装饰器绑定到请求方法上。最后在请求方法中返回数据库对象或字典即可。 from flask_restful import Resource, fields, marshal_with resource_fields = { 'name': fields.String, 'address': fields.String, 'date_updated': fields.DateTime(dt_format='rfc822'), } class Todo(Resource): @marshal_with(resource_fields, envelope='resource') def get(self, **kwargs): return db_get_todo() # 这里的对象可以是数据库对象，或者 dict 上面这个例子中，我们假定返回的自定义的数据库对象，有 name、address 和 date_updated 属性。对象中的其他属性将不会被返回。envelope 参数指定可选的关键字参数以包装结果输出。 装饰器 marshal_with 相当于： class Todo(Resource): def get(self, **kwargs): return marshal(db_get_todo(), resource_fields), 200 ","date":"2018-10-23","objectID":"/posts/e5c6e/:6:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"fields 常用类型 String(default=None, attribute=None) 字符串 Float(default=None, attribute=None) 浮点数 Boolean(default=None, attribute=None) 布尔型 Integer(default=0, **kwargs) 整数 FormattedString(src_str) 格式化字符串，自动替换 format 语法中的参数。例如： fields = { 'name': fields.String, 'greeting': fields.FormattedString(\"Hello {name}\") } data = { 'name': 'Doug', } marshal(data, fields) DateTime(dt_format='rfc822’, **kwargs) UTC时间，可以输出为 ‘rfc822’ 或者 ‘iso8601’ 格式。 Url(endpoint=None, absolute=False, scheme=None, **kwargs) url类型，类似 Flask 的 url_for 函数 Fixed(decimals=5, **kwargs) 固定小数位数的浮点数，用于价格等场景 Price 即 Fixed Arbitrary(default=None, attribute=None) 具有任意精度的浮点数 Nested(nested, allow_null=False, **kwargs) 嵌套类型 List(cls_or_instance, **kwargs) 列表类型 Raw(default=None, attribute=None) 提供了一个基本字段类，自定义字段类从该字段类继承。 ","date":"2018-10-23","objectID":"/posts/e5c6e/:7:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"重命名属性 如果内部字段名称和输出字段名称不同，可以使用 attribute 参数指定内部参数名称。 指定时，可以使用字符串： fields = { 'name': fields.String(attribute='private_name'), 'address': fields.String, } 使用函数： fields = { 'name': fields.String(attribute=lambda x: x._private_name), 'address': fields.String, } 嵌套属性： fields = { 'name': fields.String(attribute='people_list.0.person_dictionary.name'), 'address': fields.String, } ","date":"2018-10-23","objectID":"/posts/e5c6e/:8:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"增加默认值 使用 default 参数为输出增加默认值。仅有部分类型支持。 fields = { 'name': fields.String(default='Anonymous User'), 'address': fields.String, } ","date":"2018-10-23","objectID":"/posts/e5c6e/:9:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"自定义字段值 自定义字段需要继承 fields.Raw类并实现format方法。这对于使用整数存储的标识位字段非常有用。 class UrgentItem(fields.Raw): def format(self, value): return \"Urgent\" if value \u0026 0x01 else \"Normal\" class UnreadItem(fields.Raw): def format(self, value): return \"Unread\" if value \u0026 0x02 else \"Read\" fields = { 'name': fields.String, 'priority': UrgentItem(attribute='flags'), 'status': UnreadItem(attribute='flags'), } ","date":"2018-10-23","objectID":"/posts/e5c6e/:10:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"复杂结构 除了输出简单的一层 k-v 结构之外，也可以输出嵌套结构。 resource_fields = {'name': fields.String} resource_fields['address'] = {} resource_fields['address']['line 1'] = fields.String(attribute='addr1') resource_fields['address']['line 2'] = fields.String(attribute='addr2') resource_fields['address']['city'] = fields.String resource_fields['address']['state'] = fields.String resource_fields['address']['zip'] = fields.String data = { 'name': 'bob', 'addr1': '123 fake street', 'addr2': '', 'city': 'New York', 'state': 'NY', 'zip': '10468' } result = marshal(data, resource_fields) # result { \"name\": \"bob\", \"address\":{ \"line 1\": \"123 fake street\", \"line 2\": \"\", \"state\": \"NY\", \"zip\": \"10468\", \"city\": \"New York\" } } 地址字段实际上并不存在于数据对象上，但是任何子字段都可以直接从对象访问属性，就好像它们没有嵌套一样。 ","date":"2018-10-23","objectID":"/posts/e5c6e/:11:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"列表字段 使用 fields.List 输出列表字段。 \u003e\u003e\u003e from flask_restful import fields, marshal \u003e\u003e\u003e import json \u003e\u003e\u003e \u003e\u003e\u003e resource_fields = {'name': fields.String, 'first_names': fields.List(fields.String)} \u003e\u003e\u003e data = {'name': 'Bougnazal', 'first_names' : ['Emile', 'Raoul']} \u003e\u003e\u003e json.dumps(marshal(data, resource_fields)) \u003e\u003e\u003e '{\"first_names\": [\"Emile\", \"Raoul\"], \"name\": \"Bougnazal\"}' ","date":"2018-10-23","objectID":"/posts/e5c6e/:12:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"输出列表 有时，我们可能不想要输出 dict，而是要直接输出列表，可以利用 fields.List 和 fields.Nested 配合输出列表。 此时要使用 marshal_with_field 装饰器。 resource_fields = {'name': fields.String, 'age': fields.Integer} resource_list_fields = fields.List(fields.Nested(product_fields)) class ResourceList(Resource): @marshal_with_field(resource_list_fields) def get(self): data = [ dict(name='aaa', age=14), dict(name='bbb', age=15), ] return data 参考文档 Flask-RESTful — Flask-RESTful 0.3.6 documentation ","date":"2018-10-23","objectID":"/posts/e5c6e/:13:0","tags":[],"title":"使用Flask-RESTful构建RESTful API","uri":"/posts/e5c6e/"},{"categories":["Python"],"content":"在 Linux 系统和 Windows 系统中，我们使用 ~ 和 ~user 表示用户主目录。 cd ~/Downloads 但是 Python 的 os.path.abspath 函数会认为 ~ 表示目录名称： In [2]: os.path.abspath('~') Out[2]: '/Users/chi/Projects/~' 对此，Python 提供了 os.path.expanduser 函数，来解析 ~： In [3]: os.path.expanduser('~') Out[3]: '/Users/chi' 参考链接 os.path — Common pathname manipulations — Python 3.7.0 documentation ","date":"2018-09-26","objectID":"/posts/333e4/:0:0","tags":[],"title":"Python解析主目录相对路径","uri":"/posts/333e4/"},{"categories":["Infrastructure"],"content":"简介 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。Compose 可以使用 YAML 文件来配置应用程序的服务，然后可以从配置中使用单个命令，创建并启动所有服务。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 docker-compose.yaml docker-compose.yaml 和 docker-compose.yml 是 Docker Compose 的默认模版文件名称，格式为 YAML 格式。模板文件是使用 Compose 的核心。模版文件中使用的指令，与 Dockerfile 中的指令有相似之处。 docker-compose.yaml 中的配置为创建容器时的配置，Dockerfile 中的配置为创建镜像时的配置。 一般我们在第一行使用 version 声明模版文件使用的版本。 ","date":"2018-09-05","objectID":"/posts/b6f79/:0:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"build 和 image docker-compose 中的每个服务都必须通过 image 指令指定镜像或者 build 指令指定 Dockerfile 来自动构建生成镜像。 使用 build 指令时，要指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 使用 image 指令时，如果本地不存在，会自动尝试拉取镜像。 version:'3'services:mysql:image:mysql:5.7webapp:build:./dir 上述指令含义为，mysql 服务使用 mysql:5.7 镜像，webapp 服务使用 ./dir 目录下的 Dockerfile 文件构建镜像。 ","date":"2018-09-05","objectID":"/posts/b6f79/:1:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"depends_on 指定服务的依赖。服务启动时，必须先启动其依赖的其他服务。也就是说： 被依赖的服务会先启动； 启动当前服务时，也会启动其依赖的服务。 举例，celery 的服务依赖于 rabbitmq 服务和 redis 服务。 version:'3'services:celery:build:.depends_on:- redis- rabbitmqredis:image:redis:alpinerabbitmq:image:rabbitmq:alpine ","date":"2018-09-05","objectID":"/posts/b6f79/:2:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"environment 设置运行时的环境变量。可以使用 YAML 语法的数组格式或者字典格式。 environment:NAME:valueenvironment:- NAME=value 如果只定义环境变量名而不赋值，则从执行模版文件所在的 shell 环境变量中，或者从模版文件所在目录的 .env 文件中读取（模版文件执行时，会自动读取当前目录的 .env 环境变量文件），前者优先级较高。 environment:NAME: 另外要注意的是，变量值中用到的表达布尔含义的词语，需要放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些词有： y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF ","date":"2018-09-05","objectID":"/posts/b6f79/:3:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"env_file 从文件中获取环境变量。文件路径相对于模版文件路径。 env_file:- ./common.env- ./web.env 如果有变量名称与 environment 指令冲突，则以 environment 指令为准。 ","date":"2018-09-05","objectID":"/posts/b6f79/:4:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"volumes 设置目录映射或数据卷挂载。格式可以为 HOST:CONTAINER、HOST:CONTAINER:MODE 或 DATA_VOLUME:CONTAINER，模式可以为：ro 只读，rw 读写。 宿主机路径可以指定相对路径，注意指定相对路径时，路径要写完整，否则可能被认为是数据卷。 volumes:- /ui:/src- ./ui:src- ui:/src 上述第一个是绝对路径映射，第二个是相对路径映射，第三个是挂载名为 ui 的数据卷。 另外如果宿主机路径指向的是一个已存在的文件，则会映射文件到容器中，而不是目录。例如映射 mysql 的配置文件。 volumes:- ./conf/mysql.ini:/etc/mysql/conf.d/mrchiblog.cnf:ro ","date":"2018-09-05","objectID":"/posts/b6f79/:5:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"networks 配置容器连接的网络。为增强安全性，我们可以给应用指定不同的网络以隔离它们。网络需要在根层级声明和配置。 举例，我们有一个 web 应用，包含 web、nginx 和 mysql 三个服务。我们可以配置两个网络：后端 back-tire 和 前端 front-tire。其中 web 和 nginx 通信使用 front-tire，web 和 mysql 通信使用 back-tire，这样就将 nginx 和 mysql 隔离开来。 version:'3'networks:back-tire:front-tire:services:web:build:.networks:- back-tire- front-tiremysql:image:mysql:5.7networks:- back-tirenginx:image:nginx:alpinenetworks:- front-tire ","date":"2018-09-05","objectID":"/posts/b6f79/:6:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"ports 和 expose ports 指定容器端口到宿主机的映射。expose 只暴露端口供容器间通过网络访问，不映射到宿主机（不 expose 在同一网络中也是能够互相访问的）。 expose 指定暴露的端口就可以。 ports 映射有几种格式： 只指定容器端口，映射到宿主机随机端口； 指定宿主机端口和容器端口 HOST:CONTAINER，则映射到指定端口并监听 0.0.0.0； 指定宿主机监听地址、宿主机端口和容器端口 IP:HOST:CONTAINER。 version:'3'services:web:expose:- \"5000\"ports:- \"5000\"- \"5000:5000\"- \"127.0.0.1:5000:5000\" ","date":"2018-09-05","objectID":"/posts/b6f79/:7:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"working_dir 指定容器中工作目录，等同于 Dockerfile 中的 WORKDIR。 working_dir:/dir ","date":"2018-09-05","objectID":"/posts/b6f79/:8:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"command 覆盖容器启动后默认执行的命令。 command:echo\"hello\" ","date":"2018-09-05","objectID":"/posts/b6f79/:9:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"restart 指定容器退出后的重启策略。 restart:on-failure 有四种取值： no 默认值，退出后不重启； on-failure 出错退出（exit code 不为 0）时重启。 unless-stoped 除非显式停止或停止或重新启动Docker本身，否则重新启动容器。 always 总是重启； 生产环境可以适当设置为 on-failure 或者 unless-stoped。对于一些特殊应用，例如 ss，可以设置为 always。 注意： 重启策略仅在容器成功启动后生效。在这种情况下，成功启动意味着容器启动至少10秒并且Docker已开始监视它。这可以防止根本不启动的容器进入重启循环。 如果手动停止容器，则会忽略其重新启动策略，直到Docker守护程序重新启动或手动重新启动容器。这是防止重启循环的另一种尝试。 CLI 命令 ","date":"2018-09-05","objectID":"/posts/b6f79/:10:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"config 验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。 ","date":"2018-09-05","objectID":"/posts/b6f79/:11:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"build 构建（重新构建）项目中的服务镜像。 docker-compose build [options] [SERVICE...] ","date":"2018-09-05","objectID":"/posts/b6f79/:12:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"start 启动已经存在的服务容器。 docker-compose start [SERVICE...] ","date":"2018-09-05","objectID":"/posts/b6f79/:13:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"stop 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 docker-compose stop [options] [SERVICE...] 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 ","date":"2018-09-05","objectID":"/posts/b6f79/:14:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"restart 重启项目中的服务。 docker-compose restart [options] [SERVICE...] 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 ","date":"2018-09-05","objectID":"/posts/b6f79/:15:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"rm 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 docker-compose rm [options] [SERVICE...] 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 ","date":"2018-09-05","objectID":"/posts/b6f79/:16:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"up 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 docker-compose up [options] [SERVICE...] 选项： -d 在后台运行服务容器。 --no-color 不使用颜色来区分不同的服务的控制台输出。 --no-deps 不启动服务所链接的容器。 --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。 --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 --no-build 不自动构建缺失的服务镜像。 -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 如果 docker-compose.yaml 指定的环境变量发生改变，例如 environment 发生改变，或 env_file 指向的文件内容发生改变，up 命令执行时会重新创建容器。 ","date":"2018-09-05","objectID":"/posts/b6f79/:17:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"logs 查看服务容器的输出。 docker-compose logs [options][SERVICE...] 默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。 该命令在调试问题的时候十分有用。 FAQ ","date":"2018-09-05","objectID":"/posts/b6f79/:18:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"如何设置容器的时区 容器默认的时区为 UTC 时区，要设置为不同时区只需要在模版文件中设置 TZ 环境变量即可： environment:TZ:Asia/Shanghai 参考链接 命令说明 · Docker —— 从入门到实践 docker compose编排文件中如何设置容器的时区_博客园 关于Docker Compose的环境变量-Linux运维日志 Docker Compose | Docker Documentation ","date":"2018-09-05","objectID":"/posts/b6f79/:19:0","tags":[],"title":"学习Docker(6)-Docker Compose","uri":"/posts/b6f79/"},{"categories":["Infrastructure"],"content":"适用于 MySQL 5.6 和 MySQL 5.7 版本，其他版本未测试。 先说方法，修改 MySQL 配置文件的以下参数： [mysqld] performance_schema_max_table_instances=400 table_definition_cache=400 table_open_cache=256 performance_schema 主要用于收集数据库服务器性能参数，适当调小可以减少内存占用。甚至，可以将其完全关闭： [mysqld] performance_schema=OFF 经测试，关闭 performance_schema 后，MySQL 5.7 的内存占用仅有 30MB 左右，效果显著。可以在小内存 VPS 上开心的构建 web 服务了。 参考链接 MySQL5.7 内存一直好高， - V2EX MySQL 5.6内存占用过高解决方案 | 英特思瑞 MySQL :: MySQL 5.7 Reference Manual :: 25 MySQL Performance Schema ","date":"2018-09-05","objectID":"/posts/d61e3/:0:0","tags":[],"title":"减少MySQL内存占用","uri":"/posts/d61e3/"},{"categories":["Python"],"content":"stdout 中的缓存 首先来看一个例子： #!/usr/bin/env python3 import sys sys.stdout.write(\"stdout1 \") sys.stderr.write(\"stderr1 \") sys.stdout.write(\"stdout2 \") sys.stderr.write(\"stderr2 \") 将以上代码保存成 Python 文件运行。实际输出并不是： stdout1 stderr1 stdout2 stderr2 而是： stderr1 stderr2 stdout1 stdout2 原因是，虽然 stderr 和 stdout 默认都指向屏幕输出，但是： stderr 是无缓存的，程序向 stderr 输出字符会直接打印出来； stdout 是有缓存的，只有遇到换行或者积累到一定的大小，才会打印出来； 以上会影响 sys.stdout.write 和 print 的行为。 不缓存直接输出 如果不想让 stdout 缓存内容，有以下几种方案。 ","date":"2018-09-05","objectID":"/posts/bf0b4/:0:0","tags":[],"title":"Python中stdout的输出缓存","uri":"/posts/bf0b4/"},{"categories":["Python"],"content":"PYTHONUNBUFFERED 设置 PYTHONUNBUFFERED 环境变量为非空字符串： export PYTHONUNBUFFERED=1 或者在运行代码时指定： PYTHONUNBUFFERED=1 python3 test.py ","date":"2018-09-05","objectID":"/posts/bf0b4/:1:0","tags":[],"title":"Python中stdout的输出缓存","uri":"/posts/bf0b4/"},{"categories":["Python"],"content":"python -u 在运行 Python 文件时指定 -u 选项，效果等同于 PYTHONUNBUFFERED 环境变量。 python3 -u test.py 或者将 -u 选项加入到 Python 文件的 shebang 声明中，并赋予文件可执行权限并直接运行，与在运行 Python 文件时指定 -u 选项是等价的。 #!/usr/bin/env python3 -u chmod u+x test.py ./test.py 其他 在 Stack Overflow 上，有个高票答案利用了 sys.stdout 本质上是 file-object 的原理，利用 sys.stdout.flush 强制刷新缓冲区并上屏，并给出了使用自定义类复写 write 和 writelines 方法的代码。 #!/usr/bin/env python3 import sys class Unbuffered(object): def __init__(self, stream): self.stream = stream def write(self, data): self.stream.write(data) self.stream.flush() def writelines(self, datas): self.stream.writelines(datas) self.stream.flush() def __getattr__(self, attr): return getattr(self.stream, attr) sys.stdout = Unbuffered(sys.stdout) sys.stdout.write(\"stdout1 \") sys.stderr.write(\"stderr1 \") sys.stdout.write(\"stdout2 \") sys.stderr.write(\"stderr2 \") 但是经过测试，该方法在 Python 2.7.15 中输出正常，但在 Python 3.7 中输出为： stdout1 stdout2 stderr1 stderr2 原因尚不明确，不建议使用。 参考链接 python中stdout输出不缓存的设置方法_Python教程 | 帮客之家 python - Disable output buffering - Stack Overflow ","date":"2018-09-05","objectID":"/posts/bf0b4/:2:0","tags":[],"title":"Python中stdout的输出缓存","uri":"/posts/bf0b4/"},{"categories":["Python"],"content":"一对多关系联合查询 模型定义如下，Category 和 Post 是一对多的关系： class Category(db.Model): __tablename__ = \"category\" id = db.Column(db.Integer, primary_key=True, autoincrement=True) posts = db.relationship(\"Post\", backref=\"category\", lazy=\"dynamic\") class Post(db.Model): __tablename__ = \"post\" id = db.Column(db.Integer, primary_key=True, autoincrement=True) category_id = db.Column(db.Integer, db.ForeignKey(Category.id), nullable=False) 查询每个 Category 对应 Post 的数量并按照 Post 的个数从大到小排列： from sqlalchemy import func results = Category.query \\ .join(Post) \\ .add_columns(func.count(Post.id)) \\ .group_by(Category.id) \\ .order_by(func.count(Post.id).desc()) \\ .all() 多对多关系联合查询 模型定义如下，Label 和 Post 是多对多的关系： class Label(db.Model): __tablename__ = \"label\" id = db.Column(db.Integer, primary_key=True, autoincrement=True) posts = db.relationship( \"Post\", secondary=\"post_label_ref\", backref=db.backref(\"labels\", lazy=\"dynamic\"), lazy=\"dynamic\", ) class Post(db.Model): __tablename__ = \"post\" id = db.Column(db.Integer, primary_key=True, autoincrement=True) class PostLabelRef(db.Model): __tablename__ = \"post_label_ref\" post_id = db.Column(db.Integer, db.ForeignKey(Post.id), primary_key=True) label_id = db.Column(db.Integer, db.ForeignKey(Label.id), primary_key=True) 查询每个 Label 对应 Post 的数量并按照 Post 的个数从大到小排列。 results = Label.query \\ .join(PostLabelRef) \\ .join(Post) \\ .add_columns(func.count(Post.id)) \\ .group_by(Label.id) \\ .order_by(func.count(Post.id).desc()) \\ .all() 相比一对多关系的联合查询，多对多关系联合查询时需要 join 关系表。 参考链接 Flask-SQLAlchemy Query Join relational tables - Stack Overflow python - SqlAlchemy and Flask, how to query many-to-many relationship - Stack Overflow ","date":"2018-08-19","objectID":"/posts/ece99/:0:0","tags":[],"title":"Flask-SQLAlchemy联合查询","uri":"/posts/ece99/"},{"categories":["Python"],"content":"Todo Class Name中一段的翻译； 总则 Overriding Principle API公开给使用者部分的命名应当能明确地反映出其用途。 命名方式简述 Descriptive: Naming Styles 常见命名方法如下： 单个小写字母，如b； 单个大写字母，如B； 小写单词，如lowercase； 以下划线分隔的小写单词，如lower_case_with_underscores； 大写单词，如UPPERCASE； 以下划线分隔的大写单词，如UPPER_CASE_WITH_UNDERSCORES； 驼峰命名法，若有缩写名词则全字母大写，如CapitalizedWords； 首字母小写的驼峰，如mixedCase； 用下划线分隔单词的驼峰（巨丑，不推荐）。 Python中使用的四种特殊命名形式： _single_leading_underscore以单下划线开头表示只供内部使用； single_trailing_underscore_以单下划线结尾用于避免和Python关键字冲突； __double_leading_underscore以双下划线开头会在类内部被改变名字来避免被外部使用； __double_leading_and_trailing_underscore__以双下划线开头和结尾表示特殊对象或者属性，不要尝试自创这样的变量。 Python命名法 Prescriptive: Naming Conventions ","date":"2018-08-15","objectID":"/posts/383cb/:0:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"避免使用的名字 Names to Avoid 小写的l(klm)，大写的O(nop)，大写的I(hij)，不要把这三个字母用作单字母变量，会和数字0和1傻傻分不清楚～ ","date":"2018-08-15","objectID":"/posts/383cb/:1:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"包和模块的命名 Package and Module Names 模块名应当使用全小写字母，并且越短越好。必要时可以使用下划线来增强可读性。 包名也应当使用全小写字母，并且越短越好。但是不能使用下划线。 用C/C++写的Python模块以单下划线开头？（存疑） When an extension module written in C or C++ has an accompanying Python module that provides a higher level (e.g. more object oriented) interface, the C/C++ module has a leading underscore (e.g. _socket)。 ","date":"2018-08-15","objectID":"/posts/383cb/:2:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"类名 Class Names 类名应该使用驼峰命名法。 这段不会翻译： The naming convention for functions may be used instead in cases where the interface is documented and used primarily as a callable. 注意：类内部属性等的名字大多是一两个单词，命名方式与类名不同，后面会提到。只有两个例外——内建异常名和内建常量使用驼峰命名法。 ","date":"2018-08-15","objectID":"/posts/383cb/:3:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"异常命名 Exception Names 异常的类型是class，所以遵循class的命名规则，使用驼峰命名法。另外，如果你定义的异常实际上是一个error，命名时要加Error的后缀。 ","date":"2018-08-15","objectID":"/posts/383cb/:4:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"全局变量命名 Global Variable Names （我们希望全局变量是只用在一个模块中的全局变量）。全局变量的命名与函数命名相同（以下划线分隔的小写单词）？（存疑） (Let’s hope that these variables are meant for use inside one module only.) The conventions are about the same as those for functions. 模块如果被设计成由from M import *的方式来被导入，并且全局变量是不公开的话，那么应当使用__all__来阻止暴露全局变量；或者使用老的加前缀命名方式，例如下划线前缀。 ","date":"2018-08-15","objectID":"/posts/383cb/:5:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"函数命名 Function Names 函数命名应当是全小写字母，以下划线分隔单词以提高可读性。 首字母小写的驼峰命名法仅适用于已经成为主流的模块中的内容，例如threading.py，以保证向下的兼容性。 ","date":"2018-08-15","objectID":"/posts/383cb/:6:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"函数和方法的参数 Function and method arguments 实例方法的第一个参数永远是self，类方法的第一个参数永远是cls。 如果一个函数的参数名与Python关键字冲突，那么最好在参数名后缀单下划线，而不是使用缩写或者错误的拼写。举个栗子，class_要比clss好。当然最好的方式是使用同义词来避免这样的冲突。 ","date":"2018-08-15","objectID":"/posts/383cb/:7:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"方法名和实例变量 Method Names and Instance Variables 使用函数命名规则：即使用全小写字母，以下划线分隔单词以提高可读性。 不公开的方法和实例变量名称应该以单下划线开头。 下面几段看不太懂： To avoid name clashes with subclasses, use two leading underscores to invoke Python’s name mangling rules. Python mangles these names with the class name: if class Foo has an attribute named __a , it cannot be accessed by Foo.__a . (An insistent user could still gain access by calling Foo._Foo__a .) Generally, double leading underscores should be used only to avoid name conflicts with attributes in classes designed to be subclassed. Note: there is some controversy about the use of __names (see below). ","date":"2018-08-15","objectID":"/posts/383cb/:8:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"常量名 Constants 以下划线分隔的全大写单词。 参考链接 PEP 0008 – Style Guide for Python Code ","date":"2018-08-15","objectID":"/posts/383cb/:9:0","tags":[],"title":"PEP8命名规范","uri":"/posts/383cb/"},{"categories":["Python"],"content":"截止目前（2018-8-5），Whoosh 项目已经整整一年没有更新（最后提交于 2017-07-16），作者可能已经弃坑。 简介 Whoosh 是一个纯 Python 实现的全文检索引擎，虽然不如 Elasticsearch，但好处是纯 Python 实现易于集成，在小项目中应用广泛。 Whoosh 自带的分词器不支持中文分词。jieba 是一个中文分词组件，实现了一个供 Whoosh 调用的中文分词器。两者结合使用即可以实现中文全文检索。 快速上手 ","date":"2018-08-13","objectID":"/posts/7c3a9/:0:0","tags":[],"title":"whoosh和jieba实现中文全文检索","uri":"/posts/7c3a9/"},{"categories":["Python"],"content":"环境准备 pip3 install jieba pip3 install whoosh ","date":"2018-08-13","objectID":"/posts/7c3a9/:1:0","tags":[],"title":"whoosh和jieba实现中文全文检索","uri":"/posts/7c3a9/"},{"categories":["Python"],"content":"简单示例 #!/usr/bin/env python3 # coding=utf-8 import os from whoosh.index import create_in from whoosh.fields import TEXT, ID, Schema from jieba.analyse import ChineseAnalyzer # 创建 jieba 中文分词器对象 analyzer = ChineseAnalyzer() # 创建schema，使用 jieba 分词器对象 schema = Schema( title=TEXT(stored=True, analyzer=analyzer), path=ID(stored=False), content=TEXT(stored=True, analyzer=analyzer), ) # 存储schema信息至 indexdir 目录下 indexdir = \"indexdir/\" if not os.path.exists(indexdir): os.mkdir(indexdir) ix = create_in(indexdir, schema) # 按照schema定义信息，增加需要建立索引的文档 writer = ix.writer() writer.add_document( title=\"第一篇文档\", path=\"/a\", content=\"这是我们增加的第一篇文档\" ) writer.add_document( title=\"第二篇文档\", path=\"/b\", content=\"第二篇文档也很interesting！\" ) writer.commit() # 创建一个检索器 searcher = ix.searcher() # 检索标题中出现“文档”的文档 results = searcher.find(\"title\", \"文档\") # 检索出来的第一个结果 firstdoc = results[0].fields() print(firstdoc) # 打印出检索出的文档全部内容 print(results[0].highlights(\"title\")) # 高亮标题中的检索词 print(results[0].score) # bm25分数 searcher.close() 输出结果： {'content': '这是我们增加的第一篇文档', 'title': '第一篇文档'} 第一篇\u003cb class=\"match term0\"\u003e文档\u003c/b\u003e 0.5945348918918356 创建 Schema 使用 Whoosh 进行检索需要创建索引对象（index object），而索引对象的结构由 Schema 定义。 Schema 会列出索引对象的字段（field），字段是文档（document）中的一条信息，例如标题或者文本内容。字段可以通过参数，设置是否被搜索，是否在搜索结果中与被索引的字段一起返回。 类比 SQL 数据库表： Whoosh 索引 SQL 数据库表 Schema 表结构 field 字段 字段 field document 文档 记录 record 索引对象 整个表 举个例子： from whoosh.fields import TEXT, Schema from jieba.analyse import ChineseAnalyzer schema = Schema( title=TEXT(stored=True, analyzer=ChineseAnalyzer()), id=ID(stored=True), content=TEXT(stored=True), ) 上面的代码创建了一个 Schema，由 title、id 和 content 三个 filed 组成。title 和 content 的类型为 TEXT，id 的类型为 ID。 Whoosh 中为 field 预定义了以下类型： whoosh.fields.TEXT 用于正文。默认使用 whoosh.analysis.StandardAnalyzer 分词并索引，但不在检索结果中返回。 analyzer 参数指定分词器，stored 参数指定是否在检索结果中返回，phrase 参数指定是否允许分词检索。 whoosh.fields.KEYWORD 用于以空格或逗号分隔的关键字。默认索引，不在检索结果中返回，不能分词。 whoosh.fields.ID 用于日期、路径、URL，分类等等。字段的值作为整体被索引，默认不返回，不能分词。 whoosh.fields.STORED 用于在检索结果中展示的信息。不会被索引且无法检索，会在检索结果中返回。 whoosh.fields.NUMERIC 用于数字，可以存储整数或浮点数。 whoosh.fields.DATETIME 用于 datetime 对象。 whoosh.fields.BOOLEAN 用于布尔值。 其中 TEXT 和 ID 比较常用。 创建索引 有了 Schema 之后，就可以通过 Schema 创建索引。Whoosh 的索引使用文件存储，创建时传入目录名，索引文件就会存储在该目录下。 from whoosh.index import create_in, exists_in indexdir = \"indexdir/\" if not os.path.exists(indexdir): os.mkdir(indexdir) if not exists_in(indexdir): ix = create_in(indexdir, schema) exists_in 返回目录下是否存在索引，create_in 创建索引。如果在一个已经存在索引文件的目录下调用 create_in 创建索引，原索引会丢失。 exists_in 和 create_in 函数都可以传入 indexname 参数，指定创建的索引名称。 添加文档 有了索引对象后，就可以添加文档数据到索引中。 首先，获取索引对象： from whoosh.index import open_dir ix = index.open_dir(indexdir) open_dir 函数用于从指定目录中获取索引对象，该函数也可以传入 indexname 参数指定索引名称。 通过索引对象新建一个 IndexWriter 对象，该对象会锁住索引以进行写入，保证同时只有一个进程/线程进行写操作。 writer = ix.writer() 通过该 IndexWriter 对象的 add_document 方法添加 document，该方法接受关键字参数，与 Schema 定义保持一致。 writer.add_document( title=\"第一篇文档\", path=\"/a\", content=\"这是我们增加的第一篇文档\" ) 所有 docment 添加完成后，调用 commit 方法写入索引。 writer.commit() 检索结果 首先通过索引对象创建一个 Searcher 对象，该对象使用完成后应该被关闭，可以使用 Python 中的 with 语法。 with ix.searcher() as searcher: # 查询操作 pass 可以直接使用 find 方法进行检索： with ix.searcher() as searcher: results = searcher.find(\"title\", \"文档\") 或者先构造 QueryParser 对象，再使用 search 方法检索： from whoosh.qparser import QueryParser qp = QueryParser(\"content\", schema=myindex.schema) q = qp.parse(u\"hello world\") with ix.searcher() as s: results = s.search(q) search 方法可以使用 limit 参数指定返回结果的个数： results = s.search(q, limit=20) search_page 方法可以分页返回结果，默认每页 10 条结果，可以通过参数设置： # 每页20条结果，返回第 5 页的结果 results = s.search_page(q, 5, pagelen=20) 查询结果 results 对象类似 list，使用索引可以访问单个结果。 result = results[0] 单个结果的 score 属性可以得到对该 document 的权重评分，highlights 方法可以对指定 field 中的检索词进行高亮（加 b 标签）。 result.score result.highlights(\"title\") 在 Flask 中使用 Whoosh 在 Flask 中使用 Whoosh 最好用的扩展是 Flask-WhooshAlchemy，与 Flask-SQLAlchemy 无缝集成。可以直接索引数据库中的记录并通过数据库查询检索。 但这个项目已经许久没有更新，PyPI 上的版本竟然不支持 Python3，这里推荐使用从 Flask-WhooshAlchemy fork 开发的 Flask-WhooshAlchemyPlus 扩展，使用起来也非常简单，只需要以下步骤： 在 Flask 配置文件中定义 WHOOSH_BASE，即 Whoosh 索引文件的存储路径； 在定义数据库模型时指定 whoosh 索引字段和分词器； 调用扩展的 init_app(app) 方法初始化； 在查询中使用 whoosh_search 进行检索，返回的结果为 query 对象，可以继续进行筛选，排序等，最后返回数据库记录； 详细请参考 Flask-WhooshAlchemyPlus 的文档。 Jieba 延迟加载机制 jieba 采用延迟加载，import jieba 和 jieba.Tokenizer() 不会立即触发词典的加载，一旦有必要才开始加载词典构建前缀字典。 由于此机制，在初次查询时才会触发词典加载（大约 1 秒钟时间）。我们可以手动加载词典： import jieba jieba.initialize() 在 Flask 应用中，可以在创建 app 时调用上述代码。 参考链接 whoosh+jieba：python下实现中文全文检索 | Jey Zhang whoosh使用笔记 | 程序媛 Whoosh 2.7.4 documentation — Whoosh 2.7.4 documentation GitHub - Revolution1/Flask-WhooshAlchemyPlus ","date":"2018-08-13","objectID":"/posts/7c3a9/:2:0","tags":[],"title":"whoosh和jieba实现中文全文检索","uri":"/posts/7c3a9/"},{"categories":["Infrastructure"],"content":"Docker 容器的网络连接 ","date":"2018-08-11","objectID":"/posts/be138/:0:0","tags":[],"title":"学习Docker(5)-Docker服务管理","uri":"/posts/be138/"},{"categories":["Infrastructure"],"content":"Docker 客户端和守护进程 Docker 为 c/s 架构，客户端和守护进程支持以下三种socket： unix:///var/run/docker.sock tcp://host:port fd://socket 自定义的 Docker 客户端 可以通过 Remote API 与 Docker守护进程进行通信。 ","date":"2018-08-11","objectID":"/posts/be138/:1:0","tags":[],"title":"学习Docker(5)-Docker服务管理","uri":"/posts/be138/"},{"categories":["Infrastructure"],"content":"Docker 客户端远程访问 Docker 守护进程使用 -H —-host 选项指定 socket； $ sudo dockerd -H unix:///var/run/docker.sock -H tcp://192.168.59.106 -H tcp://10.10.10.2 Docker 客户端使用 -H —-host 选项 $ docker -H tcp://0.0.0.0:2375 ps 或者指定 DOCKER_HOST 环境变量指定 socket $ export DOCKER_HOST=\"tcp://0.0.0.0:2375\" $ docker ps ","date":"2018-08-11","objectID":"/posts/be138/:2:0","tags":[],"title":"学习Docker(5)-Docker服务管理","uri":"/posts/be138/"},{"categories":["Infrastructure"],"content":"Docker 容器的互联 Docker 容器使用虚拟网桥与宿主机通信，默认网段为 172.17.42.1/16。 虽然同一宿主机上的 Docker 容器可以互相访问，但由于 Docker 容器的 IP 地址在容器启动时分配，所以容器间不能通过指定 IP 的方式互相连接。 要链接到其他容器，可以在容器启动时添加 —-link 参数： docker run —-link=[CONTAINER_NAME or CONTAINER_ID]:[ALIAS] ALIAS 是给被链接容器设置的别名，可以在容器中直接使用这个名字访问被链接容器。 如果要禁止容器的互相访问，设置 Docker 守护进程的 --icc 参数为 false。 如果只允许特定容器的互相访问： 守护进程设置参数 —-icc=false（默认为 true）和 --iptables=true； 相互访问的容器设置 —-link 参数。 Docker 容器的数据管理 ","date":"2018-08-11","objectID":"/posts/be138/:3:0","tags":[],"title":"学习Docker(5)-Docker服务管理","uri":"/posts/be138/"},{"categories":["Infrastructure"],"content":"数据卷 有两种方式挂载数据卷。 一种是，在 Dockerfile 构建文件中使用 VOLUME 命令创建数据卷。通过这种方式创建的数据卷，在容器启动时会被映射到宿主机上不存在的随机目录。不能用于不同容器之间的共享。 另一种是，使用 -v，—-volume 参数在容器启动时挂载数据卷： docker run -v [宿主机目录]:[容器中目录]:[访问权限] 容器中目录必须为绝对路径 访问权限可以不指定，可选值为： wr 读写（默认值）; ro 只读； ","date":"2018-08-11","objectID":"/posts/be138/:4:0","tags":[],"title":"学习Docker(5)-Docker服务管理","uri":"/posts/be138/"},{"categories":["Infrastructure"],"content":"数据卷容器 一个容器挂载数据卷，其他容器通过挂载这个容器实现数据共享。挂载数据卷的容器，被称之为数据卷容器。 其他容器通过 —volumes-from 指令在运行时挂载数据卷容器 docker run —-volumes-from [数据卷容器名] 下面是一个实例。 首先，我们新建一个 Dockerfile 文件，在文件中创建数据卷 /datavolume。 FROMubuntu:latestVOLUME/datavolumeCMD bash 使用该文件构建镜像 dv docker build -t dv - \u003c Dockerfile 新建一个数据卷容器 dv1，把数据卷 /datavolume 映射到宿主机 ~/Downloads 目录 docker run --name dv1 -it -v ~/Downloads:/datavolume dv 此时该容器已经挂载了 /datavolume 数据卷，我们在数据卷中新建文件 dv1.txt，然后退出 dv1 的 shell，dv1 停止运行。 echo \"\" \u003e /datavolume/dv1.txt 基于 Ubuntu 镜像新建容器 dv2，把 dv1 作为数据卷容器 docker run --name dv2 --volumes-from dv1 -it ubuntu 基于 Ubuntu 镜像新建容器 dv3，把 dv1 作为数据卷容器 docker run --name dv3 --volumes-from dv1 -it ubuntu 在 dv2 和 dv3 中访问 /datavolume 目录，都能看到我们新建的 dv1.txt 文件。 删除 dv1 容器 docker rm dv1 在 dv2 中删除文件 dv1.txt，宿主机中 ~/Downloads 目录中文件也已经被删除。 查看 dv2 容器的信息，可以看到 dv2 容器中 /datavolume 数据卷直接映射到了宿主机的 ~/Downloads 目录 docker inspect dv2 该数据卷容器的作用仅仅在于传递配置信息（映射关系）。即使删除数据卷容器，容器与宿主机的映射关系仍然存在。 ","date":"2018-08-11","objectID":"/posts/be138/:5:0","tags":[],"title":"学习Docker(5)-Docker服务管理","uri":"/posts/be138/"},{"categories":["Infrastructure"],"content":"数据卷的备份和还原 使用 -—volumes-from 挂载数据卷容器 使用 -v 挂载备份目录 使用 tar 命令将数据卷容器目录打包放到备份目录，即实现了数据卷的备份。 ","date":"2018-08-11","objectID":"/posts/be138/:6:0","tags":[],"title":"学习Docker(5)-Docker服务管理","uri":"/posts/be138/"},{"categories":["Infrastructure"],"content":"镜像是生成容器的模版，镜像应该是无状态的，不包含具体的配置。 构建镜像有两种方式：从已有的容器构建，从 Dockerfile 构建。 从容器构建 基于容器创建一个新镜像。 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 该操作会将容器的文件更改或设置提交到新镜像中，但不包含容器中挂载的数据卷。 —-author -a 指定镜像作者，例如 “name email@email.com”； -—message -m commit 信息； —-change -c 创建镜像时，应用 Dockerfile 指令； --pause -p 构建镜像时停止容器运行。 docker commit -c \"EXPOSE 80\" c3f279d17e0a svendowideit/testimage:version4 从 Dockerfile 构建 ","date":"2018-08-10","objectID":"/posts/d9d3c/:0:0","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"构建命令 docker build [OPTIONS] PATH | URL | - 该 docker build 命令从 Dockerfile 和 “上下文” 构建 Docker 镜像。上下文提供构建过程中引用的文件。 选项： -t 指定镜像名称和 tag，可以有多个 -t 参数； -f 指定 Dockerfile，默认为 上下文根目录下的 Dockerfile 文件。 --build-arg 指定构建时的参数，比如设置代理 --build-arg HTTP_PROXY=http://10.20.30.2:1234； 如下是一个使用参数的例子 docker build -f Dockerfile.debug -t whenry/fedora-jboss:latest -t whenry/fedora-jboss:v2.1 . 使用 Dockerfile.debug 文件作为 Dockerfile 文件，使用当前目录作为上下文目录，生成两个镜像，名称为 whenry/fedora-jboss，tag 分别为 latest 和 v2.1。 传参： 传入 URL 和 PATH 时，构建的上下文是位于 PATH 或 URL 中的文件集。 传入 - 表示从 STDIN 中读取 Dockerfile，此时没有上下文。 如果传入的参数是 URL，该 URL 可以指向三种资源：Git 仓库、tarball打包文件和纯文本文件。 ","date":"2018-08-10","objectID":"/posts/d9d3c/:1:0","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"Git 仓库 当 URL 参数指向 Git 仓库时，仓库为构建上下文。系统递归地获取仓库和子模块内容，但不会保留提交历史记录。 如果 URL 中包含片段（fragment），则会使用 git pull -—recursive 获取仓库的所有分支和子模块。 在 fragment 中，还可以指定上下文的配置，用 : 分隔。: 之前为分支、tag 或 remote ref，: 之后为仓库的一个子目录，该子目录将用作构建上下文。 例如下面的命令将使用 container 分支的 docker 目录作为上下文： docker build https://github.com/docker/rootfs.git#container:docker 参考如下： 构建语法后缀 使用的提交 使用构建上下文 myrepo.git refs/heads/master / myrepo.git#mytag refs/tags/mytag / myrepo.git#mybranch refs/heads/mybranch / myrepo.git#pull/42/head refs/pull/42/head / myrepo.git#:myfolder refs/heads/master /myfolder myrepo.git#master:myfolder refs/heads/master /myfolder myrepo.git#mytag:myfolder refs/tags/mytag /myfolder myrepo.git#mybranch:myfolder refs/heads/mybranch /myfolder ","date":"2018-08-10","objectID":"/posts/d9d3c/:1:1","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"Tarball 打包文件 如果将 URL 指向远程的 tarball 压缩文件，文件将会在运行 Docker 守护程序的主机被下载（该主机不一定是发出构建命令的主机），解压缩后作为构建时的上下文。 Tarball上下文必须是符合标准 tar UNIX 格式的 tar 档案，并且可以使用 xz、bzip2、gzip 或 identity（无压缩）格式中的任何一种进行压缩。 如下，Docker守护程序将获取 context.tar.gz 并将其用作构建上下文。 docker build http://server/context.tar.gz 或者通过 - 从 STDIN 读取： docker build - \u003c context.tar.gz ","date":"2018-08-10","objectID":"/posts/d9d3c/:1:2","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"文本文件 通过 URL 指定一个远端的 Dockerfile 文件： docker build http://server/Dockerfile 或者通过 - 和 STDIN 指定一个本地的 Dockerfile 文件： docker build - \u003c Dockerfile 这两种情况下，没有上下文可以使用，-f 和 --file 选项会被忽略。 ","date":"2018-08-10","objectID":"/posts/d9d3c/:1:3","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"Dockerfile 指令 Dockerfile中的注释以 # 开头。 ","date":"2018-08-10","objectID":"/posts/d9d3c/:2:0","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"总览 FROM 从哪个基础镜像派生，必须是 Dockerfile 文件的第一条非注释指令； LABEL 生成镜像的一些信息，如 name、description 和 maintainer 等等； RUN 构建时执行的命令，用于生成环境、复制文件等，RUN 命令可以有多条； EXPOSE 随机映射端口； CMD 和 ENTRYPOINT 容器运行时执行的命令，只能有一条； ADD 和 COPY 复制文件或目录到 Docker 镜像中； VOLUME 随机映射数据卷； WORKDIR 指定运行时工作目录，通常使用绝对路径； ENV 设置执行时环境变量； USER 指定运行时用户，格式为 \u003cname|uid\u003e[:\u003cgroup|gid\u003e]； ONBUILD 构建触发器，当该镜像被作为基础镜像构建其他镜像时执行； MAINTAINER 不推荐使用，请使用 LABEL 替代； ","date":"2018-08-10","objectID":"/posts/d9d3c/:2:1","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"shell 模式和 exec 模式 RUN、CMD 和 ENTRYPOINT 命令都有两种格式。以 RUN 举例： shell 模式，形如 RUN \u003ccommand\u003e，实际在构建过程中执行时命令为 /bin/sh -c \u003ccommand\u003e，例如： RUN echo \"hello\" exec 模式，形如 RUN [\"executable\", \"param1\", \"param2\"] RUN [\"/bin/bash\", \"-c\", \"echo\", \"hello\"] 区别在于： 运行时的环境变量（CMD 和 ENTRYPOINT），shell 模式能够访问，exec 模式不能访问，因为 exec 模式直接执行命令不通过 shell； 在 Dockerfile 中使用 ENV 定义的环境变量，shell 模式可以使用 ${ENV_NAME} 或者 $ENV_NAME 的形式访问，exec 模式不能访问； 运行时（CMD 和 ENTRYPOINT），shell 模式命令不是 PID1 进程，exec 模式命令是 PID1 进程。 另外，exec 模式的指令会作为 JSON 列表被读取，因此要使用双引号而不是单引号。 ","date":"2018-08-10","objectID":"/posts/d9d3c/:2:2","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"RUN、CMD 和 ENTRYPOINT RUN 命令在构建过程中执行。 CMD 和 ENTRYPOINT 指定了容器运行时的默认指令。 CMD 和 ENTRYPOINT 命令单独使用时： CMD 和 ENTRYPOINT 单独使用时只能有一条（如果有多条指令，只有最后一条会生效）。 如果容器运行时指定了运行指令，CMD 指令会被覆盖，但 ENTRYPOINT 指令会被执行； 如果容器运行时指定了 --entrypoint 参数，ENTRYPOINT 指令会被覆盖； CMD 和 ENTRYPOINT 命令配合使用时（都要在 exec 模式下）： ENTRYPOINT 指令作为运行指令，CMD 指令作为运行指令的参数； 容器运行时可以替换 CMD 中指定的运行参数； 举个例子，以下 Dockerfile 文件构建的镜像 FROMubuntu:latestENTRYPOINT [\"/bin/echo\", \"Hello\"]CMD [\"world\"] 执行时 $ docker run [image] Hello world $ docker run [image] docker Hello docker ","date":"2018-08-10","objectID":"/posts/d9d3c/:2:3","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"ADD 和 COPY 都可以复制文件或目录到 Docker 镜像中。 共同点： 源路径最好是相对路径（相对构建上下文目录），只能是上下文目录的子目录或文件； 目标路径可以是 Docker 镜像中的绝对路径，或相对于 WORKDIR 的相对路径； 不同点： ADD 可以接受本地的 tar 压缩文档并解压复制，或者远程的目录。 如果只是单纯复制文件，使用 COPY 就可以； ","date":"2018-08-10","objectID":"/posts/d9d3c/:2:4","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"VOLUME 指定数据卷挂载点，容器运行时可以在该挂载点上挂载数据卷。 格式可以是 JSON 字符串数组，或者以空格分隔的普通字符串，以下是等价的： VOLUME [\"/var/log/\", \"/var/db\"]VOLUME/var/log /var/db ","date":"2018-08-10","objectID":"/posts/d9d3c/:2:5","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"构建过程 使用 Dockerfile 的构建过程 从基础镜像运行一个容器； 执行 Dockerfile 中的下一条指令，对容器作出修改； 执行类似 commit 的操作，提交一个新的镜像； 基于刚提交的镜像运行一个新容器； 重复步骤 2～4，直到 Dockerfile 中的所有指令执行完成； 删除中间层容器。 从以上过程可以看出，Dockerfile 构建过程中会生成中间层镜像并被保留。 使用 docker history \u003cimage name\u003e 可以查看一个镜像的构建过程： $ docker history ubuntu IMAGE CREATED CREATED BY SIZE COMMENT 735f80812f90 2 weeks ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0B \u003cmissing\u003e 2 weeks ago /bin/sh -c mkdir -p /run/systemd \u0026\u0026 echo 'do… 7B \u003cmissing\u003e 2 weeks ago /bin/sh -c sed -i 's/^#\\s*\\(deb.*universe\\)$… 2.76kB \u003cmissing\u003e 2 weeks ago /bin/sh -c rm -rf /var/lib/apt/lists/* 0B \u003cmissing\u003e 2 weeks ago /bin/sh -c set -xe \u0026\u0026 echo '#!/bin/sh' \u003e /… 745B \u003cmissing\u003e 2 weeks ago /bin/sh -c #(nop) ADD file:4bb62bb0587406855… 83.5MB ","date":"2018-08-10","objectID":"/posts/d9d3c/:3:0","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"构建缓存 Docker 在构建时，如果曾经执行过相同的操作，会调用之前构建时生成的镜像缓存，从而加快构建速度。 但一些情况下，我们不希望使用构建缓存，比如构建时执行 apt update 等指令，我们希望获取的是最新的软件包版本。此时有两种方法可以避免使用缓存： build 时使用 —-no-cache 参数； 在 Dockerfile 中使用 ENV REFRESH_DATE XXX 来标识缓存刷新时间，在该时间后进行构建不会使用上次的缓存。 ","date":"2018-08-10","objectID":"/posts/d9d3c/:4:0","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"提高构建效率 合理使用构建缓存； 仅向上下文目录中添加 Dockerfile 文件和构建所需的文件； 使用 .dockerignore 排除上下文目录中的文件和目录。 ","date":"2018-08-10","objectID":"/posts/d9d3c/:5:0","tags":[],"title":"学习Docker(4)-构建镜像","uri":"/posts/d9d3c/"},{"categories":["Infrastructure"],"content":"docker images 列出镜像列表。 docker images [OPTIONS] [REPOSITORY[:TAG]] --all -a 列出所有镜像（默认会隐藏中间层镜像）； —-no-trunc 显示完整的信息，如完整的 ID； --quiet -q 只列出镜像 ID。 另外，还可以只展示指定名称和 TAG 的镜像： $ docker images java:8 REPOSITORY TAG IMAGE ID CREATED SIZE java 8 308e519aac60 6 days ago 824.5 MB docker rmi 删除一个或多个镜像。 docker rmi [OPTIONS] IMAGE [IMAGE...] --force -f 强制删除镜像。 --no-prune 不删除没有标签的父镜像。 当多个不同名称的镜像拥有相同的 ID 时，不能通过 ID 删除多个镜像，需要使用 -f 参数。 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE test1 latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) test latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) test2 latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) $ docker rmi fd484f19954f Error: Conflict, cannot delete image fd484f19954f because it is tagged in multiple repositories, use -f to force 2013/12/11 05:47:16 Error: failed to remove one or more images 删除所有镜像 docker rmi $(docker images -a -q) docker inspect 展示镜像的底层信息。 docker inspect [OPTIONS] NAME|ID [NAME|ID...] docker search 搜索 Docker Hub 上的镜像 docker search [OPTIONS] TERM —-limit 最大搜索结果数量，默认值为 25。 返回的结果中，会显示出镜像 star 的数量、是否官方镜像和是否自动构建。 docker pull 从仓库拉取镜像或者 repository。如果不传 TAG 名称，默认 TAG 为 latest。 docker pull [OPTIONS] NAME[:TAG|@DIGEST] --all -a 下载 repository 中所有 TAG 的镜像。 该步骤不是必须的，如果本地镜像不存在，docker run 在执行时会自动从 Docker Hub 拉取镜像。 从自定义仓库（比如镜像站仓库）拉取镜像，例如： docker pull myregistry:5000/testing/test-image 表示从 myregistry 的 5000 端口拉取 testing/test-image 镜像。 docker push 向仓库推送镜像或 repository docker push [OPTIONS] NAME[:TAG] 如果向 Docker Hub 推送，需要拥有 Docker Hub 账户。 向自定义仓库推送： docker push myregistry:5000/testing/test-image docker tag 从源镜像创建新镜像 docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] 源镜像可以是名称 docker tag httpd fedora/httpd:version1.0 名称 + TAG docker tag httpd:test fedora/httpd:version1.0.test 或者 ID docker tag 0e5574283393 fedora/httpd:version1.0 如果目标镜像要推送到自定义仓库，需要指定自定义仓库地址和端口。 docker tag 0e5574283393 myregistryhost:5000/fedora/httpd:version1.0 ","date":"2018-08-09","objectID":"/posts/9fa19/:0:0","tags":[],"title":"学习Docker(3)-镜像基本操作","uri":"/posts/9fa19/"},{"categories":["Infrastructure"],"content":"docker run 该命令用于在新容器中运行 image，IMAGE 可以为 image 的名称或者 ID。 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] -p --publish 映射指定端口； -P --publish-all 映射容器暴露的所有端口到随机端口； -i 和 -t 两者常常配合使用前者开启 STDIN，后者分配一个 TTY。共同使用可以进入容器的 shell；退出时，ctrl+p 再 ctrl+q，可以保持容器在后台运行不终止。 --name 指定容器名称； -d --detach 在后台运行 container，并输出容器的 ID； —-rm 容器停止后自动删除容器。 -p 参数映射端口有以下几种形式： -p 80 映射容器的 TCP 80 端口到宿主机随机端口； -p 8080:80 映射容器的 TCP 80 端口到宿主机的 8080 端口； -p 127.0.0.1:8080:80 映射容器的 TCP 80 端口到宿主机的 8080 端口，并监听 127.0.0.1； -p 8080:80/udp 映射 UDP 端口； 举例说明： docker run -p 80:80 nginx 使用 nginx 镜像新建一个 container，在前台运行 nginx，将容器的 80 端口映射到宿主机的 80 端口。访问 http://localhost/ 就能够看到 nginx 的欢迎页面，使用 ctrl+c 终止运行。 如果命令执行时本地不存在镜像，会直接从 Docker Hub 拉取镜像。 docker ps 列出容器。 docker ps [OPTIONS] -a 列出所有容器，不加该参数只会列出运行中的容器。 -q 只列出容器 ID。 --no-trunc 显示完整的容器信息，包括完整的 ID，运行的命令等； docker start 启动一个或多个已经停止的容器。 docker start [OPTIONS] CONTAINER [CONTAINER...] docker rm 删除一个或者多个容器。默认情况下不能删除正在运行的容器。 docker rm [OPTIONS] CONTAINER [CONTAINER...] -f 强制删除容器（使用 SIGKILL），该参数可以删除正在运行的容器。 与 docker ps 组合删除所有容器的命令： docker rm $(docker ps -a) docker attach 将本地 STDIN，STDOUT 和 STDERR 附加到正在运行的容器。 docker attach [OPTIONS] CONTAINER 适用于连接在后台运行的容器的shell等。比如: docker run -it ubuntu bash ctrl+p 再 ctrl+q 退出后，容器仍然在后台运行，需要再次进入容器 shell 的时候，就可以使用本命令。 docker logs 查看容器日志。 docker logs [OPTIONS] CONTAINER —-tail n 输出末尾 n 行，默认为 all，即输出日志全部内容。 -f 同 tail 命令的 -f 参数，实时输出最新日志内容； -t 输出日志时添加时间戳。 docker stop 停止正在运行的一个或多个容器。发送 SIGTERM 信号给容器中的主进程，超过等待时间后会再发送 SIGKILL 信号。 docker stop [OPTIONS] CONTAINER [CONTAINER...] -t 设置等待时间，默认 10 秒。 docker kill 杀掉正在运行的一个或多个容器。直接发送 SIGKILL 信号。 docker kill [OPTIONS] CONTAINER [CONTAINER...] docker top 查看容器中正在运行的进程。 docker top CONTAINER [ps OPTIONS] docker exec 在运行的容器中运行命令。 docker exec [OPTIONS] CONTAINER COMMAND [ARG...] -i、-t、-d 选项同 docker run； docker cp 在宿主机和 Docker 容器之间拷贝文件。 docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH - 代表标准输入输出。 docker port 展示容器的所有端口映射或特定端口映射。 docker port CONTAINER [PRIVATE_PORT[/PROTO]] 例如： $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b650456536c7 busybox:latest top 54 minutes ago Up 54 minutes 0.0.0.0:1234-\u003e9876/tcp, 0.0.0.0:4321-\u003e7890/tcp test $ docker port test 7890/tcp -\u003e 0.0.0.0:4321 9876/tcp -\u003e 0.0.0.0:1234 $ docker port test 7890/tcp 0.0.0.0:4321 $ docker port test 7890/udp 2014/06/24 11:53:36 Error: No public port '7890/udp' published for test $ docker port test 7890 0.0.0.0:4321 docker inspect 展示容器的底层信息。比如容器的 IP 地址，运行的命令等等。 docker inspect [OPTIONS] NAME|ID [NAME|ID...] docker stats 实时展示容器资源使用量，包括 CPU、内存、网络、磁盘等。 docker stats [OPTIONS] [CONTAINER...] 结果： CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS d384e1e2bab2 container1 0.07% 310.4MiB / 738.3MiB 42.05% 2.14MB / 58.6kB 72.8MB / 16.8MB 7 18097b8fd0ce container2 0.14% 67.96MiB / 738.3MiB 9.20% 75.9kB / 74.9kB 78.8MB / 1.61MB 2 34840174a49b container2 0.05% 14.93MiB / 738.3MiB 2.02% 59.8kB / 2.14MB 58.1MB / 12.7MB 30 75f1f2a10ab4 container2 0.13% 632KiB / 738.3MiB 0.08% 1.01kB / 0B 1.77MB / 266kB 4 e1e70fe93c75 container3 0.11% 43.36MiB / 738.3MiB 5.87% 75.9kB / 74.9kB 54.5MB / 999kB 85 ","date":"2018-08-09","objectID":"/posts/1c21f/:0:0","tags":[],"title":"学习Docker(2)-容器基本操作","uri":"/posts/1c21f/"},{"categories":["Infrastructure"],"content":"简介 ","date":"2018-08-08","objectID":"/posts/80148/:0:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"环境配置的问题 软件开发中的一大问题，就是环境配置。开发、测试和生产环境不完全相同，需要复杂的配置才能在新机器上部署代码。 ","date":"2018-08-08","objectID":"/posts/80148/:1:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"虚拟机和 Linux 容器 虚拟机（virtual machine）可以在操作系统里虚拟出另一个操作系统，可以将配置好环境的操作系统做成镜像复制到其他机器上运行，是带环境安装的一种解决方案。但由于虚拟机是虚拟化了整个操作系统，因此有资源占用多、冗余步骤多和启动慢的缺点。 Linux 容器（Linux Container，缩写为 LXC）是另一种虚拟化方案。它不是模拟一个完整的操作系统，而是对进程进行隔离。Linux 容器是进程级别的，容器中的进程使用的资源都是虚拟的。相比虚拟机，Linux 容器启动快、资源占用少、体积小。 ","date":"2018-08-08","objectID":"/posts/80148/:2:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"Docker 是什么 Docker 是 PaaS 提供商 dotCloud 开源的一个基于 LXC 的高级容器引擎，源代码托管在 Github 上, 基于 go 语言并遵从 Apache2.0 协议开源。是目前最流行的 Linux 容器解决方案。 Docker 将应用程序和该程序的依赖，打包在镜像（Image）文件中。运行文件可以生成容器（Container），程序就在容器中运行。Docker 接口简单，用户可以方便的构建和使用容器，并进行版本管理、复制、分享、修改等操作。 Docker 分为 CE（社区版）和 EE（企业版）两个版本，企业版包含了一些收费服务，个人开发者一般用不到。 ","date":"2018-08-08","objectID":"/posts/80148/:3:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"Docker 的用途 Docker 主要有三大用途。 **提供一次性的运行环境。**如本体测试他人的软件、持续集成的时候提供单元测试和构建的环境。 **提供弹性的云服务。**Docker 容器随开随关的特性，很适合动态扩容和缩容。 **组建微服务架构。**在一台机器上跑多个容器，每个容器运行不同的服务，在本机就可以模拟出微服务架构。 ","date":"2018-08-08","objectID":"/posts/80148/:4:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"Docker 的基本组成 Docker 包含了以下几个主要部分：Client（客户端）、Deamon（守护进程）、Image（镜像）、Container（容器）和 Registry（仓库）。 Docker 为 C/S 架构，用户通过 Client 向 Deamon 发出指令，Deamon 处理完后返回结果给 Client； Image 是 Container 的模版文件，定义了代码和执行环境； Container 是代码执行单元，由 Image 新建一个 Container 来执行代码； Registry 类似 Github，可以为公开或私有，用来存储和管理镜像，官方公开仓库 Docker Hub； 类比 Docker 和 Supervisor： Docker Supervisor Client supervisorctl Deamon supervisord Image program 的配置文件，program01.conf Container supervisord 根据 program 配置文件启动的应用进程。 安装 ","date":"2018-08-08","objectID":"/posts/80148/:5:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"MacOS brew cask install docker ","date":"2018-08-08","objectID":"/posts/80148/:6:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"Ubuntu 和 树莓派 Ubuntu 参考 Get Docker CE for Ubuntu | Docker Documentation。 树莓派参考 Get Docker CE for Debian | Docker Documentation。 一些安全方面的配置 Post-installation steps for Linux | Docker Documentation。 ","date":"2018-08-08","objectID":"/posts/80148/:7:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"安装完成后 验证安装是否成功： docker version # or docker info docker 服务管理： # service 命令的用法 $ sudo service docker start # systemctl 命令的用法 $ sudo systemctl start docker 上手实例 ","date":"2018-08-08","objectID":"/posts/80148/:8:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"hello world 从 官方的 Docker Hub 抓取 image 到本地： docker pull library/hello-world docker image pull 从仓库抓取 image 文件，library 是 image 文件在仓库中所在的组，hello-world 是 image 文件的名字。 官方提供的 image 都放在 library 组中，该组是默认组，因此组名可以省略： docker pull hello-world 抓取后，查看本机的 image 文件： docker images 创建 container 运行 docker run hello-world docker run 命令会从 image 文件，生成一个正在运行的 container 实例。如果本地没有指定的 image 文件，会自动从仓库抓取，前面的 docker pull 命令并不是必要的。 运行成功后，会有这样一段输出： $ docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/engine/userguide/ 输出这段提示以后，hello-world 就会停止运行，container 自动终止。 ","date":"2018-08-08","objectID":"/posts/80148/:9:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"Ubuntu 如果 container 提供的是服务，运行结束后不会自动终止。比如 ubuntu docker run -it ubuntu 就可以在命令行中体验 Ubuntu 系统。这里我们直接运行了 library/ubuntu，Docker 会自动帮我们拉取镜像。 参考链接 Docker 入门教程 - 阮一峰的网络日志 【公开课】Docker入坑教程【33集】_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili Docker Documentation | Docker Documentation ","date":"2018-08-08","objectID":"/posts/80148/:10:0","tags":[],"title":"学习Docker(1)-入门","uri":"/posts/80148/"},{"categories":["Infrastructure"],"content":"最近在向 MySQL 数据库里更新数据的时候，遇到了这样的一个问题： “Incorrect string value: ‘\\xF0\\x9F\\x98\\x82\\xEF\\xBC…’ for column ‘content’ at row 1” 报错的字符串是一个 emoji 表情，emoji 表情要用 utf8mb4 字符集的字段存储，而我的数据库采用了 utf8 字符集，导致报错。 utf8 和 utf8mb4 详情可以看参考链接中 MacTalk 的微信公众号文章，简单总结如下： MySQL 中的 utf8 每个字符的编码长度最多三个字节，不是通俗意义上的 utf8 字符集，少很多字符； MySQL 中的 utf8mb4 字符集才是才是真正的 utf8 字符集，所以它能够正常编码 emoji 表情。 建议 MySQL 和 MariaDB 用户使用 utf8mb4 代替 utf8； 使用 utf8mb4 MySQL 安装后默认的字符集是 utf8。使用 utf8mb4 字符集需要进行一些设置。 ","date":"2018-08-04","objectID":"/posts/7a2c5/:0:0","tags":[],"title":"在MySQL中使用utf8mb4字符集","uri":"/posts/7a2c5/"},{"categories":["Infrastructure"],"content":"全局配置 如果能改变数据库服务器的设置，只需要修改 MySQL 配置文件，如下： [client] default-character-set = utf8mb4 [mysql] default-character-set = utf8mb4 [mysqld] # 忽略客户端的字符集请求，强制使用服务器字符集返回结果 character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci 检查设置： mysql\u003e SHOW VARIABLES WHERE Variable_name LIKE 'character\\_set\\_%' OR Variable_name LIKE 'collation%'; +--------------------------+--------------------+ | Variable_name | Value | +--------------------------+--------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8 | | collation_connection | utf8mb4_unicode_ci | | collation_database | utf8mb4_unicode_ci | | collation_server | utf8mb4_unicode_ci | +--------------------------+--------------------+ 10 rows in set (0.00 sec) ","date":"2018-08-04","objectID":"/posts/7a2c5/:1:0","tags":[],"title":"在MySQL中使用utf8mb4字符集","uri":"/posts/7a2c5/"},{"categories":["Infrastructure"],"content":"数据库实例配置 如果不能改变数据库服务器的设置，只针对某个数据库使用 utf8mb4 字符集，需要： 创建数据库时，指定 utf8mb4 字符集和 utf8mb4_unicode_ci 字序； create database dbname CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci; 新建数据库连接时，指定字符集 utf8mb4； mysql+driver]://[username]:[password]@[host]:[port/dbname?charset=utf8mb4 从 utf8 切换到 utf8mb4 备份数据库数据； 升级 MySQL 版本到 5.5.3+； 修改数据库、表、字段字符集和字序； # 数据库 ALTER DATABASE database_name CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci; # 表 ALTER TABLE table_name CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; # varchar 字段 ALTER TABLE table_name CHANGE column_name column_name VARCHAR(xx) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; 检查字段和索引 key 的最大长度，参考 Section 10.1.11 of the MySQL 5.5 Reference Manual； 修改数据库服务器设置，同上； 修复和优化所有表； # For each table REPAIR TABLE table_name; OPTIMIZE TABLE table_name; 或者直接使用该命令： mysqlcheck -u root -p --auto-repair --optimize --all-databases 参考链接 永远不要在 MySQL 中使用「utf8」- MacTalk How to support full Unicode in MySQL databases · Mathias Bynens In MySQL, never use “utf8”. Use “utf8mb4”. – Adam Hooper – Medium ","date":"2018-08-04","objectID":"/posts/7a2c5/:2:0","tags":[],"title":"在MySQL中使用utf8mb4字符集","uri":"/posts/7a2c5/"},{"categories":["工欲善其事"],"content":"git patch 可以将项目中的一些 commit 提取出来，生成 .patch 文件。其他分支或其他项目可以合并这些 .patch 文件，并生成与原 commit 一致的提交记录。 git patch 对于解决在错误的分支上开发了新功能特别有效。 生成 patch 使用 git format-patch 命令生成所需要的 patch。 选择超前于 Master 分支的所有提交： git format-patch -M master 选择某个提交之后的所有提交（不包括该次提交 35ec56）： git format-patch 35ec56 选择某两个提交之间的所有提交（不包括提交 35ec56，但包括 c388c0）： git format-patch 35ec56...c388c0 选择某个提交之前的n次提交（包括该次提交 35ec56）： git format-patch -n 35ec56 选择单个提交（将 n 指定为 1）： git format-patch -1 35ec56 命令执行后，每个 commit 会生成为一个 .patch 文件，文件带有编号，编号顺序为 commit 的顺序。 合并 patch 显示 patch 的文件改动状态： git apply --stat 0001-.patch 检查 patch 是否正常执行，大概相当于 dry-run。该命令能够检查出 patch 合并时一些常见的问题，比如 patch 中对文件进行了修改但文件不存在，patch 中创建文件但项目中已存在同名的文件。 git apply --check *.patch 合并 patch。在合并过程中 Git 如果检测到冲突，会报错并停止合并接下来的 patch，不会自动回滚，冲突处理参见下一节。 git am *.patch 冲突处理 下面是一个遇到冲突的例子： ~ git am *.patch Applying: add supervisor 配置 Applying: add Nginx配置 Applying: 更新配置 Applying: 修改博客LOGO error: aaa.txt: does not exist in index Patch failed at 0004 修改博客LOGO Use 'git am --show-current-patch' to see the failed patch When you have resolved this problem, run \"git am --continue\". If you prefer to skip this patch, run \"git am --skip\" instead. To restore the original branch and stop patching, run \"git am --abort\". 可以看出，在编号为 0004 的 patch 执行时，Git 在当前项目中无法找到 aaa.txt 文件。 解决冲突的方式，一种是简单粗暴的使用 git am —abort 命令，中断合并 patch，并会滚到合并 patch 之前的版本； 另一种是手动合并该 patch，并对冲突的文件手动修改，再继续 am 命令。这种处理方式不会对 commit 记录造成影响，重点介绍该方法。 首先，手动合并该 patch。对于没有冲突的文件，会自动更新（不会自动加入缓冲区）；对于有冲突的文件，会生成一个 .rej 冲突参考文件。 git apply --reject 0004.patch .rej 文件中包含了冲突文件的 diff 信息，参考该 .rej 文件对冲突的文件进行修改，.rej 文件参考完之后可以删除。 修改好冲突的文件之后，把冲突的文件和之前更新的文件加入缓冲区： git add aaa.txt bbb.txt 告诉 Git 冲突已解决，继续合并 patch git am --resolved 执行时，会根据缓冲区中对文件的修改，生成本次冲突 patch（0004）的 commit。 参考链接 如何使用git 生成patch 和打入patch - CSDN博客 Git 合并 patch 时的冲突处理一例 – Fwolf’s Blog ","date":"2018-08-04","objectID":"/posts/426bb/:0:0","tags":[],"title":"Git生成patch和合并patch","uri":"/posts/426bb/"},{"categories":["Infrastructure"],"content":"简介 UFW (uncomplicated firewall) 是 Ubuntu 默认的防火墙配置工具。为了简化 iptables 防火墙的配置，ufw 提供了一种友好的方式来创建基于 IPv4 或 IPv6 主机的防火墙。 在 Ubuntu 中，ufw 默认是禁用状态。 在 Arch 和 Debian 中，需要先安装 ufw： # Arch sudo pacman -S ufw sudo systemctl start ufw sudo systemctl enable ufw # Debian sudo apt-get install ufw 基本语法和规则 ","date":"2018-08-03","objectID":"/posts/8d237/:0:0","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"启用和禁用 ufw 启用 ufw，默认情况下，防火墙规则为：除一些默认的例外端口，传入流量-deny，传出流量-allow。 sudo ufw enable 查看 ufw 状态（按添加顺序排列，越早添加的规则优先级越高）： sudo ufw status verbose 禁用 ufw： sudo ufw disable 查看原始配置，也可以查看 /etc/ufw/ 目录中以 .rules 结尾的文件。 sudo ufw show raw ","date":"2018-08-03","objectID":"/posts/8d237/:1:0","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"设置规则 ","date":"2018-08-03","objectID":"/posts/8d237/:2:0","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"设置 allow 规则 sudo ufw allow \u003cport\u003e/\u003coptional：protocol\u003e **示例：**允许 53 端口传入 tcp 和 udp 数据包 sudo ufw allow 53 **示例：**只允许 53 端口传入 tcp 数据包 sudo ufw allow 53/tcp **示例：**只允许 53 端口传入 udp 数据包 sudo ufw allow 53/udp ","date":"2018-08-03","objectID":"/posts/8d237/:2:1","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"设置 deny 规则 sudo ufw deny \u003cport\u003e/\u003coptional: protocol\u003e **示例：**禁止 53 端口传入 udp 数据包 sudo ufw deny 53/udp ","date":"2018-08-03","objectID":"/posts/8d237/:2:2","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"设置默认规则 sudo ufw default allow outgoing sudo ufw default deny incoming ","date":"2018-08-03","objectID":"/posts/8d237/:2:3","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"删除规则 要删除规则，只需在原始规则前加上 delete 命令。例如，原始规则命令是： sudo ufw deny 80/tcp 那么删除这条规则的命令是： sudo ufw delete deny 80/tcp ","date":"2018-08-03","objectID":"/posts/8d237/:3:0","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"通过服务名称设置规则 也可以使用服务名称来设置和删除规则。ufw 会从 /etc/services 中读取服务列表。 **示例：**设置 allow 规则允许 SSH 服务端口 sudo ufw allow ssh 注意：如果更改了服务的默认端口号，要使用实际端口号，而不是服务名称来设置规则。 ","date":"2018-08-03","objectID":"/posts/8d237/:4:0","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"日志 启用日志记录： sudo ufw logging on 关闭日志记录： sudo ufw logging off 设置日志级别，默认为 low： sudo ufw logging low|medium|high 日志文件默认路径为 /var/logs/ufw.log。 高级设置 ","date":"2018-08-03","objectID":"/posts/8d237/:5:0","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"访问规则 允许特定 IP 地址访问： sudo ufw allow from 127.0.0.1 允许特定子网访问： sudo ufw allow from 123.45.67.89/24 允许特定 IP 的特定端口访问，destination 可以为 any 表示不限制目的地址。 sudo ufw allow from \u003ctarget\u003e to \u003cdestination\u003e port \u003cport number\u003e 允许特定 IP 的特定端口使用特定协议访问： sudo ufw allow from \u003ctarget\u003e to \u003cdestination\u003e port \u003cport number\u003e proto \u003cprotocol name\u003e 禁止访问规则与上述相似，只要将 allow 替换为 deny 即可。 ","date":"2018-08-03","objectID":"/posts/8d237/:6:0","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Infrastructure"],"content":"规则参考编号 查看 ufw 状态时显示规则编号： sudo ufw status numbered 通过编号删除规则： sudo ufw delete 1 通过编号插入规则，新规则将会被插入到编号指定位置，方便设置规则的优先级： sudo ufw insert 1 allow from \u003cip address\u003e 参考链接 UncomplicatedFirewall - Ubuntu Wiki UFW - Community Help Wiki 系统运维|在 Ubuntu 中用 UFW 配置防火墙 ","date":"2018-08-03","objectID":"/posts/8d237/:7:0","tags":[],"title":"在Ubuntu中使用UFW配置防火墙","uri":"/posts/8d237/"},{"categories":["Web 开发"],"content":"简介 JSON Web Token（JWT）是是目前最流行的跨域认证（Authentication）解决方案。 基于 session 的认证方案，在服务器集群或跨域的多系统中，难以实现一次登录多端共享。此时，有两种方案。 一种是，将 session 数据持久化，所有子系统都向持久层请求数据。这种方案优点是架构清晰，缺点是工程量大，另外如果持久层挂机，所有系统都无法登录； 另一种是，服务器不保存 session 数据，所有数据保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。 关于用户认证和用户授权的区别： 用户认证（Authentication）：让用户登录，确认用户拥有该账户，举例来说登录服务器； 用户授权（Authorization）：鉴别用户是否有某项操作的权限，举例来说 root 用户可以修改 /etc/hosts 文件。 原理 服务端初次认证以后，生成一个 JSON 对象，发回给用户。例如： { \"姓名\": \"张三\", \"角色\": \"管理员\", \"到期时间\": \"2018年7月1日0点0分\" } 在此之后，用户与服务端通信时带上这个 JSON 对象，服务器只靠这个对象认定用户身份，服务器不保存任何 session 数据。也就是说，服务器变成无状态了，从而比较容易实现扩展。 为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名（签名密钥存储在服务器上）。 数据结构 JWT 是一个没有换行长字符串，中间用 . 分隔为三部分。三个部分依次为：头部（Header）、负载（Payload）和签名（Signature）。即： Header.Payload.Signature ","date":"2018-08-03","objectID":"/posts/5304a/:0:0","tags":[],"title":"JSON Web Token入门","uri":"/posts/5304a/"},{"categories":["Web 开发"],"content":"Header Header 部分描述 JWT 的元数据，是一个 JSON 对象。 { \"alg\": \"HS256\", \"typ\": \"JWT\" } alg 属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）； typ 属性表示这个令牌（token）的类型（type），JWT 令牌统一写为 JWT。 最后，将上面的 JSON 对象使用 Base64URL（注意不是常用的 Base64） 算法转成字符串。 ","date":"2018-08-03","objectID":"/posts/5304a/:1:0","tags":[],"title":"JSON Web Token入门","uri":"/posts/5304a/"},{"categories":["Web 开发"],"content":"Payload Payload 部分用来存储实际需要传输的数据。JWT 规定了 7 个官方字段，供选用。 iss (issuer)：签发人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 除了官方字段，也可以自定义私有字段，例如： { \"sub\": \"1234567890\", \"name\": \"John Doe\", \"admin\": true } 注意，JWT 默认是不加密的，不能在 Payload 中放秘密信息。 这个 JSON 对象也要使用 Base64URL 算法转成字符串。 ","date":"2018-08-03","objectID":"/posts/5304a/:2:0","tags":[],"title":"JSON Web Token入门","uri":"/posts/5304a/"},{"categories":["Web 开发"],"content":"Signature Signature 部分是对前两部分的数据进行签名，防止数据篡改。计算签名所使用的密钥（secret）应安全存储在服务器端，不能泄露给用户。 使用 Header 中指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名（Python 示例）。 import hmac from base64 import urlsafe_b64encode hmac.new( secret, urlsafe_b64encode(header.encode()) + b\".\" + urlsafe_b64encode(payload.encode()), \"sha256\", ).hexdigest() 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用\"点”（.）分隔，就可以返回给用户。 ","date":"2018-08-03","objectID":"/posts/5304a/:3:0","tags":[],"title":"JSON Web Token入门","uri":"/posts/5304a/"},{"categories":["Web 开发"],"content":"Base64URL JWT 作为一个令牌（token），有些场合可能会放到 URL 中，例如 api.example.com/?token=xxx。 Base64 有三个字符 +、/ 和 =，在 URL 里面有特殊含义，所以要被替换掉：= 被省略、+ 替换成 -，/ 替换成 _ 。这就是 Base64URL 算法。 使用场景 ","date":"2018-08-03","objectID":"/posts/5304a/:4:0","tags":[],"title":"JSON Web Token入门","uri":"/posts/5304a/"},{"categories":["Web 开发"],"content":"简单认证 向用户发送的通知邮件，需要用户点击链接做一些不太重要的操作时，例如退订、填写问卷等等。此时可以在链接 URL 中带上 JWT —— 既可以认证用户（防止他人伪造链接），又不需要用户登录。 ","date":"2018-08-03","objectID":"/posts/5304a/:5:0","tags":[],"title":"JSON Web Token入门","uri":"/posts/5304a/"},{"categories":["Web 开发"],"content":"单点登录 如果是同一域名下的多个子域名站点的单点登录，可以将 JWT 放在 cookie 中，并将 domain 设置为顶级域名。例如： Set-Cookie: jwt=\u003ctoken\u003e; HttpOnly; max-age=980000; domain=.taobao.com 如果涉及到跨域，可以把 JWT 放在 HTTP 请求的头信息 Authorization 字段里面，或者放在 POST 请求的数据体里面； Authorization: Bearer \u003ctoken\u003e 特点 JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。 JWT 不加密的情况下，不能将秘密数据写入 JWT。 JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。 JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。 JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。 参考链接 JSON Web Token 入门教程 - 阮一峰的网络日志 JSON Web Token - 在Web应用间安全地传递信息 - 回田园 八幅漫画理解使用JSON Web Token设计单点登录系统 - 回田园 ","date":"2018-08-03","objectID":"/posts/5304a/:6:0","tags":[],"title":"JSON Web Token入门","uri":"/posts/5304a/"},{"categories":["Web 开发"],"content":"Nginx 的配置文件是一个以块（block）的形式组织一组指令的文本文件。 配置文件路径： Ubuntu apt 安装：/etc/nginx/； MacOS brew 安装：/usr/local/etc/nginx/； include 在配置文件中，使用 include 指令来执行对一个特定文件的包含，即将特定文件内容插入到配置文件 include 指令的位置。例如 include mime.types; 以上配置包含了 Nginx 自带的文件扩展列表。 这种组织配置的方式，使我们可以将不同域的配置分开成独立的配置文件。 block ","date":"2018-08-01","objectID":"/posts/9a8a2/:0:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"概述 每个块以一个花括号（{}）来表示。主要块有： 块 含义 main 全局设置，包含一些 Nginx 的基本控制功能。它在配置的顶层，不需要显式写出。 events 事件设置，控制 Nginx 处理连接的方式 http HTTP 设置 server 主机设置 upstream 负载均衡设置 location 针对特定 URL 的设置。 块的嵌套关系如下：  main ├── events └── http ├── server │ └── location └── upstream 被嵌套的块将继承其父块的设置，也可以重新进行设置。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:1:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"原理 在 http 块中可以声明多个 server 块，一个 server 块允许配置一个虚拟主机和监听的端口，在 server 块内允许插入多个 location 块，当需要对特定的路径进行URL匹配时，location块允许对这些路径单独设置。 例如： http { include mime.types; # 虚拟主机配置 server { listen 80; server_name bbs.example.com; location / { proxy_pass http://localhost:5000; # 后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } #静态文件，nginx自己处理，不去backend请求tomcat location ~* /download/ { root /apps/oa/fs; } ","date":"2018-08-01","objectID":"/posts/9a8a2/:2:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"main 块 nginx在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。 woker_processes 2 worker 工作进程的个数。这个数值简单一点可以设置为 cpu 的核数grep ^processor /proc/cpuinfo | wc -l，也是设置为 auto 时的值；如果开启了 ssl 和 gzip 应该设置成与逻辑 CPU 数量一样甚至为2倍，可以减少 I/O 操作；如果 nginx 服务器还有其它服务，可以考虑适当减少。 worker_cpu_affinity 在高并发情况下，通过设置 cpu 粘性来降低由于多 CPU 核切换造成的寄存器等现场重建带来的性能损耗。如 worker_cpu_affinity 0001 0010 0100 1000; （四核）。 worker_rlimit_nofile 10240 默认是没有设置，可以限制为操作系统最大的限制 65535。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:3:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"events 块 worker_connections 2048 每一个 worker 进程能并发处理（发起）的最大连接数（包括与客户端和后端服务器的连接）。nginx 作为反向代理服务器时，计算公式 最大连接数 = worker_processes * worker_connections/4；当 nginx 作为 http 服务器时，计算公式里面是除以2。 use epoll 在 Linux 操作系统下，nginx 默认使用 epoll 事件模型，得益于此，nginx 在 Linux 操作系统下效率相当高。同时 Nginx 在 OpenBSD 或 FreeBSD 操作系统上采用类似于 epoll 的高效事件模型kqueue。在操作系统不支持这些高效模型时才使用 select。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:4:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"http 块 HTTP 服务相关的一些配置参数。 sendfile on 开启高效文件传输模式，sendfile 指令指定 nginx 是否调用 sendfile 函数来输出文件，减少用户空间到内核空间的上下文切换。对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络 I/O 处理速度，降低系统的负载。 keepalive_timeout 60 长连接超时时间，单位是秒。如果是大量小文件的场景，设置较长的超时时间可以减少重建连接的开销；如果是大文件的场景，设置时间较短会导致失败。但如果设置时间过长，长时间保持连接会占用大量资源。 send_timeout 用于指定响应客户端的超时时间。这个超时仅限于两个连接活动之间的时间，如果超过这个时间，客户端没有任何活动，Nginx 将会关闭连接。 client_max_body_size 10m 允许客户端请求的最大单文件字节数。如果有上传较大文件，请设置它的限制值。 client_body_buffer_size 128k 缓冲区代理缓冲用户端请求的最大字节数。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:5:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"gzip 压缩相关设置 gzip on 开启 gzip 压缩输出，减少网络传输。 gzip_min_length 1k 设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取。默认值是20。建议设置成大于1k的字节数，小于1k可能会越压越大。 gzip_buffers 4 16k 设置系统获取几个单位的缓存用于存储 gzip 的压缩结果数据流。“4 16k”代表按原始数据大小以 16k 为单位的 4 倍申请内存。 gzip_http_version 1.1 启用 GZip 所需的 HTTP 最低版本，默认 1.1，也可以设置成 1.0。 gzip_comp_level 6 GZip 压缩比，1 压缩比最小处理速度最快，9 压缩比最大但处理速度最慢。 gzip_types 匹配 mime 类型进行压缩，无论是否指定，“text/html” 类型总是会被压缩的。 gzip_proxied any Nginx 作为反向代理的时候，决定后端服务器返回的结果是否压缩，匹配的前提是后端服务器必须要返回包含 ”Via” 的 header 头。 gzip_vary on ： 和 http 头有关系，会在响应头加个 Vary: Accept-Encoding ，可以让前端的缓存服务器缓存经过 gzip 压缩的页面，例如，用Squid缓存经过Nginx压缩的数据。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:5:1","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"http_proxy 相关设置 proxy_connect_timeout 60 nginx 跟后端服务器连接超时时间(代理连接超时)。 proxy_read_timeout 60 连接成功后，与后端服务器两个成功的响应操作之间超时时间(代理接收超时)。 proxy_buffer_size 4k 设置作为代理服务器从后端 realserver 读取并保存用户头信息的缓冲区大小，默认与 proxy_buffers 大小相同。 proxy_buffers 4 32k proxy_buffers 缓冲区，nginx 针对单个连接缓存来自后端 realserver 的响应。 proxy_busy_buffers_size 64k 高负荷下缓冲大小，一般为 proxy_buffers*2 proxy_max_temp_file_size 当 proxy_buffers 放不下后端服务器的响应内容时，会将一部分保存到硬盘的临时文件中，这个值用来设置最大临时文件大小，默认1024M，设置为0禁用。 proxy_temp_file_write_size 64k 当缓存被代理的服务器响应到临时文件时，这个选项限制每次写临时文件的大小。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:5:2","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"server块 listen 监听端口，默认80，小于1024的要以root启动。可以为listen *:80、listen 127.0.0.1:80等形式。 server_name 服务器名，如localhost、www.example.com，可以通过正则匹配。 可以根据 server_name 不同，对来自同一端口的访问请求转发到不同的后端服务器。 server { listen 80; server_name www.a.net; location / { proxy_pass http://127.0.0.1:5000; index index.html index.htm; } } server { listen 80; server_name www.a.cn; location / { proxy_pass http://127.0.0.1:8000; index index.html index.htm; } } ","date":"2018-08-01","objectID":"/posts/9a8a2/:6:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"upstream 块 在 upstream 块中定义多个后端服务器地址，格式为server ip:port options，通过算法进行负载均衡设置。 例如： upstream backend { least_conn; server 127.0.0.1:8000 down; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; } least_conn 为负载均衡算法名称，down 表示当前服务器不参与负载均衡。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:7:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"负载均衡算法 round-robin Nginx 默认的轮询算法（不需要在 upstream 块中显式指定），每个请求按时间顺序逐一分配到不同的后端服务器。宕机服务器会被自动剔除。可以通过 weight 指定轮询权值，weight 值越大，该服务器被访问的概率越高，主要用于后端服务器性能不均的情况。 least_conn 请求会被发送到活跃连接数最少的服务器上。 ip_hash 按访问 IP 的哈希结果分配请求，来自同一 IP 的用户会固定访问一个后端服务器； hash 按某个键的哈希结果分配（键可以是文本、变量等）请求。例如 hash $request_uri 即是按请求地址生成哈希结果。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:7:1","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"状态参数 状态参数 含义 down 当前服务器暂时不参与负载均衡，对该服务器的请求会自动发送到下一个服务器 max_fails 允许请求失败的次数，默认为1。当超过最大次数时，返回对应的 XX_next_upstream 模块定义的错误。 fail_timeout 在经历了 max_fails 次失败后，暂停服务的时间，默认是 10s。 backup 预留的备份服务器。当其他所有非 backup 服务器出现故障或者忙时，才会请求 backup 服务器。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:7:2","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"location 块 root /var/www/html 定义服务器的默认网站根目录位置。如果 location URL匹配的是子目录或文件，root 没什么作用，一般放在 server 指令里面或 / 下。 index index.jsp index.html index.htm 定义路径下默认访问的文件名，一般跟着 root 放。 proxy_pass http://backend 请求转向 backend 定义的服务器列表，即反向代理，对应 upstream 负载均衡器。如果只有一个服务器地址，也可以不用负载均衡直接写 proxy_pass http://ip:port。 proxy_set_header Host $host; 让 backend 服务器知道真实请求host。 proxy_set_header X-Real-IP $remote_addr; 让 backend 服务器知道真实请求IP。 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 让 backend 服务器知道真实请求 URL； proxy_pass 是 Nginx 作为反向代理服务器时的重要配置。 ","date":"2018-08-01","objectID":"/posts/9a8a2/:8:0","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Web 开发"],"content":"URI 匹配规则 按照匹配顺序，如下： = 开头表示精确匹配； 完整路径匹配； ^~ 开头表示以某个常规字符串开头，不是正则匹配； ~ 开头表示区分大小写的正则匹配； ~* 开头表示不区分大小写的正则匹配； /images/abc 表示最长字符匹配，匹配包含 /images/abc 的URI； / 通用匹配，如果没有其它匹配，任何请求都会匹配到； 举个例子： location = / { # 精确匹配 / ，主机名后面不能带任何字符串 [ configuration A ] } location / { # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ] } location ~ /documents/Abc { # 匹配任何以 /documents/ 开头的地址 } location ^~ /images/ { # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 } location ~* \\.(gif|jpg|jpeg)$ { # 匹配所有以 gif,jpg或jpeg 结尾的请求 } location /images/ { # 字符匹配到 /images/ } location /images/abc { # 最长字符匹配到 /images/abc，优先级高于上一条 [ configuration G ] } HTTPS 设置 使用 Let’s Encrypt 的 HTTPS 证书设置如下： http { ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; include /etc/letsencrypt/options-ssl-nginx.conf; add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always; server { listen 443 ssl; server_name xxxxx; ssl_certificate /etc/letsencrypt/live/jupyter.mrchi.cc/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/jupyter.mrchi.cc/privkey.pem; } # HTTP 请求301重定向到 HTTPS server { listen 80; server_name xxxxx; return 301 https://$server_name$request_uri; } } WebSocket 设置 location ~ /api/kernels/ { proxy_pass http://localhost:8888; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade \"websocket\"; proxy_set_header Connection \"Upgrade\"; proxy_read_timeout 86400; } Default server 配置 444 状态码是 Nginx 专用状态码，会直接关闭连接，不会返回任何内容。 server { listen 80 default_server; listen [::]:80 default_server; listen 443 ssl default_server; listen [::]:443 ssl default_server; server_name _; ssl_certificate /etc/letsencrypt/live/jupyter.mrchi.cc/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/jupyter.mrchi.cc/privkey.pem; return 444; } 其他 测试配置： sudo nginx -t 加载配置： sudo nginx -s reload ","date":"2018-08-01","objectID":"/posts/9a8a2/:8:1","tags":[],"title":"Nginx配置","uri":"/posts/9a8a2/"},{"categories":["Python"],"content":"Flask 是一个非常灵活的 Web 开发框架，因而其目录结构可以有多种形式。 单独实例化扩展对象 在相关文件中单独实例化扩展对象，而不是将扩展对象放入__init__.py中。这是 Flask 官方文档推荐的方式。 引用原作者的一句话： Don’t backward import from root __init__.py. ","date":"2018-07-06","objectID":"/posts/a9cbb/:0:0","tags":[],"title":"Flask项目的目录结构","uri":"/posts/a9cbb/"},{"categories":["Python"],"content":"示例 举个例子，我们使用 Flask-SQLAlchemy 扩展，则在 models.py 中创建 SQLAlchemy 对象。 yourapplication/__init__.py： from flask import Flask def create_app(config_filename): app = Flask(__name__) app.config.from_pyfile(config_filename) from yourapplication.model import db db.init_app(app) from yourapplication.views.admin import admin from yourapplication.views.frontend import frontend app.register_blueprint(admin) app.register_blueprint(frontend) return app yourapplication/models.py： from flask_sqlalchemy import SQLAlchemy db = SQLAlchemy() class User(db.Model): pass ","date":"2018-07-06","objectID":"/posts/a9cbb/:1:0","tags":[],"title":"Flask项目的目录结构","uri":"/posts/a9cbb/"},{"categories":["Python"],"content":"原因 为了避免一些情况下的循环导入问题。 假如我们在 __init__.py 中实例化 SQLAlchemy 对象，那么在 models.py 需要从 __init__.py 中导入该对象以便创建数据库模型。但若另一扩展使用某个模型进行初始化，则需要在 __init__.py 中导入模型。这就造成了 models.py 和 __init__.py 之间的循环导入。 yourapplication/__init__.py： from flask import Flask from flask_sqlalchemy import SQLAlchemy from yourapplication.models import User db = SQLAlchemy() ext = AnotherExtension(User) def create_app(config_filename): app = Flask(__name__) app.config.from_pyfile(config_filename) db.init_app(app) from yourapplication.views.admin import admin from yourapplication.views.frontend import frontend app.register_blueprint(admin) app.register_blueprint(frontend) return app yourapplication/models.py： from yourapplication import db class User(db.Model): pass 基于功能的组织结构 所有内容按照其功能（模型、路由、模版、API等等）分别存放在不同目录中。 project ├── __init__.py ├── models │ ├── __init__.py │ ├── posts.py │ └── users.py ├── routes │ ├── __init__.py │ ├── auth.py │ ├── dashboard.py │ └── home.py ├── services │ ├── __init__.py │ ├── google.py │ └── mail.py └── templates ├── home.html └── login.html 在 project/__init__.py 文件中编写 create_app 工厂函数，并执行所有的 init_app 方法。 # project/__init__.py from flask import Flask def create_app(): from . import models, routes, services app = Flask(__name__) models.init_app(app) routes.init_app(app) services.init_app(app) return app 这里原作者的一个小技巧是，在每个目录的 __init__.py 文件中，都定义一个 init_app 方法，在其中再调用 Flask 扩展的 init_app 方法或注册蓝本。 # project/models/__init__.py from .base import db def init_app(app): db.init_app(app) # project/routes/__init__.py from .users import user_bp from .posts import posts_bp def init_app(app): app.register_blueprint(user_bp) app.register_blueprint(posts_bp) 基于app的组织结构 基于app的内容，或者说基于蓝本来组织目录结构，每个蓝本为一个目录，每个目录下有自己单独的路由、模型、模版等。 project ├── __init__.py ├── auth │ ├── __init__.py │ ├── models.py │ ├── routes.py │ └── templates ├── blog │ ├── __init__.py │ ├── models.py │ ├── routes.py │ └── templates └── db.py 这是另一个比较有名的组织方式，《Flask Web开发：基于Python的Web应用开发实战》书中即使用了该种方式，这也是Django的默认模式。 但有的时候，可能需要以上两种模式混合使用。例如，有的数据库模型可能在多个蓝本中都会用到，不好区分他们究竟属于哪个蓝本。 参考链接 Structure of a Flask Project - Just lepture Organizing your project — Explore Flask 1.0 documentation ","date":"2018-07-06","objectID":"/posts/a9cbb/:2:0","tags":[],"title":"Flask项目的目录结构","uri":"/posts/a9cbb/"},{"categories":["Web 开发"],"content":"什么是CSS？ Cascading Style Sheets (CSS) 是一门指定文档该如何呈现给用户的语言。 文档是信息的集合，它使用一门标记语言作为结构。文档不等同于文件，一个文档可能由多个文件组成。 CSS 并非仅仅用于浏览器，也不仅限于视觉展现。按照 CSS 的正式术语来讲，将文档呈现给用户的程序称为用户代理(UA)。浏览器只是用户代理的其中之一。 浏览器如何展现文档？ 浏览器先将标记语言和 CSS 转换成DOM (文档对象模型)结构。 这时 DOM 就代表了电脑内存中的相应文档，因为它已经融合了文档内容和相应的样式表。 最后浏览器把 DOM 的内容展示出来。 CSS的层叠和继承 !important关键字，用户可以通过使用这个关键字使自己定义的样式覆盖掉开发者定义的样式。 ","date":"2018-06-07","objectID":"/posts/53748/:0:0","tags":[],"title":"CSS入门教程-MDN","uri":"/posts/53748/"},{"categories":["Web 开发"],"content":"层叠 对于层叠来说，共有三种主要的样式来源： 浏览器对HTML定义的默认样式。 用户定义的样式。 开发者定义的样式，可以有三种形式： 定义在外部文件（外链样式）：本教程中案例主要是通过这种形式定义样式。 在页面的头部定义（内联样式）：通过这种形式定义的样式只在本页面内生效。 定义在特定的元素身上（行内样式）：这种形式多用于测试，可维护性较差。 优先级从高到低依次为：网页开发者定义的样式、网页阅读者定义的样式、浏览器的默认样式。 ","date":"2018-06-07","objectID":"/posts/53748/:1:0","tags":[],"title":"CSS入门教程-MDN","uri":"/posts/53748/"},{"categories":["Web 开发"],"content":"继承 对继承的元素来说，子元素自身的样式优先级高于从父级继承来的样式。 CSS选择器 ","date":"2018-06-07","objectID":"/posts/53748/:2:0","tags":[],"title":"CSS入门教程-MDN","uri":"/posts/53748/"},{"categories":["Web 开发"],"content":"样式优先级 如果多于一个规则指定了相同的属性值都应用到一个元素上，CSS规定拥有更高确定度的选择器优先级更高。ID选择器比类选择器更具确定度, 而类选择器比标签选择器（tag selector）更具确定度。 如果样式中包含冲突的规则，且它们具有相同的确定度。那么，后出现的规则优先级高。 ","date":"2018-06-07","objectID":"/posts/53748/:3:0","tags":[],"title":"CSS入门教程-MDN","uri":"/posts/53748/"},{"categories":["Web 开发"],"content":"基于关系的选择器 一个HTML表格有id 属性，但是它的行和单元格没有单独的id。可以使用关系选择器设置单元格格式。 ","date":"2018-06-07","objectID":"/posts/53748/:4:0","tags":[],"title":"CSS入门教程-MDN","uri":"/posts/53748/"},{"categories":["Web 开发"],"content":"纯CSS实现的下拉列表 \u003c!doctype html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eSample document\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"style.css\"\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv class=\"menu-bar\"\u003e \u003cul\u003e \u003cli\u003e \u003ca href=\"example.html\"\u003eMenu\u003c/a\u003e \u003cul\u003e \u003cli\u003e \u003ca href=\"example.html\"\u003eLink\u003c/a\u003e \u003c/li\u003e \u003cli\u003e \u003ca class=\"menu-nav\" href=\"example.html\"\u003eSubmenu\u003c/a\u003e \u003cul\u003e \u003cli\u003e \u003ca class=\"menu-nav\" href=\"example.html\"\u003eSubmenu\u003c/a\u003e \u003cul\u003e \u003cli\u003e\u003ca href=\"example.html\"\u003eLink\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"example.html\"\u003eLink\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"example.html\"\u003eLink\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"example.html\"\u003eLink\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003e\u003ca href=\"example.html\"\u003eLink\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2018-06-07","objectID":"/posts/53748/:5:0","tags":[],"title":"CSS入门教程-MDN","uri":"/posts/53748/"},{"categories":["Web 开发"],"content":"HTML \u003cem\u003e：表示强调，斜体表示； \u003cstrong\u003e：表示更强烈的强调，粗体表示； \u003cspan\u003e：用于给文本设置单独的样式，没有语义； \u003cq\u003e: 引用文本，会自动添加双引号，不需要手动添加。cite属性标记引用内容的来源或者解释； \u003cblockquote\u003e：对长文本的引用，浏览器对该标签的解析是缩进样式，不会自动加双引号； \u003cbr /\u003e：折行，一般写带斜线的这种格式比较规范； \u0026nbsp;：空格； \u003chr /\u003e：分割线； \u003caddress\u003e：联系地址，斜体表示； \u003cdiv\u003e：相当于一个容器，可以把一些独立的逻辑部分划分出来，放在一个\u003cdiv\u003e标签中。 ","date":"2018-05-31","objectID":"/posts/79cd5/:0:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"table \u003ctable\u003e 整个表格 \u003ccaption\u003e 显示在表格上方的标题 \u003cthead\u003e 表头 \u003ctbody\u003e 表内容 \u003ctfoot\u003e footer \u003ctr\u003e 表格的一行 \u003cth\u003e 表头单元格 \u003ctd\u003e 标准单元格 典型嵌套结构： \u003ctable summary=\"表格简介文本\"\u003e \u003ccaption\u003e一个标题\u003c/caption\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eHeader content 1\u003c/th\u003e \u003cth\u003eHeader content 2\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003eBody content 1\u003c/td\u003e \u003ctd\u003eBody content 2\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003ctfoot\u003e \u003ctr\u003e \u003ctd\u003eFooter content 1\u003c/td\u003e \u003ctd\u003eFooter content 2\u003c/td\u003e \u003c/tr\u003e \u003c/tfoot\u003e \u003c/table\u003e ","date":"2018-05-31","objectID":"/posts/79cd5/:1:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"a href属性的mailto链接，用于发送电子邮件。参数以\u0026符号隔开，类似GET请求参数。 \u003ca href=\"mailto:yy@imooc.com?subject=主题\" 参数含义如下： cc 抄送 bcc 密送 subject 主题 body 内容 ","date":"2018-05-31","objectID":"/posts/79cd5/:2:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"img 说两个属性： alt 指定图像不可见时的描述性文本，当图像不可见指加载不成功等； title 指定图像可见时的描述性文本； ","date":"2018-05-31","objectID":"/posts/79cd5/:3:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"form 属性： method 请求方法 action 请求URL ","date":"2018-05-31","objectID":"/posts/79cd5/:4:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"input 单标签。 属性： type 类型，text 普通文本，password 密码文本，radio 单选框，checkbox 复选框，submit 提交按钮，reset 重置按钮； name 表单提交时该输入框内容的变量名； value 输入框的默认值，为按钮时是按钮上显示的文字； checked 单选框和复选框独有，值为\"checked\"时，表示默认勾选。 注意： 同一组单选按钮 name 属性取值要一致。 ","date":"2018-05-31","objectID":"/posts/79cd5/:4:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"textarea 文本输入域。 属性： cols 多行输入域的列数； rows 多行输入域的行数； 在\u003ctextarea\u003e\u003c/textarea\u003e标签之间可以输入默认值。 ","date":"2018-05-31","objectID":"/posts/79cd5/:4:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"select \u003cselect\u003e 下拉列表 multiple 设置为\"multipule\"时，下拉列表可以多选。 \u003coption\u003e 下拉列表中的选项： value 表单提交数据； selected 设置值为\"selected\"时，该选项被默认选中。 ","date":"2018-05-31","objectID":"/posts/79cd5/:4:3","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"label 属性： for 与input控件的ID属性相同； CSS ","date":"2018-05-31","objectID":"/posts/79cd5/:4:4","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"CSS集成方式 ","date":"2018-05-31","objectID":"/posts/79cd5/:5:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"内联css 在开始标签中使用 style 属性定义，写在双引号中，多条 css 样式用分号隔开。 \u003cp style=\"color:red;font-size:12px\"\u003e这里文字是红色。\u003c/p\u003e ","date":"2018-05-31","objectID":"/posts/79cd5/:5:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"嵌入式css 把css样式代码写在 \u003cstyle\u003e 标签中，\u003cstyle\u003e 标签定义在 \u003chead\u003e 标签中。 \u003cstyle type=\"text/css\"\u003e span{ color:red; } \u003c/style\u003e ","date":"2018-05-31","objectID":"/posts/79cd5/:5:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"文件css \u003clink href=\"base.css\" rel=\"stylesheet\" type=\"text/css\" /\u003e /* 注释语句 */ 选择符 { 属性:值; /* 注释语句 */ 属性:值; ... } ","date":"2018-05-31","objectID":"/posts/79cd5/:5:3","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"优先级 层叠 层叠时，遵循**就近原则（离被设置元素越近优先级别越高）。**一般来说，相同权值的情况下：内联式 \u003e 嵌入式 \u003e 外部式。 权值 权值规律： 标签的权值为 1，类选择符的权值为 10，ID 选择符的权值最高为 100。继承也有权值但很低，有的文献提出它只有 0.1，所以可以理解为继承的权值最低。 重要性 使用 !important 设置某些样式拥有最高权值。 p {color:red!important;} 浏览器默认的样式 \u003c 网页制作者样式 \u003c 用户自己设置的样式 \u003c important 设置的样式 ","date":"2018-05-31","objectID":"/posts/79cd5/:5:4","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"CSS 选择器 :hover 伪类选择符，控制鼠标滑过时的样式。 CSS 的某些样式具有继承性，允许样式不仅应用于某个特定 html 标签元素，而且应用于其后代。 ","date":"2018-05-31","objectID":"/posts/79cd5/:6:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"文字排版和段落排版 ","date":"2018-05-31","objectID":"/posts/79cd5/:7:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"文字排版 font-family 字体； font-size 字号； color 颜色； font-weight 字重，bold 粗体； font-style 字范儿😂， italic 斜体; text-decoration 装饰， underline 下划线，line-through 删除线； ","date":"2018-05-31","objectID":"/posts/79cd5/:7:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"段落排版 em 是文字大小。 text-indent 缩进 line-height 行高 letter-spacing 中文的文字间隔和英文的字母间隔； word-spacing 英文的单词间隔，对中文无效； text-align 为块状元素中的文本图片等设置对齐方式，center 居中，left 居左，right 居右； ","date":"2018-05-31","objectID":"/posts/79cd5/:7:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"元素分类 ","date":"2018-05-31","objectID":"/posts/79cd5/:8:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"块状元素（block） 包括 \u003cdiv\u003e、\u003cp\u003e、\u003ch1\u003e…\u003ch6\u003e、\u003col\u003e、\u003cul\u003e、\u003cdl\u003e、\u003ctable\u003e、\u003caddress\u003e、\u003cblockquote\u003e 、\u003cform\u003e。 特点： 每个块级元素都从新的一行开始，并且其后的元素也另起一行。 元素的高度、宽度、行高以及顶和底边距都可设置。 元素宽度在不设置的情况下，是它本身父容器宽度的100%，除非设定一个宽度。 可以通过设置 display:block 将元素显示为块级元素，会具有块状元素的特点。例如： a {display:block}; ","date":"2018-05-31","objectID":"/posts/79cd5/:8:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"内联元素（inline） 包括 \u003ca\u003e、\u003cspan\u003e、\u003cbr\u003e、\u003ci\u003e、\u003cem\u003e、\u003cstrong\u003e、\u003clabel\u003e、\u003cq\u003e、\u003cvar\u003e、\u003ccite\u003e、\u003ccode\u003e。 特点： 和其他元素都在一行上； 元素的高度、宽度及顶部和底部边距不可设置； 元素的宽度就是它包含的文字或图片的宽度，不可改变。 可以通过设置 display:inline 将元素显示为内联元素，会具有内联元素的特点。例如： p {display:inline}; ","date":"2018-05-31","objectID":"/posts/79cd5/:8:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"内联块状元素 包括 \u003cimg\u003e、\u003cinput\u003e。 特点： 和其他元素都在一行上； 元素的高度、宽度、行高以及顶和底边距都可设置。 可以通过设置 display:inline-block 将元素设置为内联块状元素； a {display:inline-block} ","date":"2018-05-31","objectID":"/posts/79cd5/:8:3","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"盒模型 盒模型由内到外为内容、padding、border、margin。 **元素实际宽度（盒子的宽度）**=左边界+左边框+左填充+内容宽度+右填充+右边框+右边界。 ","date":"2018-05-31","objectID":"/posts/79cd5/:9:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"内容 width 宽度； height 高度； ","date":"2018-05-31","objectID":"/posts/79cd5/:9:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"padding padding 设定四个方向上 padding 的距离； padding-top 设定上填充； padding-bottom 设定下填充； padding-left 设定左填充； padding-right 设定右填充。 设定属性值： 4个属性值，分别为 上、右、下、左（顺时针方向）； 2个属性值，分别为 上下、左右； 1个属性值，所有方向。 ","date":"2018-05-31","objectID":"/posts/79cd5/:9:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"border 样式 border-width 边框宽度，可以设置为 thin、medium、thick 或者像素值； border-style 边框样式，dashed 虚线，dotted 点线，solid 实线； border-color 边框颜色， 合写样式，格式为\u003cwidth\u003e \u003cstyle\u003e \u003ccolor\u003e： border 设定四个方向上 border 的属性； border-top 设定上边框； border-bottom 设定下边框； border-left 设定左边框； border-right 设定右边框。 ","date":"2018-05-31","objectID":"/posts/79cd5/:9:3","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"margin margin 设定四个方向上 margin 的距离； margin-top 设定上边界； margin-bottom 设定下边界； margin-left 设定左边界； margin-right 设定右边界。 多值的情况同padding。 ","date":"2018-05-31","objectID":"/posts/79cd5/:9:4","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"CSS布局模型 在网页中，元素有三种布局模型： 流动模型（Flow）； 浮动模型（Float）； 层模型（Layer）； ","date":"2018-05-31","objectID":"/posts/79cd5/:10:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"Flow模型 默认的网页布局模式。 块状元素：默认情况下，块状元素的宽度为 100%，因此块状元素在所处的包含元素内自上而下按顺序垂直延伸分布； 内联元素：在所处的包含元素内从左到右水平分布显示。 ","date":"2018-05-31","objectID":"/posts/79cd5/:10:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"Float模型 使块状元素并排显示。脱离了文档流。 通过设置块状元素 float 属性为 left 浮动居左，或者 right 浮动居右。 注意：浮动居右的时候，html中靠上的元素在最右侧。 ","date":"2018-05-31","objectID":"/posts/79cd5/:10:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"Layer模型 类似PS中图层，可以对每个图层进行精确定位操作，达到不错的效果。 absolute定位 将元素从文档流中拖出来，相对于其最接近的一个具有定位属性的父包含块进行绝对定位；如果不存在这样的包含块，则相对于body元素（浏览器窗口）进行定位。 通过设置 position: absolute 和 left、right、top、bottom属性实现 div { width:200px; height:200px; border:2px red solid; position:absolute; left:100px; top:50px; } relative定位 在正常文档流中，相对于以前的位置移动，偏移前的位置保留不动。 与 absolute 不同的是： 在正常文档流中，偏移位置基于文档流中的位置，不需要具有定位属性的父包含块； 偏移后，其他元素仍按照偏移前的位置进行渲染； 通过设置 position: relative 和 left、right、top、bottom属性实现 #div1 { width:200px; height:200px; border:2px red solid; position:relative; left:100px; top:50px; } fixed定位 将元素从文档流中拖出，相对于视图（网页窗口）进行定位，使元素始终处于浏览器窗口内视图的某个位置。 通过设置 position: fixed 和 left、right、top、bottom属性实现 #div1{ width:200px; height:200px; border:2px red solid; position:fixed; left:100px; top:50px; } Relative与Absolute组合使用 在不设置偏移量的情况下，relative 定位的元素与正常元素没有区别。 absolute 定位需要具有定位属性的父包含块，可以将父包含块(前辈元素)设置为 relative 定位。 ","date":"2018-05-31","objectID":"/posts/79cd5/:10:3","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"css缩写 ","date":"2018-05-31","objectID":"/posts/79cd5/:11:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"颜色值缩写 设置的颜色是16进制的色彩值时，如果每两位的值相同，可以缩写一半。 p{color: #336699;} p{color: #369;} ","date":"2018-05-31","objectID":"/posts/79cd5/:11:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"字体缩写 使用格式： font: \u003cfont-style\u003e \u003cfont-variant\u003e \u003cfont-weight\u003e \u003cfont-size\u003e/\u003cline-height\u003e \u003cfont-family\u003e 注意： 至少需要指定 font-size 和 font-family 属性； font-size 和 line-height 中间加入 “/” 斜杠； 举例： body{ font-style:italic; font-variant:small-caps; font-weight:bold; font-size:12px; line-height:1.5em; font-family:\"宋体\",sans-serif; } body{ font:italic small-caps bold 12px/1.5em \"宋体\",sans-serif; } ","date":"2018-05-31","objectID":"/posts/79cd5/:11:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"单位和值 ","date":"2018-05-31","objectID":"/posts/79cd5/:12:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"颜色值 单词颜色； RGB颜色，数值或百分比； 十六进制颜色； p{color:red;} p{color:rgb(133,45,200);} p{color:rgb(20%,33%,25%);} p{color:#00ffff;} ","date":"2018-05-31","objectID":"/posts/79cd5/:12:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"长度值 以下都是相对单位； px，像素； em，是本元素给定字体的 font-size 值。如果 font-size = 14px, 那么 1em = 14px； 百分比，同样以 font-size 为基础； 注意，假如设置 font-size 单位为 em，则计算标准以元素的父元素的 font-size 为基础。 p { font-size: 12px; text-indent: 2em; line-height: 130%; } ","date":"2018-05-31","objectID":"/posts/79cd5/:12:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"水平居中实现 ","date":"2018-05-31","objectID":"/posts/79cd5/:13:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"行内元素 如果被设置的元素为文本、图片等行内元素时，通过设置父元素属性 text-align:center 实现。 例如： \u003cbody\u003e \u003cdiv class=\"txtCenter\"\u003e我想要在父容器中水平居中显示。\u003c/div\u003e \u003c/body\u003e .txtCenter { text-align: center; } ","date":"2018-05-31","objectID":"/posts/79cd5/:13:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"定宽块状元素 首先元素要是定宽的（table 或者设置了 width 属性），然后通过设置左右 margin 值为“auto”实现。 \u003cbody\u003e \u003cdiv\u003e我是定宽块状元素，哈哈，我要水平居中显示。\u003c/div\u003e \u003c/body\u003e div { width: 200px; margin: 20px auto; } 但这并不能使文本在 div 中居中显示，只是使 div 居中了。要使文本居中，还要设置 text-align:center。 ","date":"2018-05-31","objectID":"/posts/79cd5/:13:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"不定宽块状元素 有三种方法 加入 table 标签； 设置 display: inline 方法：与第一种类似，显示类型设为 行内元素，进行不定宽元素的属性设置； 设置 position:relative 和 left:50%：利用 相对定位 的方式，将元素向左偏移 50% ，即达到居中的目的。 使用 table 标签 利用table标签的长度自适应性—即不定义其长度也不默认父元素body的长度（table其长度根据其内文本长度决定），因此可以看做一个定宽度块元素，然后再利用定宽度块状居中的margin的方法，使其水平居中。 \u003cdiv\u003e \u003ctable\u003e \u003ctbody\u003e \u003ctr\u003e\u003ctd\u003e \u003cul\u003e \u003cli\u003e我是第一行文本\u003c/li\u003e \u003cli\u003e我是第二行文本\u003c/li\u003e \u003cli\u003e我是第三行文本\u003c/li\u003e \u003c/ul\u003e \u003c/td\u003e\u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e \u003c/div\u003e table{ border:1px solid; margin:0 auto; } 设置为行内元素 改变元素的 display 类型为行内元素，然后对父级元素设置 text-align:center 来实现居中效果。 \u003cbody\u003e \u003cdiv class=\"container\"\u003e \u003cul\u003e \u003cli\u003e\u003ca href=\"#\"\u003e1\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"#\"\u003e2\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"#\"\u003e3\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/body\u003e /* margin:0;padding:0（消除文本与div边框之间的间隙）*/ .container ul{ list-style:none; margin:0; padding:0; display:inline; } /* margin-right:8px（设置li文本之间的间隔）*/ .container li{ margin-right:8px; display:inline; } .container{ text-align:center; } 设置浮动和相对定位属性 通过给父元素设置 float，然后给父元素设置 position:relative 和 left:50%，子元素设置 position:relative 和 left: -50% 来实现水平居中。 \u003cbody\u003e \u003cdiv class=\"container\"\u003e \u003cul\u003e \u003cli\u003e\u003ca href=\"#\"\u003e1\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"#\"\u003e2\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"#\"\u003e3\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/body\u003e .container{ float:left; position:relative; left:50%; } .container ul{ list-style:none; margin:0; padding:0; position:relative; left:-50%; } .container li{ float:left; display:inline; margin-right:8px; } ","date":"2018-05-31","objectID":"/posts/79cd5/:13:3","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"垂直居中实现 ","date":"2018-05-31","objectID":"/posts/79cd5/:14:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"父元素高度确定的单行文本 单行文本通过设置父元素的 height 和 line-height 高度相同来垂直居中。原理是：line-height 与 font-size 之差为行间距，行间距分为两半分别加到文本行内容的顶部和底部。 缺点：当文字内容的长度大于块状元素的宽时，就有内容脱离了块。 \u003cdiv class=\"container\"\u003e hi,imooc! \u003c/div\u003e .container{ height:100px; line-height:100px; background:#999; } ","date":"2018-05-31","objectID":"/posts/79cd5/:14:1","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"父元素高度确定的多行文本 使用 table css 中有一个用于竖直居中的属性 vertical-align，在父元素设置此样式时，会对 inline-block 类型的子元素都有用。td 标签默认情况下设置了 vertical-align 为 middle，不需要显式设置。 \u003cbody\u003e \u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd class=\"wrap\"\u003e \u003cdiv\u003e \u003cp\u003e看我是否可以居中。\u003c/p\u003e \u003c/div\u003e \u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e \u003c/body\u003e table td{ height:500px; background:#ccc; } 使用 table-cell 在 chrome、firefox 及 IE8 以上的浏览器下可以设置块级元素的 display:table-cell（设置为表格单元显示），激活 vertical-align 属性。 \u003cdiv class=\"container\"\u003e \u003cdiv\u003e \u003cp\u003e看我是否可以居中。\u003c/p\u003e \u003cp\u003e看我是否可以居中。\u003c/p\u003e \u003cp\u003e看我是否可以居中。\u003c/p\u003e \u003c/div\u003e \u003c/div\u003e .container{ height: 300px; background: #ccc; display: table-cell; /*IE8以上及Chrome、Firefox*/ vertical-align: middle; /*IE8以上及Chrome、Firefox*/ } ","date":"2018-05-31","objectID":"/posts/79cd5/:14:2","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Web 开发"],"content":"隐性改变display类型 给元素（display:none 元素除外）设置 position:absolute 或 float 属性时，元素的display类型会自动变为 inline-block。即可以设置元素的 width 和 height，且默认宽度不占满父元素。 \u003cdiv class=\"container\"\u003e \u003ca href=\"#\" title=\"\"\u003e进入课程请单击这里\u003c/a\u003e \u003c/div\u003e .container a{ position: absolute; width: 200px; background: #ccc; } ","date":"2018-05-31","objectID":"/posts/79cd5/:15:0","tags":[],"title":"HTML和CSS基础教程-慕课网","uri":"/posts/79cd5/"},{"categories":["Python"],"content":"pip + pyvenv 方案的不足 手动更改版本包后，需要定期更新 requirements.txt 文件，以保持项目环境的一致。 项目中含有多个 requirement.txt 文件的，比如区分开发环境和生产环境，现有方案无法满足复杂需要； 卸载包的时候不能处理相关依赖包，造成包管理的混乱； Pipenv 主要特性包含： Enables truly deterministic builds, while easily specifying only what you want. 为锁定的版本包生成并检查 hash，确保安全性； 如果 pyenv 可用，自动安装所需的 Pythons； 通过查找自动递归找到项目 Pipfile 文件（有点像 git）； Pipfile 不存在时自动生成（类比 requirement.txt 是不是有很大的优势）； 在指定位置自动创建虚拟环境； Pipfile 在卸载/安装软件包时自动添加/删除软件包。 自动加载 .env 文件，可以为项目设置环境变量（与 Flask 配合相当好用吧）； 主要命令是 install，uninstall 和 lock。 PS：Pipenv的作者是 Kenneth Reitz 大神，他写了 requests。 安装和配置 ","date":"2018-05-19","objectID":"/posts/888bf/:0:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"安装 通过 brew 安装（也可以通过 pip 安装）： brew install pipenv ","date":"2018-05-19","objectID":"/posts/888bf/:1:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"配置 编辑 ~/.zshrc 文件 ","date":"2018-05-19","objectID":"/posts/888bf/:2:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"指定 virtualenv 存储路径 默认 virtualenv 都存储在 ~/.local/share/virtualenvs 目录下。 通过环境变量指定目录（最好使用绝对路径）： export WORKON_HOME=~/.venvs 如果要保存到项目目录下的 .venv 目录，设置： export PIPENV_VENV_IN_PROJECT=true 基本操作 ","date":"2018-05-19","objectID":"/posts/888bf/:2:1","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"新建虚拟环境 使用 pipenv shell 或 pipenv install 命令都能够自动触发创建虚拟环境。执行后会在目录中新建 Pipfile 和 Pipfile.lock 文件，这两个文件要加入 VCS。 或者直接指定 Python 版本，配合 pyenv 使用效果更佳。 pipenv --python 3.7.1 ","date":"2018-05-19","objectID":"/posts/888bf/:3:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"安装软件包 安装指定包： pipenv install xxx 安装 Pipfile 文件中指定的包： pipenv install 以上两个命令都支持 --dev 选项，表示安装为开发环境使用的包。 另外，安装 Pipfile.lock 文件中指定的所有包： pipenv sync ","date":"2018-05-19","objectID":"/posts/888bf/:4:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"使用虚拟环境 进入虚拟环境 pipenv shell 退出虚拟环境 exit 使用虚拟环境执行命令，但不进入虚拟环境： pipenv run python3 ","date":"2018-05-19","objectID":"/posts/888bf/:5:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"查看依赖关系 pipenv graph 输出 celery==4.0.2 - billiard [required: \u003c3.6.0,\u003e=3.5.0.2, installed: 3.5.0.3] - kombu [required: \u003e=4.0.2,\u003c5.0, installed: 4.1.0] - amqp [required: \u003e=2.1.4,\u003c3.0, installed: 2.2.2] - vine [required: \u003e=1.1.3, installed: 1.1.4] - pytz [required: \u003edev, installed: 2018.4] PyMySQL==0.8.0 redis==2.10.6 requests==2.18.4 - certifi [required: \u003e=2017.4.17, installed: 2018.1.18] - chardet [required: \u003e=3.0.2,\u003c3.1.0, installed: 3.0.4] - idna [required: \u003c2.7,\u003e=2.5, installed: 2.6] - urllib3 [required: \u003e=1.21.1,\u003c1.23, installed: 1.22] SQLAlchemy==1.2.6 tornado==4.3 还可以输出 json 格式 pipenv graph --json ","date":"2018-05-19","objectID":"/posts/888bf/:6:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"卸载软件包 使用 uninstall 命令 pipenv uninstall xxx 但是该命令不会自动卸载软件包的依赖包，例如卸载 requests 时不会自动卸载 urllib3。 可以借助 graph 命令获得依赖关系并卸载 pipenv uninstall `pipenv graph --json | python3 depends.py requests` 其中 depends.py 用于解析依赖关系： import sys import json package = sys.argv[1] other_dependencies = set() removing_dependencies = {package} for i in json.load(sys.stdin): dependencies = {dependency['key'] for dependency in i['dependencies']} if i['package']['key'] == package: removing_dependencies.update(dependencies) else: other_dependencies.update(dependencies) print(' '.join(removing_dependencies - other_dependencies)) ","date":"2018-05-19","objectID":"/posts/888bf/:7:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Python"],"content":"检查安全问题 根据 PEP 508 检查当前管理的软件包版本是否存在漏洞 pipenv check 支持 .env 文件 Pipenv 在执行 pipenv run 和 pipenv shell 命令时，如果在项目目录（即 Pipfile 的同级目录）下，存在 .env 文件，则会自动加载 .env 文件中的环境变量。 .env 文件不应加入到 VCS 中，因为它一般存储账号密码等关键保密信息。 参考链接 使用pipenv管理你的项目 | 小明明s à domicile | Python之美 Pipenv: Python Dev Workflow for Humans — pipenv documentation ","date":"2018-05-19","objectID":"/posts/888bf/:8:0","tags":[],"title":"使用Pipenv管理Python项目","uri":"/posts/888bf/"},{"categories":["Web 开发"],"content":"名词定义 Third-party application：第三方应用程序，本文中又称\"客户端”（client）； HTTP service：HTTP服务提供商，本文中简称\"服务提供商”； Resource Owner：资源所有者，本文中又称\"用户”（user）； User Agent：用户代理，本文中就是指浏览器； Authorization server：认证服务器，即服务提供商专门用来处理认证的服务器； Resource server：资源服务器，即服务提供商存放用户生成的资源的服务器； OAuth简介 ","date":"2018-05-18","objectID":"/posts/68076/:0:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"思路 OAuth在\"客户端\"与\"服务提供商\"之间，设置了一个授权层（authorization layer）。“客户端\"不能直接登录\"服务提供商”，只能登录授权层，以此将用户与客户端区分开来。“客户端\"登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。 “客户端\"登录授权层以后，“服务提供商\"根据令牌的权限范围和有效期，向\"客户端\"开放用户储存的资料。 ","date":"2018-05-18","objectID":"/posts/68076/:1:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"基本流程 +--------+ +---------------+ | |--(A)- Authorization Request -\u003e| Resource | | | | Owner | | |\u003c-(B)-- Authorization Grant ---| | | | +---------------+ | | | | +---------------+ | |--(C)-- Authorization Grant --\u003e| Authorization | | Client | | Server | | |\u003c-(D)----- Access Token -------| | | | +---------------+ | | | | +---------------+ | |--(E)----- Access Token ------\u003e| Resource | | | | Server | | |\u003c-(F)--- Protected Resource ---| | +--------+ +---------------+ 步骤如下： 客户端要求用户给予授权。 用户同意给予客户端授权。 客户端使用上一步获得的授权，向认证服务器申请令牌。 认证服务器对客户端进行认证以后，确认无误，同意发放令牌。 客户端使用令牌，向资源服务器申请获取资源。 资源服务器确认令牌无误，同意向客户端开放资源。 客户端的授权模式 OAuth 2.0定义了四种授权方式。 授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 授权码模式 是功能最完整、流程最严密的授权模式。采用这种模式的有：豆瓣、Coding、钉钉、微信。 HTTP头信息中明确指定不得缓存 Cache-Control: no-store。 ","date":"2018-05-18","objectID":"/posts/68076/:2:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"基本流程 +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- \u0026 Redirection URI ----\u003e| | | User- | | Authorization | | Agent -+----(B)-- User authenticates ---\u003e| Server | | | | | | -+----(C)-- Authorization Code ---\u003c| | +-|----|---+ +---------------+ | | ^ v (A) (C) | | | | | | ^ v | | +---------+ | | | |\u003e---(D)-- Authorization Code ---------' | | Client | \u0026 Redirection URI | | | | | |\u003c---(E)----- Access Token -------------------' +---------+ (w/ Optional Refresh Token) 步骤如下： 用户访问客户端，后者将前者导向认证服务器。 用户选择是否给予客户端授权。 假设用户给予授权，认证服务器将用户导向客户端事先指定的\"重定向URI”（redirection URI），同时附上一个授权码。 客户端收到授权码，附上早先的\"重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。 ","date":"2018-05-18","objectID":"/posts/68076/:3:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 A 参数(GET) response_type：表示授权类型，必选项，此处的值固定为\"code”； client_id：表示客户端的ID，必选项； redirect_uri：表示重定向URI，可选项； scope：表示申请的权限范围，可选项； state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值； ","date":"2018-05-18","objectID":"/posts/68076/:4:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 C 参数 认证服务器回应客户端，参数有： code：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 ","date":"2018-05-18","objectID":"/posts/68076/:5:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 D 参数(POST) grant_type：表示使用的授权模式，必选项，此处的值固定为\"authorization_code”。 code：表示上一步获得的授权码，必选项。 redirect_uri：表示重定向URI，必选项，且必须与A步骤中的该参数值保持一致。 client_id：表示客户端ID，必选项。 一般来说，这里还会有一个 client_secret 验证客户端的身份，因为 client_id 对用户是可见的。需要防止某些客户端伪装成其他客户端搞事情。 ","date":"2018-05-18","objectID":"/posts/68076/:6:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 E 参数 access_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。 简化模式 简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了\"授权码\"这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。 简化模式中，授权服务器不能签发 refresh_token。 ","date":"2018-05-18","objectID":"/posts/68076/:7:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"基本流程 +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- \u0026 Redirection URI ---\u003e| | | User- | | Authorization | | Agent -|----(B)-- User authenticates --\u003e| Server | | | | | | |\u003c---(C)--- Redirection URI ----\u003c| | | | with Access Token +---------------+ | | in Fragment | | +---------------+ | |----(D)--- Redirection URI ----\u003e| Web-Hosted | | | without Fragment | Client | | | | Resource | | (F) |\u003c---(E)------- Script ---------\u003c| | | | +---------------+ +-|--------+ | | (A) (G) Access Token | | ^ v +---------+ | | | Client | | | +---------+ 步骤如下： 客户端将用户导向认证服务器。 用户决定是否给于客户端授权。 假设用户给予授权，认证服务器将用户导向客户端指定的\"重定向URI”，并在URI的Hash部分包含了访问令牌。 浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。 资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。 浏览器执行上一步获得的脚本，提取出令牌。 浏览器将令牌发给客户. ","date":"2018-05-18","objectID":"/posts/68076/:8:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 A 参数(GET) response_type：表示授权类型，此处的值固定为\"token”，必选项。 client_id：表示客户端的ID，必选项。 redirect_uri：表示重定向的URI，可选项。 scope：表示权限范围，可选项。 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。 ","date":"2018-05-18","objectID":"/posts/68076/:9:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 C 参数 认证服务器回应客户端的URI，包含以下参数： access_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 密码模式 密码模式（Resource Owner Password Credentials Grant）中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向\"服务商提供商\"索要授权。 通常用在用户对客户端高度信任的情况下。 ","date":"2018-05-18","objectID":"/posts/68076/:10:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"基本流程 +----------+ | Resource | | Owner | | | +----------+ v | Resource Owner (A) Password Credentials | v +---------+ +---------------+ | |\u003e--(B)---- Resource Owner -------\u003e| | | | Password Credentials | Authorization | | Client | | Server | | |\u003c--(C)---- Access Token ---------\u003c| | | | (w/ Optional Refresh Token) | | +---------+ +---------------+ 步骤如下： 用户向客户端提供用户名和密码。 客户端将用户名和密码发给认证服务器，向后者请求令牌。 认证服务器确认无误后，向客户端提供访问令牌。 ","date":"2018-05-18","objectID":"/posts/68076/:11:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 B 参数(POST) grant_type：表示授权类型，此处的值固定为\"password”，必选项。 username：表示用户名，必选项。 password：表示用户的密码，必选项。 scope：表示权限范围，可选项。 ","date":"2018-05-18","objectID":"/posts/68076/:12:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 C 参数 参考授权码模式-流程E。 客户端模式 客户端模式（Client Credentials Grant）指客户端以自己的名义，而不是以用户的名义，向\"服务提供商\"进行认证。 严格地说，客户端模式并不属于 OAuth 框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求\"服务提供商\"提供服务，其实不存在授权问题。 ","date":"2018-05-18","objectID":"/posts/68076/:13:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"基本流程 +---------+ +---------------+ | | | | | |\u003e--(A)- Client Authentication ---\u003e| Authorization | | Client | | Server | | |\u003c--(B)---- Access Token ---------\u003c| | | | | | +---------+ +---------------+ 步骤如下： 客户端向认证服务器进行身份认证，并要求一个访问令牌。 认证服务器确认无误后，向客户端提供访问令牌。 ","date":"2018-05-18","objectID":"/posts/68076/:14:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 A 参数(POST) grant_type：表示授权类型，此处的值固定为\"client_credentials”，必选项。 scope：表示权限范围，可选项。 ","date":"2018-05-18","objectID":"/posts/68076/:15:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Web 开发"],"content":"流程 B 参数 参考授权码模式-流程E。 更新令牌(POST) 如果用户访问的时候，客户端的\"访问令牌\"已经过期，则需要使用\"更新令牌\"申请一个新的访问令牌。 grant_type：表示使用的授权模式，此处的值固定为\"refresh_token”，必选项。 refresh_token：表示早前收到的更新令牌，必选项。 scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。 一般也会带上 client_id。 参考链接 理解OAuth 2.0 - 阮一峰的网络日志 rfc6749 - RFC Reader ","date":"2018-05-18","objectID":"/posts/68076/:16:0","tags":[],"title":"OAuth2授权协议","uri":"/posts/68076/"},{"categories":["Python"],"content":"Python import 的搜索路径 当前目录 环境变量 PYTHONPATH 中指定的路径列表中依次搜索 在 Python 安装路径的 lib 库中搜索 绝对导入 绝对导入有以下几种格式： import foo import foo.bar import foo as bar from foo import bar 除此之外还有一种 from foo import * 的形式，但是不推荐使用。原因是这样会打乱命名空间。模块导入的函数可能会与自定义的函数或变量重名，造成未知的 bug。 相对导入 PEP328 介绍了引入相对导入的原因，以及选择了哪种语法。 具体来说，使用句点来决定如何相对导入其他包或模块，多个文件层级使用多个句点。不过 PEP328 建议相对导入的层级不要超过两层。 # 从当前目录的 foo 模块中导入 bar from .foo import bar # 从当前文件的上级目录的 foo 模块中导入 bar from ..foo import bar 需要注意的是，存在相对导入的语句的模块，不能直接运行，否则会有异常。 ValueError: Attempted relative import in non-package 原因如下： 在没有明确指定包结构的情况下，Python 是根据 __name__ 来决定一个模块在包中的结构的，如果是 __main__ 则它本身是顶层模块，没有包结构；如果是 A.B.C 结构，那么顶层模块是 A。基本上遵循这样的原则： 如果是绝对导入，一个模块只能导入自身的子模块或和它的顶层模块同级别的模块及其子模块； 如果是相对导入，一个模块必须有包结构且只能导入它的顶层模块内部的模块； 如果一个模块被直接运行，则它自己为顶层模块，不存在层次结构，所以找不到其他的相对路径。 如果想要在直接运行的模块中使用相对导入，那么可以通过将路径添加到 Python 检索路径的方式。 import sys sys.path.append(\"/path/to/folder/containing/my_package\") import my_package 注意，相对导入与绝对导入仅用于包内部。如果是同一个目录下的两个文件，且目录不是一个包，那么每一个 python 文件都是一个独立的可以直接被其他模块导入的模块，就像导入标准库一样，它们不存在相对导入和绝对导入的问题。 导入注意事项 ","date":"2018-05-13","objectID":"/posts/37d90/:0:0","tags":[],"title":"Python中的导入","uri":"/posts/37d90/"},{"categories":["Python"],"content":"循环导入 如果创建了两个模块，二者互相导入对方，就会出现循环导入。运行任何一个模块，都会引发 AttributeError 。 在 《Flask Web 开发：基于 Python 的 Web 应用开发实战》中，第七章的大型结构有一个 hack 循环导入的方法——将导入代码放到模块的末尾。 但是，这与“所有的导入语句都应该位于模块的顶部”的约定相悖，因此并不是一个好的方案。在解决循环导入的问题时，首先考虑的方案应该是重构代码。 参考链接 Python导入模块的几种姿势| 编程派 | Coding Python PEP 328 – Imports: Multi-Line and Absolute/Relative | Python.org Python 相对导入与绝对导入 ","date":"2018-05-13","objectID":"/posts/37d90/:1:0","tags":[],"title":"Python中的导入","uri":"/posts/37d90/"},{"categories":["Web 开发"],"content":"简介 ","date":"2018-05-05","objectID":"/posts/e85e6/:0:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"什么是 WebSocket WebSocket protocol 是 HTML5 定义的一种新的标准协议（RFC6455），它实现了浏览器与服务器的全双工通信（full-duplex）。 ","date":"2018-05-05","objectID":"/posts/e85e6/:1:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"为什么需要 WebSocket 传统的 HTTP+HTML 方案只适用于客户端主动发起请求的场景，而无法满足服务器端发起的通信要求。而 Ajax 和 Long poll 等基于传统HTTP的动态客户端技术使用轮询，耗费了大量的网络带宽和计算资源。 WebSocket 相对于普通的 Socket 通信，在应用层定义了基本的交互流程，使得 Tornado 等服务器框架和JavaScript 客户端可以构建出标准的 WebSocket 模块。 ","date":"2018-05-05","objectID":"/posts/e85e6/:2:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"WebSocket 的特点 最大的特点，当然是服务器端可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话。 其他特点包括： 建立在 TCP 协议之上，服务器端的实现比较容易。 与 HTTP 协议有良好的兼容性。默认端口也是 80 和 443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。 数据格式比较轻量，性能开销小，通信高效。 可以发送文本，也可以发送二进制数据。 没有同源限制，客户端可以与任意服务器通信。 协议标识符是 ws（如果加密，则为 wss），服务器网址就是 URL。 WebSocket 握手原理 WebSocket 的通信原理是在客户端与服务器之间建立 TCP 持久链接，从而使得当服务器有消息需要推送给客户端时能够进行即时通信。 虽然 WebSocket 不是 HTTP，但在握手阶段，仍然使用了 HTTP 协议进行传输。 ","date":"2018-05-05","objectID":"/posts/e85e6/:3:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"客户端握手请求 客户端通过发送含有特殊字段的 HTTP Request 告诉服务器需要建立一个 WebSocket 连接，特殊字段如下 GET ws://echo.websocket.org/?encoding=text HTTP/1.1 Origin: http://websocket.org Connection: Upgrade Sec-WebSocket-Key: uRovscZjNol/umbTt5uKmw== Upgrade: websocket Sec-WebSocket-Version: 13 含义是： 客户端希望建立一个 WebSocket 链接，ws 对应 http，wss 对应 https； 客户端使用的 WebSocket 版本是 13，密钥是 uRovscZjNo1/umbTt5uKmw==（不用于加密，用于标识该连接）。 Origin 由浏览器添加，WebSocket协议本身不要求同源策略（Same-origin Policy），但服务器可以根据 Origin 拒绝 WebSocket 请求； 还有可能存在一个 Sec-WebSocket-Protocol: chat 字段，由用户定义，用来区分同 URL 下，不同的服务所需要的协议。 ","date":"2018-05-05","objectID":"/posts/e85e6/:4:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"服务端握手响应 服务端如果同意 WebSocket 链接则返回类似的 Response，特殊字段如下 HTTP/1.1 101 Switching Protocols Connection: Upgrade Upgrade: WebSocket Access-Control-Allow-Origin: http://websocket.org Access-Control-Allow-Credentials: true Sec-WebSocket-Accept: rLHCkw/SKsO9GAH/ZSFhBATDKrU= Access-Control-Allow-Headers: content-type 服务器返回 HTTP 101，服务器已经将本连接转换为 WebSocket 链接； Sec-WebSocket-Accept 经过服务器确认并密过后的 Sec-WebSocket-Key，用于客户端确认服务器身份。 同源策略的话看服务器的实现； 至此，在客户端和服务端之间已经建立了一个 TCP 持久长链接，双方已经可以随时向对方发送消息。 HTML5 客户端实现 客户端围绕着 WebSocket 对象展开。 在 JavaScript 中可以通过如下代码初始化 WebSocket 对象，在代码中需要给 WebSocket 构造函数传入服务器的 URL 地址，URL 是 ws 或 wss 开头的 URL。 var Socket = new WebSocket(url); ","date":"2018-05-05","objectID":"/posts/e85e6/:5:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"回调函数属性 可以为该对象的如下事件制定处理函数以响应它们。 WebSocket.onopen 此事件发生在 WebSocket 链接建立时； WebSocket.onmessage 此事件发生在收到了来自服务器的消息时； WebSocket.onerror 此事件发生在通信过程中有任何错误时； WebSocket.onclose 此事件发生在与服务器的链接关闭时。 ","date":"2018-05-05","objectID":"/posts/e85e6/:6:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"普通属性 WebSocket.readyState 返回实例对象的当前状态，共四种 WebSocket.CONNECTING 值为0，表示正在连接。 WebSocket.OPEN 值为1，表示连接成功，可以通信了。 WebSocket.CLOSING 值为2，表示连接正在关闭。 WebSocket.CLOSED 值为3，表示连接已经关闭，或者打开连接失败。 webSocket.bufferedAmount 表示还有多少字节的二进制数据没有发送出去，可以用来判断发送是否结束。 ","date":"2018-05-05","objectID":"/posts/e85e6/:7:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"主动操作方法 除事件外，还可以通过 WebSocket 对象的两个方法进行主动操作： WebSocket.send(data) 向服务器发送消息； WebSocket.close() 主动关闭现有连接。 Tornado 服务端实现 Tornado定义了tornado.websocket.WebSocketHandler类用于处理 WebSocket 链接的请求。 ","date":"2018-05-05","objectID":"/posts/e85e6/:8:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"消息处理方法 open()：在新链接建立时调用此方法。在本方法中，可以像在 get()、post() 中一样使用 get_argument() 函数获取客户端提交的参数，以及用 get_secure_cookie()、set_secure_cookie() 等方法操作 cookie。 on_message(message)：收到来自客户端消息时调用； on_close()：在 WebSocket 连接关闭时调用。 ","date":"2018-05-05","objectID":"/posts/e85e6/:9:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"主动操作方法 write_message(message, binary=False)：用于写消息； close(code=None, reason=None)：主动关闭 WebSocket 连接。 ","date":"2018-05-05","objectID":"/posts/e85e6/:10:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Web 开发"],"content":"其他方法 check_origin(origin) 重新实现自定义的同源检查策略。origin 参数是从 header 中获得的 Origin，如果客户端没有发送 Origin header，该方法不会被调用。返回 True 表示接受请求，返回 False 表示拒绝请求。Tornado 4.0 以上版本，默认情况下，只允许header中 Origin 和 Host 域名一致的请求。 Nginx 配置 主要是对 Upgrade 和 Connection header 的设置。 location ~ /api/kernels/ { proxy_pass http://localhost:8888; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade \"websocket\"; proxy_set_header Connection \"Upgrade\"; proxy_read_timeout 86400; } 保持连接 大概有以下几种方式： 修改 Nginx 连接超时时间 proxy_read_timeout； 客户端定时发送心跳包维持连接； 客户端异常断开时自动重连； 参考链接 WebSocket 教程 - 阮一峰 The WebSocket Protocol WebSocket 是什么原理？为什么可以实现持久连接？ - 知乎 WebSocket - MDN Nginx代理webSocket时60s自动断开, 怎么保持长连接 - 晴识明月 python 利用websocket实现服务器向客户端推送消息 - 晴识明月 WebSocket - 廖雪峰 可扩展的 WebSocket Server ","date":"2018-05-05","objectID":"/posts/e85e6/:11:0","tags":[],"title":"WebSocket应用开发","uri":"/posts/e85e6/"},{"categories":["Infrastructure"],"content":"挂载存储 ","date":"2018-05-05","objectID":"/posts/96944/:0:0","tags":[],"title":"Linux存储操作","uri":"/posts/96944/"},{"categories":["Infrastructure"],"content":"查看设备名 连接存储设备（移动硬盘、U 盘等），执行： sudo fdisk -l TF 卡可能会被显示为 /dev/mmc，U盘和移动硬盘会被显示为 /dev/sda。 ","date":"2018-05-05","objectID":"/posts/96944/:1:0","tags":[],"title":"Linux存储操作","uri":"/posts/96944/"},{"categories":["Infrastructure"],"content":"新建挂载路径 比如要把存储设备挂载到 ~/downloads 目录，要求该目录必须已经存在。 mkdir ~/downloads ","date":"2018-05-05","objectID":"/posts/96944/:2:0","tags":[],"title":"Linux存储操作","uri":"/posts/96944/"},{"categories":["Infrastructure"],"content":"挂载 注意这里挂载的是分区 sda1，不是设备 sda。-o 选项指定归属用户和归属组，保证该用户拥有该挂载目录的读写权限。 sudo mount -o uid=pi,pid=pi /dev/sda1 ~/downloads 取消挂载存储 sudo umount ~/downloads 如果提示设备在忙，查看占用该目录的进程，结束进程后再取消挂载。 lsof | grep ~/downloads 格式化存储设备 首先将要格式化的存储设备分区取消挂载。 sudo umount ~/downloads 格式化为 FAT32 格式（在 Linux 中都会显示为 FAT 格式） sudo mkfs.vfat -F 32 /dev/sda1 格式化为 Linux EXT 格式 sudo mkfs.ext4 /dev/sda1 sudo mkfs.ext3 /dev/sda1 sudo mkfs.ext2 /dev/sda1 格式化为 NTFS 格式，需要安装 nftsprogs sudo apt-get install ntfsprogs sudo mkfs.ntfs /dev/sda1 参考链接 树莓派挂载U盘 - 简书 ","date":"2018-05-05","objectID":"/posts/96944/:3:0","tags":[],"title":"Linux存储操作","uri":"/posts/96944/"},{"categories":["Python"],"content":"什么是异步 ","date":"2018-05-03","objectID":"/posts/b95cd/:0:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"同步 IO 我们知道，CPU 的速度远远快于磁盘、网络等 IO。在一个线程中，当遇到 IO 操作时，如读写文件、发送网络请求，就需要等待 IO 操作完成，才能继续进行下一步的操作。这种称之为 同步 IO。 同步 IO 会在进行 IO 操作时，挂起当前线程，导致其他需要 CPU 执行的代码无法被当前线程处理，CPU的高速执行能力和IO设备的龟速（与 CPU 相比）严重不匹配。为此，我们可以使用多进程和多线程解决，也可以使用 异步 IO。 ","date":"2018-05-03","objectID":"/posts/b95cd/:1:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"异步 IO 异步 IO 的工作模式是，当代码需要执行一个耗时的 IO 操作时，它只发出 IO 指令，并不等待 IO 结果，然后就去执行其他代码。一段时间后，当 IO 返回结果时，再通知 CPU 进行处理。 异步 IO 模型需要一个消息循环，在消息循环中，主线程不断重复“读取消息-处理消息”这一过程。 ","date":"2018-05-03","objectID":"/posts/b95cd/:2:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"协程 协程，又称微线程，纤程，英文 coroutine。 协程的概念可以和函数调用来类比理解： 子函数的入口只有一个，一旦退出即完成了函数的执行，子函数的一个实例只会返回一次。子函数与父函数之间是被调用者与调用者的关系； 协程可以通过 yield 调用其它协程。通过 yield 方式转移执行权的携程之间不是调用者与被调用者的关系，而是彼此对称、平等的。 函数调用的声明周期遵循后进先出（最后一个被调用的子例程最先返回）；相反，协程的生命周期完全由他们的使用需要决定。 以下是一个协程实现的生产者-消费者模型，生产者生产消息后，通过 yield 跳转到消费者开始执行，待消费者执行完毕后，切回生产者继续生产。 def consumer(): \"\"\"消费者\"\"\" r = \"\" while True: n = yield r if not n: return print(\"[CONSUMER] Consuming %s...\" % n) r = \"200 OK\" def producer(c): \"\"\"生产者\"\"\" c.send(None) n = 0 while n \u003c 5: n = n + 1 print('[PRODUCER] Producing %s...' % n) r = c.send(n) print('[PRODUCER] Consumer return: %s' % r) c.close() c = consumer() produce(c) 输出为： [PRODUCER] Producing 1... [CONSUMER] Consuming 1... [PRODUCER] Consumer return: 200 OK [PRODUCER] Producing 2... [CONSUMER] Consuming 2... [PRODUCER] Consumer return: 200 OK [PRODUCER] Producing 3... [CONSUMER] Consuming 3... [PRODUCER] Consumer return: 200 OK [PRODUCER] Producing 4... [CONSUMER] Consuming 4... [PRODUCER] Consumer return: 200 OK [PRODUCER] Producing 5... [CONSUMER] Consuming 5... [PRODUCER] Consumer return: 200 OK ","date":"2018-05-03","objectID":"/posts/b95cd/:3:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"关于异步概念的误区 异步不能提升单个IO操作任务（web 请求）的响应速度。异步通过在等待 IO 操作时执行其他代码，提高了 CPU 的利用率，进而提升了整体的运行效率，但是对单个任务（web 请求）来说，还是需要等待 IO 返回结果后才能继续操作（返回 HTTP 响应），不能提升单个任务的响应速度。 同步程序不能通过协程异步封装的形式变为异步程序。要写出有异步效果的程序，只有协程是不够的，还需要有底层 IO 的支持。在发生 IO 时，要将 IO 操作交给异步实现去执行，并让渡出协程的执行权，由调度去调度执行其他协程。因此如果底层 IO 未对协程调用做处理，其结果仍然会阻塞这个协程，不能实现异步的效果，比如 SQLAlchemy。 Python3 的异步实现 ","date":"2018-05-03","objectID":"/posts/b95cd/:4:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"asyncio asyncio 是 Python 3.4 版本引入的标准库，直接内置了对异步 IO 的支持。 asyncio 的编程模型就是一个消息循环。我们从 asyncio 模块中直接获取一个 EventLoop 的引用，然后把需要执行的协程扔到 EventLoop 中执行，就实现了异步 IO。 import threading import asyncio # @asyncio.coroutine把一个generator标记为coroutine类型 @asyncio.coroutine def hello(): print('Hello world! (%s)' % threading.currentThread()) # 把asyncio.sleep(1)看成是一个耗时1秒的IO操作 r = yield from asyncio.sleep(1) print('Hello again! (%s)' % threading.currentThread()) # 获取event_loop引用 loop = asyncio.get_event_loop() # 把coroutine扔到EventLoop中执行 tasks = [hello(), hello()] loop.run_until_complete(asyncio.wait(tasks)) loop.close() tasks 中的第一个 hello() 执行时，首先打印出 “Hello, world…\"，然后 yield from 语法可以让我们方便地调用另一个 generator，即 asyncio.sleep()。 由于 asyncio.sleep() 也是一个 coroutine，所以线程不会等待 asyncio.sleep()，而是直接中断并执行下一个消息循环，即 tasks 中的第二个 hello()。 第二个 hello() 的执行同第一个 hello() 一样。 当 asyncio.sleep() 返回时，线程就可以从 yield from 拿到返回值（此处是 None ），然后接着执行下一行语句，打印出 “Hello, again…” 执行结果如下，两个 coroutine 是由同一个线程“并发”执行的。 Hello world! (\u003c_MainThread(MainThread, started 140735195337472)\u003e) Hello world! (\u003c_MainThread(MainThread, started 140735195337472)\u003e) (暂停约1秒) Hello again! (\u003c_MainThread(MainThread, started 140735195337472)\u003e) Hello again! (\u003c_MainThread(MainThread, started 140735195337472)\u003e) ","date":"2018-05-03","objectID":"/posts/b95cd/:5:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"async/await 为了简化并更好地标识异步 IO，从 Python 3.5 开始引入了新的语法 async 和 await，可以让 coroutine 的代码更简洁易读。 要使用新的语法，只需要做两步简单的替换： 把 @asyncio.coroutine 替换为 async； 把 yield from 替换为 await。 举个🌰 @asyncio.coroutine def hello(): print(\"Hello world!\") r = yield from asyncio.sleep(1) print(\"Hello again!\") 用新语法可以编写为 async def hello(): print(\"Hello world!\") r = await asyncio.sleep(1) print(\"Hello again!\") 其他代码保持不变。 Tornado 的异步实现 Tornado 是一个 Python Web 开发框架，也是异步网络请求库。通过使用非阻塞网络 IO，号称能够承载 10K 的请求量。 Tornado is a Python web framework and asynchronous networking library, originally developed at FriendFeed. By using non-blocking network I/O, Tornado can scale to tens of thousands of open connections, making it ideal for long polling, WebSockets, and other applications that require a long-lived connection to each user. 常见的情况是，在 request handler 可能需要进行网络请求。此时我们应尽量使用异步 handler 和异步网络请求，以提高并发量和 Web 服务器效率。 ","date":"2018-05-03","objectID":"/posts/b95cd/:6:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"异步 handler 异步 handler 实现主要有两种方式：tornado.web.asynchronous 和 tornado.gen.coroutine。 推荐使用 tornado.gen.coroutine 方式，不需要写回调函数，改造已有的同步代码也相对简单。 ","date":"2018-05-03","objectID":"/posts/b95cd/:7:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"tornado.web.asynchronous 使用 tornado.web.asynchronous 装饰器修饰 handler，直接调用异步代码并使用回调函数处理响应。 import tornado.web import tornado.httpclient class MyRequestHandler(tornado.web.RequestHandler): @tornado.web.asynchronous def get(self): \"\"\"异步 handler 方法\"\"\" http_client = tornado.httpclient.AsyncHTTPClient() http_client.fetch(\"https://google.com/\", self._on_download) def _on_download(self, response): \"\"\"回调方法\"\"\" self.write(\"Downloaded!\") # 使用了 asynchronous 需要手动 finish，否则一直 pending self.finish() ","date":"2018-05-03","objectID":"/posts/b95cd/:7:1","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"tornado.gen.coroutine 使用 tornado.gen.asynchr 装饰器修饰 handler，使用 yield 调用异步代码并获取响应。 import tornado.gen import tornado.web import tornado.httpclient class MyRequestHandler(tornado.web.RequestHandler): @tornado.gen.coroutine def get(self): \"\"\"异步 handler 方法\"\"\" http_client = tornado.httpclient.AsyncHTTPClient() response = yield http_client.fetch(\"https://google.com/\") retunr self.write(response.body) ","date":"2018-05-03","objectID":"/posts/b95cd/:7:2","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"异步网络请求 在 Tornado 中进行异步网络请求，可以使用 Tornado 自带的 tornado.httpclient.AsyncHTTPClient。 但在实际开发中，我们一般使用Requests库进行网络请求，相比前者，简直不能更好用。因此这里我们介绍一种将同步代码封装为“异步代码”的方法。 ","date":"2018-05-03","objectID":"/posts/b95cd/:8:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"Requests + ThreadPoolExecutor Python3 中的 concurrent.futures.ThreadPoolExecutor 是对多线程的更高级封装，其内部实现中，返回的是 concurrent.futures.Future 对象。 Future 是常见的一种并发设计模式，在多个其他语言中都可以见到这种解决方案。一个 Future 对象代表了一些尚未就绪（完成）的结果，在「将来」的某个时间就绪了之后就可以获取到这个结果。在 Future 模式下，调用方式改为异步。 我们使用 ThreadPoolExecutor 对requests库进行封装，启动一个线程来执行阻塞的网络请求，假装自己是一个异步 IO。ThreadPoolExecutor 的接口比 threading 模块要简单，有利于写出高效、异步、非阻塞的并行代码。 首先封装 requests 库 #!/usr/bin/env python3 # -*- coding: utf-8 -*- from concurrent.futures import ThreadPoolExecutor import tornado.gen import requests class AsyncRequests(object): \"\"\"异步网络请求类 使用线程池将同步网络请求转换为异步网络请求。 使用requests进行网络请求，实现了get/post/put请求方法。 \"\"\" thread_pool = ThreadPoolExecutor(4) @classmethod @tornado.gen.coroutine def aget(cls, *args, **kw): \"\"\"http get\"\"\" resp = yield cls.thread_pool.submit(requests.get, *args, **kw) return resp 在异步 handler 中调用异步网络请求 AsyncRequests.aget import tornado.web import tornado.gen class StatisticPlatformData(tornado.web.RequestHandler): \"\"\"采购用户数据累计\"\"\" @tornado.web.authenticated @tornado.gen.coroutine def get(self): url = \"https://httpbin.org/get\" resp = yield AsyncAPIRequests.aget(url) jsondata = resp.json() return self.write(jsondata) ","date":"2018-05-03","objectID":"/posts/b95cd/:8:1","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["Python"],"content":"多异步请求并发 有时需要在一个 handler 里面同时进行多个网络请求，如果我们像下面这样写，那么网络请求是串行执行的，HTTP 响应时间会比较长。 import tornado.gen @tornado.gen.coroutine def get(self): url = \"https://httpbin.org/get\" resp1 = yield AsyncAPIRequests.aget(url) resp2 = yield AsyncAPIRequests.aget(url) resp3 = yield AsyncAPIRequests.aget(url) return self.write(\"haha\") 多异步请求并发执行 import tornado.gen @tornado.gen.coroutine def get(self): http_client = AsyncHTTPClient() # 使用 list 方式 response1, response2 = yield [http_client.fetch(url1), http_client.fetch(url2)] # 使用 dict 方式 response_dict = yield dict(response3=http_client.fetch(url3), response4=http_client.fetch(url4)) response3 = response_dict['response3'] response4 = response_dict['response4'] 参考链接 异步IO - 廖雪峰的官方网站 协程：异步与并发 使用tornado让你的请求异步非阻塞 - 董伟明博客 使用Python进行并发编程-PoolExecutor篇 - 董伟明博客 协程 - 维基百科 Tornado.gen - Generator-based coroutines Asynchronous and non-Blocking I/O 真正的 Tornado 异步非阻塞 怎样理解阻塞非阻塞与同步异步的区别？- 知乎 ","date":"2018-05-03","objectID":"/posts/b95cd/:9:0","tags":[],"title":"Tornado异步非阻塞请求","uri":"/posts/b95cd/"},{"categories":["工欲善其事"],"content":"适用场景 各个项目共用一个库，而这个库正在快速迭代更新的过程中。 操作 假设有项目P1、P2，同时共用项目S的代码。 ","date":"2018-04-05","objectID":"/posts/b1129/:0:0","tags":[],"title":"在git项目中引用另一个git项目","uri":"/posts/b1129/"},{"categories":["工欲善其事"],"content":"添加remote 在P1项目中添加S项目的remote地址 git remote add jupyter git@git.coding.net:MrChi/JupyterNotes.git ","date":"2018-04-05","objectID":"/posts/b1129/:1:0","tags":[],"title":"在git项目中引用另一个git项目","uri":"/posts/b1129/"},{"categories":["工欲善其事"],"content":"引用 在P1项目中引用S项目代码： git subtree add --prefix=\u003c本地子项目目录\u003e \u003c远程库仓库地址|远程库别名\u003e \u003c分支名\u003e --squash prefix 参数指定存放S项目的路径，建议使用相对于P1项目根目录的相对路径； squash 参数：默认情况下，P1项目会合并S项目本身所有的提交记录，使用该参数可以合并子项目的提交记录为一条； 操作后，在P1项目中会产生一条commit记录。 例如： git subtree add --prefix=jupyternotes jupyter master ","date":"2018-04-05","objectID":"/posts/b1129/:2:0","tags":[],"title":"在git项目中引用另一个git项目","uri":"/posts/b1129/"},{"categories":["工欲善其事"],"content":"更新 在P1项目中更新引用的S项目的代码 git subtree pull --prefix=\u003cprefix\u003e \u003crepository\u003e \u003cref\u003e ","date":"2018-04-05","objectID":"/posts/b1129/:3:0","tags":[],"title":"在git项目中引用另一个git项目","uri":"/posts/b1129/"},{"categories":["工欲善其事"],"content":"提交 在P1项目中向S项目提交在P1中进行的更改 git subtree push --prefix=\u003cprefix\u003e \u003crepository\u003e \u003cref\u003e 优势和劣势 ","date":"2018-04-05","objectID":"/posts/b1129/:4:0","tags":[],"title":"在git项目中引用另一个git项目","uri":"/posts/b1129/"},{"categories":["工欲善其事"],"content":"优势 对于P1项目来说，S项目的代码是透明的，只是一个普通目录，不需要做特殊处理；只需要维护subtree的人在合适的时候将代码同步到S项目即可。 ","date":"2018-04-05","objectID":"/posts/b1129/:5:0","tags":[],"title":"在git项目中引用另一个git项目","uri":"/posts/b1129/"},{"categories":["工欲善其事"],"content":"劣势 subtree的这种方式，只使用了分支，对版本不能进行有效的控制。如果S项目更新了代码但与P1项目不兼容，P1项目更新后就可能会出现问题。 如果追求稳定，可以给S项目单独拉出一个版本分支，例如“v1.0”，subtree只使用这个分支即可。 参考链接 用 Git Subtree 在多个 Git 项目间双向同步子项目，附简明使用手册 ","date":"2018-04-05","objectID":"/posts/b1129/:6:0","tags":[],"title":"在git项目中引用另一个git项目","uri":"/posts/b1129/"},{"categories":["Python"],"content":" q = session.query(SomeMappedClass) 使用SQLAlchemy的session进行数据库查询时，会产生Query类的实例： class sqlalchemy.orm.query.Query 以下是Query类一些常用的方法。 筛选 ","date":"2018-03-14","objectID":"/posts/b523f/:0:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"filter_by() 传入a=b格式的参数。 ","date":"2018-03-14","objectID":"/posts/b523f/:1:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"filter() 传入Class.a!=b表达式格式的参数。 ","date":"2018-03-14","objectID":"/posts/b523f/:2:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"limit(n) 限制返回n个结果。 ","date":"2018-03-14","objectID":"/posts/b523f/:3:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"offset(m) 从第m+1个结果开始返回。 ","date":"2018-03-14","objectID":"/posts/b523f/:4:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"slice(start, stop) 切片返回结果，类似limit和offset的组合。相当于offset(start).limit(stop-start)。 结果 ","date":"2018-03-14","objectID":"/posts/b523f/:5:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"all() 将所有结果组成一个list返回。 ","date":"2018-03-14","objectID":"/posts/b523f/:6:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"first() 没有查询结果时，返回None； 其他情况下，返回第一个查询结果； ","date":"2018-03-14","objectID":"/posts/b523f/:7:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"one() 仅在查询结果为一个时返回结果，否则抛出错误。 没有查询结果时，抛出sqlalchemy.orm.exc.NoResultFound； 一个查询结果时，返回该对象； 当查询结果为多个时，抛出sqlalchemy.orm.exc.MultipleResultsFound； ","date":"2018-03-14","objectID":"/posts/b523f/:8:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"one_or_none() 没有结果，返回None； 一个查询结果时，返回该对象； 当查询结果为多个时，抛出sqlalchemy.orm.exc.MultipleResultsFound； ","date":"2018-03-14","objectID":"/posts/b523f/:9:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"scalar() 没有结果，返回None； 一个结果，返回查询结果的第一个元素； 多个结果，抛出sqlalchemy.orm.exc.MultipleResultsFound； ","date":"2018-03-14","objectID":"/posts/b523f/:10:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"count() 返回查询到的结果个数。如果没有数据，返回0。 操作 ","date":"2018-03-14","objectID":"/posts/b523f/:11:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"get(ident) 查询操作。传入主键ID，返回对象或者None。 ","date":"2018-03-14","objectID":"/posts/b523f/:12:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"update(values, synchronize_session='evaluate’, update_args=None) 更新操作。举个栗子： session.query(User).filter(User.age == 25).update({User.age: User.age - 10}) ","date":"2018-03-14","objectID":"/posts/b523f/:13:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"with_lockmode(mode) 锁操作。mode取值如下： None - 取消锁； update - 被转义为SQL语句FOR UPDATE（标准SQL，大部分数据库支持）； update_nowait - 被转义为SQL语句FOR UPDATE NOWAIT（仅支持Oracle、PostgreSQL 8.1+版本）； read - 被转义为 LOCK IN SHARE MODE (MySQL数据库)， FOR SHARE (PostgreSQL数据库)。 函数 ","date":"2018-03-14","objectID":"/posts/b523f/:14:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Python"],"content":"func.sum 对查询到的记录的字段进行求和，如果记录不存在，结果为None，不是0。 参考链接 Query API — SQLAlchemy Documentation ","date":"2018-03-14","objectID":"/posts/b523f/:15:0","tags":[],"title":"SQLAlchemy查询常用方法","uri":"/posts/b523f/"},{"categories":["Web 开发"],"content":"常见方法 现在常见的方法主要是以下两种： 第三方库：clipboard.js 原生方法：document.execCommand() clipboard.js 这是clipboard的官网：https://clipboardjs.com/，看起来就是这么的简单。 ","date":"2018-03-13","objectID":"/posts/d8fd4/:0:0","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"引用 直接引用： \u003cscript src=\"dist/clipboard.min.js\"\u003e\u003c/script\u003e 包： npm install clipboard --save ，然后 import Clipboard from 'clipboard'; ","date":"2018-03-13","objectID":"/posts/d8fd4/:1:0","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"使用 ","date":"2018-03-13","objectID":"/posts/d8fd4/:2:0","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"从输入框复制 现在页面上有一个 \u003cinput\u003e 标签，我们需要复制其中的内容，我们可以这样做： \u003cinput id=\"demoInput\" value=\"hello world\"\u003e \u003cbutton class=\"btn\" data-clipboard-target=\"#demoInput\"\u003e点我复制\u003c/button\u003e import Clipboard from 'clipboard'; const btnCopy = new Clipboard('btn'); 注意到，在 \u003cbutton\u003e 标签中添加了一个 data-clipboard-target 属性，它的值是需要复制的 \u003cinput\u003e的 id，顾名思义是从整个标签中复制内容。 ","date":"2018-03-13","objectID":"/posts/d8fd4/:2:1","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"直接复制 有的时候，我们并不希望从 \u003cinput\u003e 中复制内容，仅仅是直接从变量中取值。如果在 Vue 中我们可以这样做： \u003cbutton class=\"btn\" :data-clipboard-text=\"copyValue\"\u003e点我复制\u003c/button\u003e import Clipboard from 'clipboard'; const btnCopy = new Clipboard('btn'); this.copyValue = 'hello world'; ","date":"2018-03-13","objectID":"/posts/d8fd4/:2:2","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"事件 有的时候我们需要在复制后做一些事情，这时候就需要回调函数的支持。 在处理函数中加入以下代码： // 复制成功后执行的回调函数 clipboard.on('success', function(e) { console.info('Action:', e.action); // 动作名称，比如：Action: copy console.info('Text:', e.text); // 内容，比如：Text：hello word console.info('Trigger:', e.trigger); // 触发元素：比如：\u003cbutton class=\"btn\" :data-clipboard-text=\"copyValue\"\u003e点我复制\u003c/button\u003e e.clearSelection(); // 清除选中内容 }); // 复制失败后执行的回调函数 clipboard.on('error', function(e) { console.error('Action:', e.action); console.error('Trigger:', e.trigger); }); ","date":"2018-03-13","objectID":"/posts/d8fd4/:2:3","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"小结 文档中还提到，如果在单页面中使用 clipboard，为了使得生命周期管理更加的优雅，在使用完之后记得 btn.destroy() 销毁一下。 clipboard 使用起来是不是很简单。但是，就为了一个 copy 功能就使用额外的第三方库是不是不够优雅，这时候该怎么办？那就用原生方法实现呗。 document.execCommand()方法 先看看这个方法在 MDN 上是怎么定义的： which allows one to run commands to manipulate the contents of the editable region. 意思就是可以允许运行命令来操作可编辑区域的内容，注意，是可编辑区域。 ","date":"2018-03-13","objectID":"/posts/d8fd4/:3:0","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"定义 bool = document.execCommand(aCommandName, aShowDefaultUI, aValueArgument) 方法返回一个 Boolean 值，表示操作是否成功。 aCommandName ：表示命令名称，比如： copy, cut 等（更多命令见命令）； aShowDefaultUI：是否展示用户界面，一般情况下都是 false； aValueArgument：有些命令需要额外的参数，一般用不到； ","date":"2018-03-13","objectID":"/posts/d8fd4/:4:0","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"兼容性 这个方法在之前的兼容性其实是不太好的，但是好在现在已经基本兼容所有主流浏览器了，在移动端也可以使用。 ","date":"2018-03-13","objectID":"/posts/d8fd4/:5:0","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"使用 ","date":"2018-03-13","objectID":"/posts/d8fd4/:6:0","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"从输入框复制 现在页面上有一个 \u003cinput\u003e 标签，我们想要复制其中的内容，我们可以这样做： \u003cinput id=\"demoInput\" value=\"hello world\"\u003e \u003cbutton id=\"btn\"\u003e点我复制\u003c/button\u003e const btn = document.querySelector('#btn'); btn.addEventListener('click', () =\u003e { const input = document.querySelector('#demoInput'); input.select(); if (document.execCommand('copy')) { document.execCommand('copy'); console.log('复制成功'); } }) ","date":"2018-03-13","objectID":"/posts/d8fd4/:6:1","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"其它地方复制 有的时候页面上并没有 \u003cinput\u003e 标签，我们可能需要从一个 \u003cdiv\u003e 中复制内容，或者直接复制变量。 还记得在 execCommand() 方法的定义中提到，它只能操作可编辑区域，也就是意味着除了 \u003cinput\u003e、\u003ctextarea\u003e 这样的输入域以外，是无法使用这个方法的。 这时候我们需要曲线救国。 \u003cbutton id=\"btn\"\u003e点我复制\u003c/button\u003e const btn = document.querySelector('#btn'); btn.addEventListener('click',() =\u003e { const input = document.createElement('input'); document.body.appendChild(input); input.setAttribute('value', '听说你想复制我'); input.select(); if (document.execCommand('copy')) { document.execCommand('copy'); console.log('复制成功'); } document.body.removeChild(input); }) 算是曲线救国成功了吧。在使用这个方法时，遇到了几个坑。 ","date":"2018-03-13","objectID":"/posts/d8fd4/:6:2","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Web 开发"],"content":"遇到的坑 在Chrome下调试的时候，这个方法时完美运行的。然后到了移动端调试的时候，坑就出来了。 对，没错，就是你，ios。。。 点击复制时屏幕下方会出现白屏抖动，仔细看是拉起键盘又瞬间收起 知道了抖动是由于什么产生的就比较好解决了。既然是拉起键盘，那就是聚焦到了输入域，那只要让输入域不可输入就好了，在代码中添加 input.setAttribute('readonly', 'readonly'); 使这个 \u003cinput\u003e 是只读的，就不会拉起键盘了。 无法复制 这个问题是由于 input.select() 在ios下并没有选中全部内容，我们需要使用另一个方法来选中内容，这个方法就是 input.setSelectionRange(0, input.value.length);。 完整代码如下： const btn = document.querySelector('#btn'); btn.addEventListener('click',() =\u003e { const input = document.createElement('input'); input.setAttribute('readonly', 'readonly'); input.setAttribute('value', 'hello world'); document.body.appendChild(input); input.setSelectionRange(0, 9999); if (document.execCommand('copy')) { document.execCommand('copy'); console.log('复制成功'); } document.body.removeChild(input); }) 参考链接 以上就是关于JavaScript如何实现复制内容到剪贴板，附上几个链接： Document.execCommand() - Web APIs | MDN Can I use execcommand GitHub - zenorocha/clipboard.js 著作权声明 原作者：axuebin@github 来源：https://github.com/axuebin/articles/issues/26 ","date":"2018-03-13","objectID":"/posts/d8fd4/:6:3","tags":[],"title":"JavaScript复制内容到剪贴板","uri":"/posts/d8fd4/"},{"categories":["Infrastructure"],"content":"logrotate旨在简化对生成大量日志文件的系统的管理。它允许自动转储，压缩，删除和发送日志文件。每个日志文件可以在每天、每周、每月或日志文件达到一定大小时处理。 安装 主流Linux发行版上都默认安装了logrotate。如果没有，可以使用下面的命令安装： Debian/Ubuntu： apt install logrotate cron Fedora/CentOS/RHEL： yum install logrotate crontabs 配置 ","date":"2018-02-16","objectID":"/posts/a7779/:0:0","tags":[],"title":"logrotate日志轮转","uri":"/posts/a7779/"},{"categories":["Infrastructure"],"content":"配置文件路径 /etc/logrotate.conf，为全局配置，通常不需要要修改； 在/etc/logrotate.d/目录下，为各应用的具体配置，通常以应用程序名称来命名文件。 ","date":"2018-02-16","objectID":"/posts/a7779/:1:0","tags":[],"title":"logrotate日志轮转","uri":"/posts/a7779/"},{"categories":["Infrastructure"],"content":"配置参数 以12306轮询的配置为例（/etc/logrotate.d/12306）： /home/chi/12306/query.log { daily rotate 20 dateext copytruncate missingok notifempty create 644 chi chi } daily：日志切割的执行周期。可以为\"daily”、“weekly”、“monthly\"或者\"yearly”。 rotate 20：最多保留20个日志备份。第21个日志备份文件生成时，最早的日志备份将被删除。 dateext：日志文件切割时文件名后缀添加日期，形如query.log-20180210，日期格式可在/etc/logrotate.conf中配置。不加该参数时，默认添加阿拉伯数字后缀。 copytruncate：使用该参数后，拷贝原日志文件作为备份，并且将原文件清空。优点是兼容性好，缺点是拷贝和清空之间的时间差会丢数据。如果没有配置该选项，默认的方式是，把旧日志文件改名为备份文件名 ，然后创建新日志文件，并告知应用程序使用新的描述符。 missingok：在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误。 notifempty：如果日志文件为空的话，不转储。 create 644 chi chi：使用指定的文件模式创建新日志文件。 运行 Logrotate是基于CRON来运行的，其脚本是/etc/cron.daily/logrotate，日志轮转是系统自动完成的。 题外话，不同cron任务的执行时间分别为： /etc/cron.daily/ 下面的任务都是每天6:25 执行； /etc/cron.weekly/ 下面的任务都是每周日 6:47 执行； /etc/cron.monthly/ 下面的任务都是每月1号 6:52 执行； 因此默认情况下，日志转储都在早上6:25执行。 ","date":"2018-02-16","objectID":"/posts/a7779/:2:0","tags":[],"title":"logrotate日志轮转","uri":"/posts/a7779/"},{"categories":["Infrastructure"],"content":"自动运行 无需任何设置。logrotate每天会执行一次，检查是否需要做日志转储。 ","date":"2018-02-16","objectID":"/posts/a7779/:3:0","tags":[],"title":"logrotate日志轮转","uri":"/posts/a7779/"},{"categories":["Infrastructure"],"content":"手动运行 如果想自定义运行时间，那么可以将logrotate加入到cron定时任务中去。由于logrotate每天至多执行一次的原则，我们自己加入到cron中的定时任务执行后，自动运行的任务就不会执行了。 当然这要求我们自己任务的执行时间在6:25之前，否则需要删除/etc/cron.daily/logrotate阻止其自动运行才可以。 ⚠️：定义的任务必须是root用户的定时任务，格式为： /usr/sbin/logrotate /etc/logrotate.d/web_roteate -fv Reference Linux 日志定时轮询流程详解； Linux日志文件总管——logrotate； logrotate 使用方法； ","date":"2018-02-16","objectID":"/posts/a7779/:4:0","tags":[],"title":"logrotate日志轮转","uri":"/posts/a7779/"},{"categories":["Infrastructure"],"content":"在对大量数据进行分页查询时，我们经常使用LIMIT B OFFSET A的语法： SELECT * FROM t1 LIMIT B OFFSET A; 但是，LIMIT B OFFSET A语法的原理是，先取出 (A+B) 条数据，然后将前 A 条数据丢弃，返回剩下的 B 条数据。在处理大量数据时，随着OFFSET值的增大，取出的数据量也越来越多，造成查询速度变慢。 一种处理方式是，使用WHERE筛选替代OFFSET。 SELECT * FROM t1 WHERE id \u003e C LIMIT B; 优点是：每次查询的数据量都为B，速度不会变慢； 缺点是：需要知道上个分页最后一条数据的ID，即C。因此只适合连续的分页查询数据。 ","date":"2018-02-09","objectID":"/posts/91ce2/:0:0","tags":[],"title":"加快分页查询大量数据速度的一种方法","uri":"/posts/91ce2/"},{"categories":["工欲善其事"],"content":"翻墙 下载 ShadowsocksX-NG 客户端，配置好服务器。打开 https://google.com/ 测试代理生效。 在执行以下安装命令时，如果新开的shell，先为shell设置代理： export http_proxy=http://127.0.0.1:1087;export https_proxy=http://127.0.0.1:1087; Xcode Command Line Tools 打开终端，执行 xcode-select --install Homebrew ","date":"2018-02-05","objectID":"/posts/19945/:0:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"安装 Homebrew 打开终端，执行 /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 更新： brew update brew upgrade brew install mas ","date":"2018-02-05","objectID":"/posts/19945/:1:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"brew bundle 通过 brew bundle dump 可以在当前目录导出一个 Brewfile 文件，包含了 tap、brew、cask 和 mas 等内容。 将下面的内容写入到 Brewfile 文件中，并执行 brew bundle 命令导入。 tap \"homebrew/bundle\" tap \"homebrew/cask\" tap \"homebrew/cask-drivers\" tap \"homebrew/cask-fonts\" tap \"homebrew/cask-versions\" tap \"homebrew/core\" tap \"homebrew/services\" brew \"autojump\" brew \"openssl\" brew \"sqlite\" brew \"python\" brew \"flake8\" brew \"git\" brew \"go\" brew \"htop\" brew \"httpie\" brew \"ipython\" brew \"mas\" brew \"mongodb\", restart_service: true brew \"nginx\" brew \"nmap\" brew \"pipenv\" brew \"postgresql\" brew \"pyenv\" brew \"redis\", restart_service: true brew \"siege\" brew \"swig\" brew \"tree\" brew \"you-get\" brew \"zsh\" cask \"android-file-transfer\" cask \"android-platform-tools\" cask \"charles\" cask \"cheatsheet\" cask \"chromedriver\" cask \"docker\" cask \"etcher\" cask \"fliqlo\" cask \"folx\" cask \"font-fira-code\" cask \"font-mononoki\" cask \"font-source-code-pro\" cask \"github\" cask \"google-chrome\" cask \"gqrx\" cask \"iina\" cask \"iterm2\" cask \"laplock\" cask \"logitech-options\" cask \"microsoft-remote-desktop-beta\" cask \"monitorcontrol\" cask \"ngrok\" cask \"omnigraffle\" cask \"postman\" cask \"robo-3t\" cask \"sequel-pro\" cask \"skype\" cask \"tunnelblick\" cask \"typora\" cask \"virtualbox\" cask \"visual-studio-code\" cask \"wechatwebdevtools\" cask \"wireshark\" cask \"yyets\" mas \"QQ\", id: 451108668 mas \"QQ音乐\", id: 595615424 mas \"Reeder\", id: 880001334 mas \"The Unarchiver\", id: 425424353 mas \"Xcode\", id: 497799835 mas \"微信\", id: 836500024 mas \"截图\", id: 1059334054 mas \"熊掌记\", id: 1091189122 mas \"网易云音乐\", id: 944848654 mas \"钉钉\", id: 1435447041 oh-my-zsh ","date":"2018-02-05","objectID":"/posts/19945/:2:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"安装 oh-my-zsh sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" ","date":"2018-02-05","objectID":"/posts/19945/:3:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"配置 oh-my-zsh 编辑~/.zshrc文件： # 以下是修改已经存在的配置 ZSH_THEME=\"agnoster\" plugins=(git osx autojump sublime docker) export LANG=en_US.UTF-8 export LC_ALL=en_US.UTF-8 # 新增配置 DEFAULT_USER=\"yourusername\" export LANG=en_US.UTF-8 export LC_ALL=en_US.UTF-8 mas mas 用来管理 Mac App Store Applications。 ","date":"2018-02-05","objectID":"/posts/19945/:4:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"安装 mas brew install mas ","date":"2018-02-05","objectID":"/posts/19945/:5:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"常用操作 常用操作与brew基本一致。 mas search \u003ckeyword\u003e mas install \u003cID1\u003e \u003cID2\u003e mas upgrade \u003cID1\u003e \u003cID2\u003e mas outdated ","date":"2018-02-05","objectID":"/posts/19945/:6:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"常用 App 836500024 WeChat (2.3.10) 497799835 Xcode (9.2) 409183694 Keynote (7.3.1) 451108668 QQ (6.3.1) 944848654 NeteaseMusic (1.5.9) 截图 Bear Reeder 配置 ","date":"2018-02-05","objectID":"/posts/19945/:7:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":".zshrc # brew export PATH=/usr/local/sbin:$HOME/bin:$PATH # proxy alias pip=\"pip3 --proxy 127.0.0.1:1087\" alias ss=\"export http_proxy=http://127.0.0.1:1087;export https_proxy=http://127.0.0.1:1087;\" alias unss=\"unset http_proxy;unset https_proxy;\" # quick open alias md=\"open -a Typora\" alias idle=\"idle3 -c 'from pprint import pprint;import datetime,time,os,sys,json,collections,math;'\" # pipenv alias v=\"pipenv shell\" export PIPENV_VENV_IN_PROJECT=true # ssh alias alias pi=\"ssh pi@192.168.2.211 -p 3154\" ","date":"2018-02-05","objectID":"/posts/19945/:8:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"vim 下载 solarized 主题配色 mkdir -p ~/.vim/colors cd ~/.vim/colors curl -O https://raw.githubusercontent.com/altercation/vim-colors-solarized/master/colors/solarized.vim vi ~/.vimrc syntax on set background=dark colorscheme solarized set number ","date":"2018-02-05","objectID":"/posts/19945/:9:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":".gitconfig [user] name = foo email = name@email.com [core] quotepath = false quotepath = false 可以使 shell 中的 git 能够显示中文路径和文件名。 ","date":"2018-02-05","objectID":"/posts/19945/:10:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"Typora 主题：Solarized ","date":"2018-02-05","objectID":"/posts/19945/:11:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"iTerm2 non-ASCII字体选用 mononoki，Horizontal 90%，Vertical 110%； Preferences - Profiles - Colors - Color Presets，修改配色主题为 Solarized Dark； Preferences - Keys - Hotkey - Hotkey toggles a dedicated window with profile 勾选； Preferences - Profiles - Text - Text Rendering - Draw bold text in bright colors 取消勾选； ","date":"2018-02-05","objectID":"/posts/19945/:12:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"Sublime ","date":"2018-02-05","objectID":"/posts/19945/:13:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"插件 Package Control AdvancedNewFile GitGutter Theme - One Dark nginx HTML-CSS-JS Prettify ","date":"2018-02-05","objectID":"/posts/19945/:13:1","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"配置 { \"bold_folder_labels\": true, \"color_scheme\": \"Packages/Theme - One Dark/One Dark.tmTheme\", \"debounce_delay\": 10, \"default_line_ending\": \"unix\", \"detect_indentation\": false, \"draw_minimap_border\": true, \"ensure_newline_at_eof_on_save\": true, \"fade_fold_buttons\": false, \"file_exclude_patterns\": [ \"*.pyc\", \"*.pyo\", \"*.exe\", \"*.dll\", \"*.obj\", \"*.o\", \"*.a\", \"*.lib\", \"*.so\", \"*.dylib\", \"*.ncb\", \"*.sdf\", \"*.suo\", \"*.pdb\", \"*.idb\", \".DS_Store\", \"*.class\", \"*.psd\", \"*.db\", \"*.sublime-workspace\", \".DS_Store\" ], \"folder_exclude_patterns\": [ \".svn\", \".git\", \".hg\", \"CVS\", \"venv\", \".venv\", \".idea\", \"__pycache__\", \".pytest_cache\" ], \"font_face\": \"Source Code Pro\", \"font_size\": 16, \"highlight_line\": true, \"hot_exit\": true, \"ignored_packages\": [ \"Vintage\" ], \"line_padding_bottom\": 1, \"line_padding_top\": 2, \"rulers\": [ 80, 100, 120 ], \"save_on_focus_lost\": true, \"scroll_past_end\": true, \"show_encoding\": true, \"theme\": \"One Dark.sublime-theme\", \"translate_tabs_to_spaces\": true, \"trim_trailing_white_space_on_save\": true, \"word_wrap\": true } ","date":"2018-02-05","objectID":"/posts/19945/:13:2","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"Python Snippets snippets存储路径为 ~/Library/Application Support/Sublime Text 3/Packages/User； snippets扩展名为 .sublime-snippet。 cd ~/Library/Application Support/Sublime Text 3/Packages/User vi coding.sublime-snippet \u003csnippet\u003e \u003ccontent\u003e\u003c![CDATA[ # coding=utf-8 ]]\u003e\u003c/content\u003e \u003c!-- Optional: Set a tabTrigger to define how to trigger the snippet --\u003e \u003ctabTrigger\u003eenc\u003c/tabTrigger\u003e \u003c!-- Optional: Set a scope to limit where the snippet will trigger --\u003e \u003cscope\u003esource.python\u003c/scope\u003e \u003c/snippet\u003e vi shebang.sublime-snippet \u003csnippet\u003e \u003ccontent\u003e\u003c![CDATA[ #!/usr/bin/env python3 ]]\u003e\u003c/content\u003e \u003c!-- Optional: Set a tabTrigger to define how to trigger the snippet --\u003e \u003ctabTrigger\u003eenv\u003c/tabTrigger\u003e \u003c!-- Optional: Set a scope to limit where the snippet will trigger --\u003e \u003cscope\u003esource.python\u003c/scope\u003e \u003c/snippet\u003e ","date":"2018-02-05","objectID":"/posts/19945/:13:3","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"VSCode 扩展列表，通过 code --list-extensions 导出。 CoenraadS.bracket-pair-colorizer eamodio.gitlens hangxingliu.vscode-nginx-conf-hint mikestead.dotenv ms-azuretools.vscode-docker ms-python.python ms-vscode.Go PKief.material-icon-theme zhuangtongfa.Material-theme 通过 code install-extension 扩展 来安装。 FAQ ","date":"2018-02-05","objectID":"/posts/19945/:14:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"卸载oh-my-zsh uninstall_oh_my_zsh ","date":"2018-02-05","objectID":"/posts/19945/:15:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"Ubuntu上安装oh-my-zsh依赖 sudo apt update sudo apt upgrade sudo apt install zsh sudo apt install git sudo apt install autojump ","date":"2018-02-05","objectID":"/posts/19945/:16:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"Ubuntu启用agnoster主题报错 报错：character not in range 原因：Ubuntu主机没有正确设置locale，至少应包含一项UTF-8的locale。 解决： 检查locale，locale和locale -a命令； 重新生成locale，在/etc/locale.gen中取消注释，然后执行locale-gen命令； ","date":"2018-02-05","objectID":"/posts/19945/:17:0","tags":[],"title":"Mac开发环境搭建","uri":"/posts/19945/"},{"categories":["工欲善其事"],"content":"Jupyter Notebook是一个开源的Web应用程序，允许您创建和共享包含实时代码，方程式，可视化和叙述文本的文档。用途包括：数据清理和转换，数值模拟，统计建模，数据可视化，机器学习等等。 安装Anaconda Anaconda 是一种Python语言的免费增值开源发行版，用于进行大规模数据处理, 预测分析, 和科学计算, 致力于简化包的管理和部署。Anaconda使用软件包管理系统Conda进行包管理。 到Anaconda官网获取对应操作系统安装脚本的下载链接。 wget https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh chmod u+x Anaconda3-5.0.1-Linux-x86_64.sh ./Anaconda3-5.0.1-Linux-x86_64.sh 根据提示完成安装。使用bash可以在安装过程中选择把环境变量加入到.bashrc文件中；使用zsh的话，需要将环境变量手动加到.zshrc文件中。 export PATH=/home/chi/anaconda3/bin:$PATH 更新： conda update --prefix /home/chi/anaconda3 anaconda conda update --all 安装Jupyter 安装好anaconda后，默认情况下jupyter已经安装在主机上。检查是否安装： jupyter --version 如果未安装，可使用下面的安装命令安装： conda install jupyter 配置Jupyter ","date":"2017-12-21","objectID":"/posts/c29fb/:0:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"生成配置文件 jupyter notebook --generate-config 会生成配置文件~/.jupyter/jupyter_notebook_config.py，文件中所有的配置项都是注释掉的状态。 ","date":"2017-12-21","objectID":"/posts/c29fb/:1:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"生成密码hash 如果Jupyter服务暴露在公网上，最好为其设置密码。Jupyter的访问密码用sha1加密后存储在配置文件中。 使用下面的命令在IPython中生成密码，是类似'sha1:XXXXXXX'的字符串。 from notebook.auth import passwd passwd() ","date":"2017-12-21","objectID":"/posts/c29fb/:2:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"添加配置项 编辑~/.jupyter/jupyter_notebook_config.py文件，在末尾添加： # c.NotebookApp.certfile = '/home/ipynb/cert.pem' # 证书文件，使用Nginx时不要在这里配置 # c.NotebookApp.keyfile = '/home/ipynb/privkey.pem' # 私钥文件，使用Nginx时不要在这里配置 c.NotebookApp.ip = 'localhost' # 监听IP，使用Nginx做反向代理只需监听localhost c.NotebookApp.port = 8888 # 监听端口 c.NotebookApp.open_browser = False # 启动Jupyter时是否自动打开浏览器 c.NotebookApp.notebook_dir = '/home/chi/notes' # 笔记根目录地址，不要设置成用户的家目录 c.NotebookApp.password = \"sha1:foo:bar\" # 访问密码的hash 使用Nginx作反向代理 使用Nginx作为反向代理不是必须的，配置HTTPS访问也不是必须的。建议在公网上部署时使用Nginx并启用HTTPS。 ","date":"2017-12-21","objectID":"/posts/c29fb/:3:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"安装Nginx sudo apt update sudo apt install nginx ","date":"2017-12-21","objectID":"/posts/c29fb/:4:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"配置Nginx 在目录 /etc/nginx/sites-enabled 增加 jupyter.conf 配置文件（需要 root 权限）： server { listen 80; server_name jupyter.mrchi.cc; proxy_buffers 64 4k; access_log /var/log/nginx/jupyter_access.log; error_log /var/log/nginx/jupyter_error.log; location / { proxy_pass http://localhost:8888; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location ~ /api/kernels/ { proxy_pass http://localhost:8888; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade \"websocket\"; proxy_set_header Connection \"Upgrade\"; proxy_read_timeout 86400; } location ~ /terminals/ { proxy_pass http://localhost:8888; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade \"websocket\"; proxy_set_header Connection \"Upgrade\"; proxy_read_timeout 86400; } } 测试配置： sudo nginx -t 重新加载配置： sudo nginx -s reload ","date":"2017-12-21","objectID":"/posts/c29fb/:5:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"生成HTTPS证书 Certbot可以在您的网站上自动部署Let’s Encrypt的HTTPS证书。 安装certbot，以在Ubuntu16.04(Xenial)系统上使用Nginx为例。官网可查看更多安装方式。 sudo apt-get update sudo apt-get install software-properties-common sudo add-apt-repository ppa:certbot/certbot sudo apt-get update sudo apt-get install python-certbot-nginx 生成证书 sudo certbot --nginx certonly 证书有效期为90天，如果要更新证书，只要执行 sudo certbot renew ","date":"2017-12-21","objectID":"/posts/c29fb/:6:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"配置HTTPS 修改nginx配置文件/etc/nginx/nginx.conf，主要改动： 添加HTTPS 443访问； 301重定向HTTP访问到HTTPS； 启用HSTS； ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; include /etc/letsencrypt/options-ssl-nginx.conf; add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always; server { listen 443 ssl; server_name jupyter.mrchi.cc; proxy_buffers 64 4k; access_log /var/log/nginx/jupyter_access.log; error_log /var/log/nginx/jupyter_error.log; ssl_certificate /etc/letsencrypt/live/jupyter.mrchi.cc/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/jupyter.mrchi.cc/privkey.pem; location / { proxy_pass http://localhost:8888; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location ~ /api/kernels/ { proxy_pass http://localhost:8888; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade \"websocket\"; proxy_set_header Connection \"Upgrade\"; proxy_read_timeout 86400; } location ~ /terminals/ { proxy_pass http://localhost:8888; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade \"websocket\"; proxy_set_header Connection \"Upgrade\"; proxy_read_timeout 86400; } } server { listen 80; server_name jupyter.mrchi.cc; return 301 https://$server_name$request_uri; } 测试配置： sudo nginx -t 重新加载配置： sudo nginx -s reload ","date":"2017-12-21","objectID":"/posts/c29fb/:7:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"设置default路由 修改/etc/nginx/sites-available/default文件，设置default路由返回444，让Nginx直接断开连接。 default路由应同时设置80和443端口 如果listen了443端口，需要在server块中指定证书，任意证书包括自签名证书都可以。这里使用了之前生成的Let’s Encrypt证书。 server { listen 80 default_server; listen [::]:80 default_server; listen 443 ssl default_server; listen [::]:443 ssl default_server; server_name _; ssl_certificate /etc/letsencrypt/live/jupyter.mrchi.cc/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/jupyter.mrchi.cc/privkey.pem; return 444; } 使用supervisor管理Jupyter进程 Jupyter命令没有提供以服务后台运行的方式，推荐使用supervisor管理主进程。 ","date":"2017-12-21","objectID":"/posts/c29fb/:8:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"安装supervisor supervisor可以通过pip安装，也可以使用apt安装。 sudo apt update sudo apt install supervisor ","date":"2017-12-21","objectID":"/posts/c29fb/:9:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"supervisord配置 一般情况下，使用默认配置就可以了。但为了能够支持中文，需要在/etc/supervisor/supervisord.conf配置文件的[supervisord]配置块下增加以下配置： environment=LANG=en_US.UTF-8,LC_ALL=en_US.UTF-8,LC_LANG=en_US.UTF-8 ","date":"2017-12-21","objectID":"/posts/c29fb/:10:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"Jupyter程序配置 在/etc/supervisor/conf.d/目录下新建配置文件jupyter.conf。 [program:jupyter] environment=SHELL=/usr/bin/zsh command=/home/chi/anaconda3/bin/jupyter notebook autostart=true autorestart=true startsecs=5 startretries=3 stopasgroup=true killasgroup=true user=chi redirect_stderr=true stdout_logfile=/home/chi/logs/jupyter.log ","date":"2017-12-21","objectID":"/posts/c29fb/:11:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"加载配置 sudo supervisorctl reread sudo supervisorctl update sudo supervisorctl status 为Jupyter安装kernel Jupyter默认只有IPython kernel，你可以安装其他kernel以支持不同的语言，如R语言、Julia和JavaScript等等。 这里有一份可安装的 kernel 列表。详细的安装方法见不同kernel的repo文档。 ","date":"2017-12-21","objectID":"/posts/c29fb/:12:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"安装ijavascript内核 sudo add-apt-repository ppa:chronitis/jupyter sudo apt-get update sudo apt-get install ijavascript 为Jupyter安装扩展 安装Jupyter Notebook extensions： conda install -c conda-forge jupyter_contrib_nbextensions 安装完成后启动Jupyter，会有一个在Nbextensions的tab，其中可以对插件进行管理。 ","date":"2017-12-21","objectID":"/posts/c29fb/:13:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"开启toc2插件 toc2插件可以为Jupyter笔记生成侧边栏目录，也可将目录插入到笔记开头。它还可以自动为标题编号。 使用技巧 装扮你的 Jupyter Notebook [译]27 个Jupyter Notebook的小提示与技巧 参考链接 搭建 ipython/jupyter notebook 服务器 ijavascript 为Jupyter Notebook添加目录 Nginx 反向代理配置和工作原理 jupyter notebook服务端安装——基于Python3、nginx docker 安装 jupyter 并用 nginx 进行反向代理 HTTP Strict Transport Security (HSTS) and NGINX 使用 supervisor 管理进程 ","date":"2017-12-21","objectID":"/posts/c29fb/:14:0","tags":[],"title":"在Ubuntu上部署Jupyter","uri":"/posts/c29fb/"},{"categories":["工欲善其事"],"content":"添加用户组和用户 切换到root用户 添加用户组： groupadd shadowsocks -g 1000 添加用户并修改密码： useradd -m -g 1000 -G 100 -s /bin/bash ss passwd ss 安装加速组件 在OpenVZ架构VPS上安装LKL加速，参考OpenVZ使用BBR新姿势：LKL一键安装包（比UML简单）-5月9日更新； 在KVM架构VPS上，4.9.x以上的Linux内核自带BBR，如果低于4.9.x则需要先升级内核版本，参考Debian / Ubuntu 更新内核并开启 TCP BBR 拥塞控制算法。 OpenVZ架构VPS——安装LKL LKL全称是Linux Kernel Library。 LKL (Linux Kernel Library) is aiming to allow reusing the Linux kernel code as extensively as possible with minimal effort and reduced maintenance overhead. ","date":"2017-11-25","objectID":"/posts/ce467/:0:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"系统需求 只适用于OpenVZ架构 64bit 系统； 默认只转发9000-9999端口（即SS端口应设置在这个范围内）； 推荐系统CentOS 7, Debian 8和Ubuntu 16； ","date":"2017-11-25","objectID":"/posts/ce467/:1:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"安装 切换到root用户 首先安装git apt-get update apt-get upgrade apt-get install git 一键安装命令： wget https://github.com/91yun/uml/raw/master/lkl/install.sh \u0026\u0026 bash install.sh ","date":"2017-11-25","objectID":"/posts/ce467/:2:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"判断安装成功 执行ping 10.0.0.2，如果能ping通则成功，否则失败。 ","date":"2017-11-25","objectID":"/posts/ce467/:3:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"修改转发端口 修改/root/lkl/run.sh，查找9000-9999，改成想要的端口段； 修改/root/lkl/haproxy.cfg，查找9000-9999，改成想要的端口段； 重启vps。 KVM架构VPS——更新内核并开启BBR ","date":"2017-11-25","objectID":"/posts/ce467/:4:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"系统需求 Debian 8.x 或者 Debian 9.x 系统， Ubuntu 14.04 或 Ubuntu 16.04； 如果不是新机器，建议先备份，升级内核有风险； ","date":"2017-11-25","objectID":"/posts/ce467/:5:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"升级内核 从Ubuntu网站上下载新内核安装包，目前4.9.x内核最新的版本为4.9.65。 mkdir kernel-tmp \u0026\u0026 cd kernel-tmp wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.9.65/linux-headers-4.9.65-040965_4.9.65-040965.201711240331_all.deb wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.9.65/linux-headers-4.9.65-040965-generic_4.9.65-040965.201711240331_amd64.deb wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.9.65/linux-image-4.9.65-040965-generic_4.9.65-040965.201711240331_amd64.deb sudo dpkg -i *.deb 安装完成后重启，重启后检查内核版本： root@s1 ~ # uname -r 4.9.65-040965-generic ","date":"2017-11-25","objectID":"/posts/ce467/:6:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"配置生效 使用root用户 修改 /etc/sysctl.conf文件 cat \u003e\u003e /etc/sysctl.conf \u003c\u003c EOF net.core.default_qdisc=fq net.ipv4.tcp_congestion_control=bbr EOF 使内核配置生效 root@s1 ~ # sysctl -p net.core.default_qdisc = fq net.ipv4.tcp_congestion_control = bbr 检查 BBR 是否已正确开启，如果出现 tcp_bbr 字样则说明没有问题。 root@s1:~# lsmod | grep bbr tcp_bbr 20480 0 安装并配置ShadowSocks ","date":"2017-11-25","objectID":"/posts/ce467/:7:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"安装 切换到ss用户 安装miniconda（可选） wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \u0026\u0026 bash Miniconda3-latest-Linux-x86_64.sh 安装ShadowSocks pip install shadowsocks ","date":"2017-11-25","objectID":"/posts/ce467/:8:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"配置 mkdir shadowsocks \u0026\u0026 cd shadowsocks/ touch ssconfig.json touch ss.pid vi ssconfig.json 配置文件ssconfig.json内容： { \"server\":\"0.0.0.0\", \"port_password\":{ \"port1\":\"password1\", \"port2\":\"password2\", \"port3\":\"password3\" }, \"timeout\":600, \"method\":\"aes-256-cfb\" } 启动和停止ShadowSocks ","date":"2017-11-25","objectID":"/posts/ce467/:9:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"普通方式 设置alias： alias startss=\"cd ~/shadowsocks;ssserver -c ssconfig.json --pid-file ss.pid --log-file ss.log -d start\" alias stopss=\"cd ~/shadowsocks;ssserver -c ssconfig.json --pid-file ss.pid --log-file ss.log -d stop\" -c指定配置文件，—pid-file指定进程pid储存文件，--log-file指定日志文件，-d以服务启动。 切换到ss用户 startss stopss ","date":"2017-11-25","objectID":"/posts/ce467/:10:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["工欲善其事"],"content":"使用Supervisor supervisor配置如下，运行时-q选项使程序只记录错误日志 [program:shadowsocks] directory = /home/ss/shadowsocks command = /home/ss/miniconda3/bin/ssserver -c ssconfig.json -q autostart = true autorestart = true startsecs = 3 startretries = 3 user = ss redirect_stderr = true stdout_logfile = /home/ss/shadowsocks/error.log 更新supervisor并启动： sudo supervisorctl reread sudo supervisorctl update sudo supervisorctl status ","date":"2017-11-25","objectID":"/posts/ce467/:11:0","tags":[],"title":"在VPS上搭建ShadowSocks服务","uri":"/posts/ce467/"},{"categories":["Python"],"content":"前期准备 ","date":"2017-10-30","objectID":"/posts/ea7c7/:0:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"硬件软件安装 硬件： 芯烨(Xprinter) XP-58IIQ USB接口热敏打印机，兼容ESC/POS打印协议； 软件： python-escpos==3.0a3，是一个alpha测试版本，接口在将来可能会变动。 pip install python-escpos 如果在树莓派上使用，需要先安装 libjpeg8-dev 包 sudo apt-get install libjpeg8-dev ","date":"2017-10-30","objectID":"/posts/ea7c7/:1:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"访问权限设置 插上USB打印机，执行dmesg命令，会有新USB设备连接的信息，成功的被识别为了打印机usblp0。 # dmesg [100271.364954] usb 1-1.4: new full-speed USB device number 6 using dwc_otg [100271.498310] usb 1-1.4: New USB device found, idVendor=0483, idProduct=070b [100271.498327] usb 1-1.4: New USB device strings: Mfr=1, Product=2, SerialNumber=3 [100271.498338] usb 1-1.4: Product: USB Printing Support [100271.498348] usb 1-1.4: Manufacturer: Printer-58 [100271.498377] usb 1-1.4: SerialNumber: ÿ [100271.509441] usblp 1-1.4:1.0: usblp0: USB Bidirectional printer dev 6 if 0 alt 0 proto 2 vid 0x0483 pid 0x070B 执行ls /dev/usb，可以看到有一个lp0打印机设备 # ls /dev/usb lp0 查看打印机设备权限，为660。拥有者是root，拥有组是lp，当前用户pi无法访问打印机 # stat /dev/usb/lp0 File: /dev/usb/lp0 Size: 0 Blocks: 0 IO Block: 4096 character special file Device: 6h/6d Inode: 48155 Links: 1 Device type: b4,0 Access: (0660/crw-rw----) Uid: ( 0/ root) Gid: ( 7/ lp) Access: 2017-10-30 20:47:05.762879696 +0800 Modify: 2017-10-30 20:47:05.762879696 +0800 Change: 2017-10-30 20:47:05.762879696 +0800 Birth: - 把当前用户加入到lp组，使其能够访问打印机 sudo usermod -a -G lp pi 测试，如果正常打印，则权限已设置好 echo \"hello\" \u003e\u003e /dev/usb/lp0 定义打印机实例 所有的打印机类都定义于escpos.printer文件中。 ","date":"2017-10-30","objectID":"/posts/ea7c7/:2:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"USB打印机 class escpos.printer.Usb(idVendor, idProduct, timeout=0, in_ep=130, out_ep=1, *args, **kwargs) 在创建打印机实例之前，你需要获取一些打印机的参数。 使用lsusb命令，在输出中得到VendorID和Product ID，它们的格式是xxxx:xxxx，位置在设备名之前。 # lsusb Bus 001 Device 004: ID 148f:5370 Ralink Technology, Corp. RT5370 Wireless Adapter Bus 001 Device 006: ID 0483:070b STMicroelectronics Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. SMSC9512/9514 Fast Ethernet Adapter Bus 001 Device 002: ID 0424:9514 Standard Microsystems Corp. SMC9514 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub 根据Vendor ID和Product ID，可以得到“EndPoint”地址。 # lsusb -vvv -d 0483:070b | grep bEndpointAddress bEndpointAddress 0x81 EP 1 IN bEndpointAddress 0x02 EP 2 OUT 得到：“EndPoint”地址IN方向为0x81，OUT方向为0x02。 用这些参数可以新建一个Usb类实例。timeout参数表示等待USB接口超时时间，默认为0。 from escpos import printer p = printer.Usb(0x1a2b, 0x1a2b, timeout=0, in_ep=0x81, out_ep=0x02) 该类使用pyusb和libusb与USB接口打印机通信，不适用于USB转串口适配器设备，只适用于原生USB驱动。 ","date":"2017-10-30","objectID":"/posts/ea7c7/:3:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"网络打印机 class escpos.printer.Network(host, port=9100, timeout=60, *args, **kwargs) 一般情况下只需要IP地址 from escpos import printer p = printer.Network(\"192.168.1.99\") ","date":"2017-10-30","objectID":"/posts/ea7c7/:4:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"串口打印机 class escpos.printer.Serial(devfile=r'/dev/ttyS0', baudrate=9600, bytesize=8, timeout=1, parity='N', stopbits=1, xonxoff=False, dsrdtr=True, *args, **kwargs) 大多数串口打印机都使用默认设置，只要知道连接哪个串口就可以了。 from escpos import printer p = printer.Serial(r\"/dev/tty0\") ","date":"2017-10-30","objectID":"/posts/ea7c7/:5:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"文件系统打印机 class escpos.printer.File(devfile=r'/dev/usb/lp0', auto_flush=True, *args, **kwargs) 有些打印机使用上述类不能正常初始化（通常是使用printcap的打印机），如果你知道设备名，可以直接尝试用设备节点名来定义打印机实例： from escpos import printer p = printer.File(r\"/dev/usb/lp1\") ","date":"2017-10-30","objectID":"/posts/ea7c7/:6:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"虚拟打印机 class escpos.printer.Dummy(*args, **kwargs) 此虚拟打印机用于不需要向实际打印机发送命令的情况，可以将原生命令输出保存到变量。可以用于生成print jobs供以后使用，或者测试打印输出。使用该类的output参数获取原生命令。 ESC/POS API详解 所有的打印机类都继承自escpos.escpos.Escpos，该Escpos抽象基类定义了打印时的各种方法。 先来个demo吧： from escpos.printer import Usb p = Usb(0x0483, 0x070b, 0, 0x81, 0x02) p.hw('INIT') p.textln('Hello, world!') p.image('mafengwo.png') p.set(align='center') p.qr('https://i.senguo.cc', size=7,) p.barcode('9787111436737', 'EAN13') p.close() ","date":"2017-10-30","objectID":"/posts/ea7c7/:7:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"打印QR码 qr(content, ec=0, size=3, model=2, native=False, center=False) 根据传入的字符串打印QR码，一般情况下为先生成QR码图片然后传给打印机打印图片。 参数说明： content - 二维码的内容，数字数据能够被更高效地压缩。 ec - 容错能力，取值如下：QR_ECLEVEL_L=0、QR_ECLEVEL_M=1、QR_ECLEVEL_Q=2或QR_ECLEVEL_H=3，默认值为0。相对而言，容错能力越高，QR码图形面积越大。 size - QR码大小等级，取值范围为1-16，默认值为3。实际打印大小取决于QR码的内容，实测打印内容为https://i.senguo.cc/时在58mm打印纸上最大等级为14。 model - QR码格式，取值如下：QR_MODEL_1=1、QR_MODEL_2 =2或QR_MICRO=3，默认值为2。不是所有的打印机都支持QR_MICRO格式。（XP-58IIQ只支持QR_MODEL_2）。 native - 原生打印模式，为True时给打印机传代码，False时给打印机传生成的QR码图片，默认值False center - 是否居中，默认值False。（当前并不生效，还是要先用set方法设置居中） ","date":"2017-10-30","objectID":"/posts/ea7c7/:8:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"打印图片 image(img_source, high_density_vertical=True, high_density_horizontal=True, impl='bitImageRaster', fragment_height=960, center=False) 你可以选择是否使用高密度模式打印，默认为高密度模式。如果以低密度模式打印，图像将被拉伸（低密度模式即是倍宽、倍高模式）。 ESC/POS提供了几个打印命令，本方法支持其中的三个。如果你打印图片有问题，可以尝试其他打印命令。 可用的打印实现有： bitImageRaster：使用GS v 0命令打印； graphics：使用GS ( L命令打印； bitImageColumn：使用ESC *命令打印； 参数列表： img_source - PIL image对象或者文件名字符串，支持jpg、gif、png和bmp格式图像。 high_density_vertical - 在垂直方向使用高密度打印模式，默认值True； high_density_horizontal - 在水平方向使用高密度打印模式，默认值True； impl - 打印实现模式，可选值如上所述，默认值为bitImageRaster； fragment_height - 图片高度大于该值的将会被分为多片段打印，默认值为960； center - 是否居中，默认值False。（当前并不生效，还是要先用set方法设置居中） ","date":"2017-10-30","objectID":"/posts/ea7c7/:9:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"打印条形码 barcode(code, bc, height=64, width=3, pos='BELOW', font=u'A', align_ct=True, function_type=None, check=True) 该方法用于打印条形码，条形码打印是大部分打印机原生支持的功能。默认情况下，该方法会检查传入的条形码文本是否正确，即ESCPOS协议支持的条形码的字符和长度。使用 check=False 参数可以禁用检查，但是不正确的条形码可能会导致打印机的未知行为。条形码功能有两种类型，默认使用类型A，但类型A条码较少，类型B有更多的选择。 使用参数 height 和 width 调整条码尺寸。请注意，条码如果在可打印区域外将不会被打印。（一般来讲这是不会出现的，因此这个信息可能在调试时更有用。） 如果你不想让条形码居中显示可以设置参数 align_ct=False，将会禁用自动居中。请注意，如果设置了条码居中显示，那么在此之后打印文字也将是居中的，你需要在打印完条码后手动设置对齐方式。 参数列表： code - 要打印为条形码的字母数字数据； bc - 条形码格式，type A的格式有： UPC-A UPC-E EAN13 EAN8 CODE39 ITF NW7 type B的格式有： 所有Type A中的格式； CODE93 CODE128 GS1-128 GS1 DataBar Omnidirectional GS1 DataBar Truncated GS1 DataBar Limited GS1 DataBar Expanded 如果没有传该参数，会抛出BarcodeTypeError异常。 height - 条码高度，取值范围1-255，默认值64。 width - 条码宽度，取值范围2-6，默认值3。 pos - 文字相对于条形码的位置，默认值BELOW在条码下方，可取值： ABOVE BELOW BOTH OFF font - 选择字体A或B，默认值A。 align_ct - 条码是否居中，默认True。如果为False，将不会发送对齐方式指令。 function_type - 根据打印机是否支持支持和所需条形码，在ESCPOS功能类型A或B之间进行选择。如果没有给出，打印机将尝试根据当前配置文件自动选择正确的功能。 默认值：A。 check - 如果设置为True，将会检查条形码格式，已确保其符合esc/pos文档中的要求。默认值True。更多信息见escpos.Escpos.check_barcode方法。 soft_barcode(barcode_type, data, impl='bitImageColumn', module_height=5, module_width=0.2, text_distance=1) “软打印”条形码。类似打印QR码，该方法将数据先转化为图片，再发送给打印机打印。暂时没有文档。 ","date":"2017-10-30","objectID":"/posts/ea7c7/:10:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"打印文本 text(txt) 打印字母和数字文本，传入txt为Unicode编码格式。但是这样无法打印中文，会乱码。 ln(count=1) 打印n个换行，默认打印1个换行。count不能小于0。 textln(txt='') 打印字母数字文本并换行，调用text(txt)方法实现。 block_text(txt, font=None, columns=None) 打印文本到指定的列，即打印columns列后就自动换到下一行继续打印。注意在最后不会打印换行符，所以最后一行的文本打印不出来。 ","date":"2017-10-30","objectID":"/posts/ea7c7/:11:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"设置格式 set(align='left', font=u'a', bold=False, underline=0, width=1, height=1, density=9, invert=False, smooth=False, flip=False, double_width=False, double_height=False, custom_size=False ) 设置文本属性。 参数列表： align (str) - 设置水平位置，可选值center、left和right。默认值left。 font (str) - 设置字体，可以使用字体名，‘a’和’b’，或者0和1。（貌似并没有用） bold (bool) - 设置文本加粗，默认值False。 underline (int) - 设置文本下划线，取值范围0-2，0没有下划线，1和2有下划线，2时下划线颜色较深，仅英文有效，默认值0。 double_height (bool) - 设置文字倍高，默认值False。 double_width (bool) – 设置文字倍宽，默认值False。 custom_size (bool) – 使用由width和height参数定义的大小，此时double_height和double_width参数不生效。默认值False。 width (int) – 当custom_size为True时用于设定文本宽度，取值范围1-8，默认值1。 height (int) – 当custom_size为True时用于设定文本高度，取值范围1-8，默认值1。 density (int) – 打印密度，取值范围0-8，当前版本未生效 invert (bool) – 设置反色打印, 默认值: False smooth (bool) – 开启字体平滑，只对4x4及以上大小的文本有效，默认值: False flip (bool) – 开启倒置打印，当前版本无效，默认值：False line_spacing(spacing=None, divisor=180) 设置行距，如果不传参数，行距会被设置为默认值。 有几种不同的命令可以设置行距，它们分别使用了不同的分母divisor： “+”: 一英寸的line_spacing/360，其中0 \u003c= line_spacing \u003c= 255； “3”: 一英寸的line_spacing/180，其中0 \u003c= line_spacing \u003c= 255； “A”: 一英寸的line_spacing/60，其中0 \u003c= line_spacing \u003c= 85。 有些打印机不支持上述所有类型，请使用最通常的方式，也就是180做分母的方式。（xp-58IIQ支持180模式） ","date":"2017-10-30","objectID":"/posts/ea7c7/:12:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"硬件操作 ","date":"2017-10-30","objectID":"/posts/ea7c7/:13:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"切纸 cut(mode='FULL', feed=True) 默认不传任何参数时，切纸会完全切断。当mode传\"PART\"是，将会尝试部分切纸。不是所有的打印机都支持切纸和部分切纸。 参数列表： mode - 可选\"PART\"或者\"FULL”，默认值\"FULL”； feed - 在切纸前“打印并进纸”，默认为True。 ","date":"2017-10-30","objectID":"/posts/ea7c7/:13:1","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"打开钱箱 cashdraw(pin) 发送打开钱箱指令脉冲。 传入2或5或一个十进制数组成的list，表示脉冲序列。 ","date":"2017-10-30","objectID":"/posts/ea7c7/:13:2","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"其他 hw(hw) 硬件操作，可选值\"INIT”，“SELECT\"或\"RESET”。 print_and_feed(n=1) 打印缓冲区数据，并进纸n行。n的取值范围为0-255，默认为1。 panel_buttons(enable=True) 是否使能控制面板按钮。默认True。该设置持续到打印机initialized, reset or power-cycled。 禁用按钮对有些打印机无效。 ","date":"2017-10-30","objectID":"/posts/ea7c7/:13:3","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"查询状态 is_online() 这个，不用解释了吧，返回True或者False。 paper_status() 查询打印纸状态。返回int型，2有纸，1有纸但纸快没了，0没纸。 query_status(mode) 查询打印机状态，返回一个数组。mode取值RT_STATUS_ONLINE或RT_STATUS_PAPER，分别查询打印机在线状态和打印纸状态，但返回数组意义不明。 打印中文兼容性 可以写一个自定义类，继承自Usb类（假如你是Usb打印机的话）： class MyUsb(Usb): \"\"\"docstring for MyUsb\"\"\" def __init__(self, *args, **kwargs): super(MyUsb, self).__init__(*args, **kwargs) self.charcode('CP1252') def text(self, txt): txt = txt.encode('gb2312').decode('l1') txt = six.text_type(txt) self.magic.write(txt) ","date":"2017-10-30","objectID":"/posts/ea7c7/:14:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"芯烨 XP-58IIQ 设置字符代码表为\"CP1252”； 打印机默认使用GB2312编码，将中文文本用GB2312编码后使用latin1解码。 p.charcode('CP1252') p.textln('中文'.encode('gb2312').decode('latin1')) ","date":"2017-10-30","objectID":"/posts/ea7c7/:15:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"复坤 FK-POS58GP-2 设置字符代码表为\"ISO_8859-2”； 打印机默认使用UTF-8编码，将中文文本用UTF-8编码后使用latin2解码。 p.charcode('ISO_8859-2') p.textln('中文'.encode().decode('latin2')) # encode不传参数即编码为utf-8 ","date":"2017-10-30","objectID":"/posts/ea7c7/:16:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"复坤 FK-POS80GP-2 p.charcode('CP1252') p.textln('中文'.encode('gb2312').decode('latin1')) ","date":"2017-10-30","objectID":"/posts/ea7c7/:17:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"佳博 S-U804 p.charcode('ISO_8859-15') p.textln('中文'.encode('gb2312').decode('latin2')) 写在最后 目前来看，escpos库的3.0版本将会很不错，但是发布时间并不确定，目前已经处于alpha测试10个月了= =只能先用着3.0a3测试版本，等正式版本出来后再更新笔记。 热敏打印机的应用，想到几个： 打印开发任务上线的checklist； 作为一个输出设备，用来输出一些需要对比历史数据、不重要的、看过就可以扔的输出； 也许哪天SG要用Pyton操作打印机了也说不定呢😄（中了！） ","date":"2017-10-30","objectID":"/posts/ea7c7/:18:0","tags":[],"title":"使用Python操作ESCPOS协议热敏打印机","uri":"/posts/ea7c7/"},{"categories":["Python"],"content":"写在前面 按照日常需求， 应该开启的扩展为： Fenced Code Blocks Tables Sane Lists SmartyPants 建议开启的扩展为： Codehilite Footnotes Meta-Data Table of Contents Python-Markdown简介 Python-Markdown是John Gruber创造的Markdown语言的Python实现。除了极少的差异外（差别见下文），它几乎完全符合其语法参考。点击查看Markdown语法文档。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:0:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"特性 除了基本的markdown语法，Python-Markdown还支持以下特性： 国际化语言输入(International Input) Python-Markdown 接受 Unicode 支持的任何语言，包括 bi-directional text。实际上测试套件包括用俄语和阿拉伯语写的文件。 扩展(Extensions) 支持多种扩展用于改变或扩展基本语法。有开放的extension API供你进行开发。 多种输出格式(Output Formats) Python-Markdown 支持以 HTML4、XHTML 和 HTML5 格式输出文档。 命令行界面(Command Line Interface) 提供了一个命令行脚本方便你进行 markdown 的转换。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:1:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"差异 虽然 Python-Markdown 尽量贴合 markdown 的语法规则，但某些规则可以以不同的方式解释，不同的方式实现（相关示例请参阅 Babelmark FAQ）。Python-Markdown中发现的已知和有意义的差异总结如下： Middle-Word Emphasis Python-Markdown 默认忽略 Middle-Word Emphasis。换言之，some_long_filename.txt 不会成为 some\u003cem\u003elong\u003c/em\u003efilename.txt。如有需要，这个选项可以关闭。 Indentation/Tab Length markdown语法 明确指出，当列表项包含多个段落时： each subsequent paragraph in a list item must be indented by either 4 spaces or one tab 然而许多markdown语法的实现并不执行此规则，允许缩进少于4个空格。Python-Markdown开发者认为这么做是个bug。 这适用于嵌套在列表中的任何块级元素，包括段落，子列表，块引用，代码块等。对于每个级别的嵌套，必须始终缩进四个空格或一个tab。 Consecutive Lists 虽然语法规则没有明确指出，但是当列表标记（星号，粗线，连字符和数字）更改时，许多实现（包括原始）不会结束一个列表并启动第二个列表。为了保持一致性，Python-Markdown保持相同的行为，目前没有更改的计划。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:2:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"安装 pip install markdown 或者 easy_install markdown 使用参考 ","date":"2017-10-29","objectID":"/posts/ac7c7/:3:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"简单的 import markdown html = markdown.markdown(your_text_string) ","date":"2017-10-29","objectID":"/posts/ac7c7/:4:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"详细的 Python-Markdown提供了两个公共函数（markdown.markdown和markdown.markdownFromFile），它们都包含公共类markdown.Markdown。如果您一次处理一个文档，这些功能将满足您的需求。但是，如果您需要处理多个文档，那么创建markdown.Markdown该类的单个实例并通过它传递多个文档可能是有利的。如果您确实使用单个实例，请确保正确调用该reset 方法。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:5:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"markdown.markdown (text [, **kwargs]) text（必需）：源Unicode字符串。Python-Markdown期望Unicode作为输入（尽管一些简单的ASCII字符串可能正常工作），并返回输出为Unicode。不要将编码后的字符串传递给它！ extensions：扩展列表。Python-Markdown为第三方提供了一个API来为解析器编写extension，对语法进行添加或更改。一些常用的extension程序随着markdown库一起提供。有关可用extension的列表，请参阅文档。 extension列表可以包含extension实例或者extension名字符串。优先传extension实例。 extensions=[MyExtension(), 'path.to.my.ext'] extension_configs：扩展名的配置字典。任何配置项只会传递给使用名称字符串加载的extension，使用类实例加载的extension将会在类初始化时直接传递参数。（优选的方法是使用类实例加载extension，因此并不需要使用extension_configs关键字。） 配置字典必须采用以下格式（查看extension的配置参数请参阅extension相关文档）： extension_configs = { 'extension_name_1': { 'option_1': 'value_1', 'option_2': 'value_2' }, 'extension_name_2': { 'option_1': 'value_1' } } output_format：输出格式。支持的格式有（值可以是小写或大写）： \"xhtml1\"：输出XHTML 1.x. 默认。 \"xhtml5\"：输出HTML 5的XHTML样式标签。 \"xhtml\"：（不推荐使用）输出最新支持的XHTML版本（目前为XHTML 1.1）。 \"html4\"：输出HTML 4。 \"html5\"：输出HTML 5的HTML样式标签 \"html\"：（不推荐使用）输出最新支持的HTML版本（目前为HTML 4）。 safe_mode：（已被弃用）禁止部分原生HTML标签。默认值：False，可选值 replace、remove、escape。“safe_mode” 也会更改 enable_attributes 选项的默认值。该设置项已被弃用，建议使用HTML清理器（如 Bleach）处理用户提交的不受信任的HTML。 import markdown import bleach html = bleach.clean(markdown.markdown(untrusted_text)) html_replacement_text:当safe_mode设置为replace时用于替换的文本。已被弃用。 tab_length：tab的长度。默认值：4 enable_attributes：启用属性的转换。默认为 True，除非 safe_mode 启用，在这种情况下是默认值 False。safe_mode仅覆盖默认值。如果enable_attributes 显式设置，则使用显式值，无论如何safe_mode。但是，这可能会让不受信任的用户将JavaScript注入到文档中。 smart_emphasis：_connected_words_ 智能处理默认值：True，即上文差异中说的第一点。 lazy_ol：忽略有序列表的第一个项目的数量。默认值：True，即上文差异中说的第三点。如果设置为False，则给出以下列表： 4. Apples 5. Oranges 6. Pears 将输出： \u003col start=\"4\"\u003e \u003cli\u003eApples\u003c/li\u003e \u003cli\u003eOranges\u003c/li\u003e \u003cli\u003ePears\u003c/li\u003e \u003c/ol\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:5:1","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"markdown.markdownFromFile (**kwargs) 除了极少数的情况，markdown.markdownFromFile接受与markdown.markdown相同的参数。但是其不接受text（或Unicode）类型字符串，而是接受以下必传参数： input （必填）：源文本文件。 可以设置为以下三种： 一个字符串，指定了文件系统中可读文件的路径； 一个可读的file-like对象； None（默认），此时将从stdin中读取； output：定义输出位置。 可以设置为以下三种： 一个字符串，指定了文件系统中可写文件的路径； 一个可写的file-like对象； None（默认），此时输出到stdout； encoding：源文本文件的编码。默认值是utf-8。输入和输出总是使用相同的编码。编码output时将会使用xmlcharrefreplace错误处理程序。 这是唯一可以在Python-Markdown中进行Unicode解码和编码的地方。如果这种天真的解决方案不能满足您的具体需求，建议您编写自己的代码来处理编码/解码需求。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:5:2","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"markdown.Markdown ([**kwargs]) 初始化markdown.Markdown类时，可以使用与markdown.markdown函数相同的参数，唯一的例外是该类在初始化时不接受源文本字符串。源文本字符串必须传递给以下两个实例方法之一： Markdown.convert(source) 该source文本与markdown.markdown函数的text参数有相同的要求。 你还可以用该方法处理多个字符串而不必为每个字符串创建一个新的类实例。 md = markdown.Markdown() html1 = md.convert(text1) html2 = md.convert(text2) 根据要使用的选项和扩展，解析器可能要在每个调用convert方法之间进行复位（reset），否则可能会影响性能： html1 = md.convert(text1) md.reset() html2 = md.convert(text2) 你也可以同时调用reset方法和convert方法： html3 = md.reset().convert(text3) Markdown.convertFile(**kwargs) 该方法的参数与markdown.markdownFromFile函数相同。与convert方法一样，该方法也用于处理多个文件而不必为每个文件创建一个新的类实例，也可在调用convertFile之间调用reset方法。 CLI命令 虽然Python-Markdown主要是一个Python库，但也包括一个命令行脚本。虽然还有许多其他的命令行的Markdown实现，但您可能没有安装它们，或者您更喜欢使用Python-Markdown的各种扩展：） Python-Markdown的命令行脚本利用了Python的-m标志。因此可以通过以下方式来运行： $ python -m markdown [options] [args] 最基本的用法是只传递一个文件名作为唯一的参数： $ python -m markdown input_file.txt 支持管道输入和输出（STDIN和STDOUT)。例如： $ echo \"Some **Markdown** text.\" | python -m markdown \u003e output.html 使用--help参数查看所有可用选项和参数列表。 $ python -m markdown --help 如果不想直接调用Python可执行文件（使用-m标志），请按照以下说明使用封装后的脚本： ","date":"2017-10-29","objectID":"/posts/ac7c7/:5:3","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"设置 Python-Markdown使用\"markdown_py\"作为脚本名称，因为Perl语言已经使用了更加明显的名称\"markdown”。此外，某些系统上的默认Python配置会导致命名为\"markdown.py\"的脚本不能正常工作，因为系统错误地导入了脚本本身而不是markdown库。因此，我们将脚本命名为了\"markdown_py”，如果您希望在您的系统中使用不同的脚本名称，建议您使用软链接指定到markdown_py命令。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:6:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"使用说明 最简单的方式 $ markdown_py input_file.txt 或者 $ markdown_py input_file.txt \u003e output_file.html 要查看所有可用选项的列表 $ markdown_py --help ","date":"2017-10-29","objectID":"/posts/ac7c7/:7:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"加载extension 要从命令行加载Python-Markdown extension，请使用-x （或--extension）选项。扩展模块必须位于您的PYTHONPATH 环境变量中（有关详细信息，请参阅Extension API）。可以使用Python的点语法通过该模块的名称来调用extension： $ python -m markdown -x path.to.module input.txt 要加载多个extension，请为每个extension都指定-x选项： $ python -m markdown -x markdown.extensions.footnotes -x markdown.extensions.codehilite input.txt 如果extension支持配置选项，您也可以将它们传入： $ python -m markdown -x markdown.extensions.footnotes -c config.yml input.txt 该-c（或--extension_configs）选项接受一个文件名。该文件必须是YAML或JSON格式，并且包含YAML或JSON格式的内容，储存markdown.Markdown的extension_configs关键字参数使用的dict。因此，config.yaml上述示例中引用的文件可能如下所示： markdown.extensions.footnotes:PLACE_MARKER:~~~~~~~~UNIQUE_IDS:True 请注意，虽然该--extension_configs选项确实指定了“markdown.extensions.footnotes” extension，但您仍然需要使用-x选项加载该extension，否则该extension的配置将被忽略。 如果您的系统中安装了PyYAML，--extension_configs选项将能够支持YAML格式配置文件。JSON格式配置文件的支持不需要安装额外扩展。程序会自动检测配置文件的格式。 官方Extensions 下面列出的extensions都包含在最新版本的Python-Markdown包中，并且由Python-Markdown官方维护。 Extension “Name” Extra markdown.extensions.extra - Abbreviations markdown.extensions.abbr - Attribute Lists markdown.extensions.attr_list - Definition Lists markdown.extensions.def_list - Fenced Code Blocks markdown.extensions.fenced_code - Footnotes markdown.extensions.footnotes - Tables markdown.extensions.tables - Smart Strong markdown.extensions.smart_strong Admonition markdown.extensions.admonition CodeHilite markdown.extensions.codehilite HeaderId markdown.extensions.headerid Meta-Data markdown.extensions.meta New Line to Break markdown.extensions.nl2br Sane Lists markdown.extensions.sane_lists SmartyPants markdown.extensions.smarty Table of Contents markdown.extensions.toc WikiLinks markdown.extensions.wikilinks ","date":"2017-10-29","objectID":"/posts/ac7c7/:8:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Extra 这是一部分Python-Markdown扩展的集合，主要模仿了PHP Markdown Extra。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:9:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Abbreviations 该扩展提供定义缩写的功能。任何定义的缩写都会被包含在\u003cabbr\u003e标签中。 举例说明，下面的文本 The HTML specification is maintained by the W3C. *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium 将会被解析为： \u003cp\u003e The \u003cabbr title=\"Hyper Text Markup Language\"\u003eHTML\u003c/abbr\u003e specification is maintained by the \u003cabbr title=\"World Wide Web Consortium\"\u003eW3C\u003c/abbr\u003e . \u003c/p\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:9:1","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Attribute Lists 该扩展为HTML输出中的元素添加了属性定义。 语法 属性列表定义如下所示： {: #someid .someclass somekey='some value' } 以hash（#）开头的单词将设置为一个元素的id，以dot（.）开头的单词将被添加到元素的class中，键值对（somekey='some value'）将会作为属性分配给元素。注意，对于class，后定义的键值对会覆盖前定义的dot语法。 例如，下面的定义： {: #id1 .class1 id=id2 class=\"class2 class3\" .class4 } 其属性定义的结果是： id=\"id2\" class=\"class2 class3 class4\" 使用 定义块级元素的属性，属性列表应该在块的最后一行定义。 This is a paragraph. {: #an_id .a_class } 以上的解析结果是： \u003cp id=\"an_id\" class=\"a_class\"\u003eThis is a paragraph.\u003c/p\u003e 对于标题，只能定义在同一行： A setext style header {: #setext} ================================= ### A hash style header ### {: #hash } 以上的解析结果是： \u003ch1 id=\"setext\"\u003eA setext style header\u003c/h1\u003e \u003ch3 id=\"hash\"\u003eA hash style header\u003c/h3\u003e 定义内联元素的属性，属性应在同一行的内联元素后定义，且中间不能有空格。 [link](http://example.com){: class=\"foo bar\" title=\"Some title!\" } 以上的解析结果是： \u003cp\u003e\u003ca href=\"http://example.com\" class=\"foo bar\" title=\"Some title!\"\u003elink\u003c/a\u003e\u003c/p\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:9:2","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Definition Lists 该扩展用于定义HTML中的definition list。 Apple : Pomaceous fruit of plants of the genus Malus in the family Rosaceae. Orange : The fruit of an evergreen tree of the genus Citrus. 将呈现为： \u003cdl\u003e \u003cdt\u003eApple\u003c/dt\u003e \u003cdd\u003ePomaceous fruit of plants of the genus Malus in the family Rosaceae.\u003c/dd\u003e \u003cdt\u003eOrange\u003c/dt\u003e \u003cdd\u003eThe fruit of an evergreen tree of the genus Citrus.\u003c/dd\u003e \u003c/dl\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:9:3","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Fenced Code Blocks 该扩展用于定义多行代码块。 可以这样： ​~~~~{.python} # python code ​~~~~ ​~~~~.html \u003cp\u003eHTML Document\u003c/p\u003e ​~~~~ 或者这样 ​```python # more python code ​``` 对代码块中某些行进行强调（需要安装 Pygments依赖）： ​~~~~{.python hl_lines=\"1 3\"} # This line is emphasized # This line isn't # This line is emphasized ​~~~~ 或者 ​```python hl_lines=\"1 3\" # This line is emphasized # This line isn't # This line is emphasized ​``` ","date":"2017-10-29","objectID":"/posts/ac7c7/:9:4","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Footnotes 该扩展支持在Markdown文档中定义脚注。 Footnotes[^1] have a label[^@#$%] and the footnote's content. [^1]: This is a footnote content. [^@#$%]: A footnote on the label: \"@#$%\". 脚注标签定义在一组square brackets（[]）中，必须以caret（^）开头，标签名中可能包含任何内联文本，包括空格。只有第一个^是有特殊含义的。 脚注内容格式：在标签后必须跟冒号和至少一个空格，然后在同一行或者下一行添加脚注内容。内容可以包含多行、段落、代码块、引用和其他大多数markdown语法。从第二行开始应当缩进一级（四个空格或者一个tab）。 当使用多个块时，建议在块与块之间空一行分割内容，增加可读性。 [^1]: The first paragraph of the definition. Paragraph two of the definition. \u003e A blockquote with \u003e multiple lines. a code block A final paragraph. ","date":"2017-10-29","objectID":"/posts/ac7c7/:9:5","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Tables 该扩展支持在Markdown文档中定义表格。 First Header | Second Header ------------- | ------------- Content Cell | Content Cell Content Cell | Content Cell 将呈现为： \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eFirst Header\u003c/th\u003e \u003cth\u003eSecond Header\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003eContent Cell\u003c/td\u003e \u003ctd\u003eContent Cell\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eContent Cell\u003c/td\u003e \u003ctd\u003eContent Cell\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:9:6","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Smart_Strong 该扩展能智能处理双下划线标识的强调。 \u003e\u003e\u003e import markdown \u003e\u003e\u003e markdown.markdown('Text with double__underscore__words.', \\ extensions=['markdown.extensions.smart_strong']) u'\u003cp\u003eText with double__underscore__words.\u003c/p\u003e' \u003e\u003e\u003e markdown.markdown('__Strong__ still works.', \\ extensions=['markdown.extensions.smart_strong']) u'\u003cp\u003e\u003cstrong\u003eStrong\u003c/strong\u003e still works.\u003c/p\u003e' \u003e\u003e\u003e markdown.markdown('__this__works__too__.', \\ extensions=['markdown.extensions.smart_strong']) u'\u003cp\u003e\u003cstrong\u003ethis__works__too\u003c/strong\u003e.\u003c/p\u003e' ","date":"2017-10-29","objectID":"/posts/ac7c7/:9:7","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Admonition 该扩展支持在markdown中定义rST-style admonitions。 !!! type \"optional explicit title within double quotes\" Any number of other indented markdown elements. This is the second paragraph. 如果没有标题，type将被用作css类名和默认标题。rST建议以下内容的type：attention, caution, danger, error, hint, important, note, tip, warning。举个🌰： !!! note You should note that the title will be automatically capitalized. \u003cdiv class=\"admonition note\"\u003e \u003cp class=\"admonition-title\"\u003eNote\u003c/p\u003e \u003cp\u003eYou should note that the title will be automatically capitalized.\u003c/p\u003e \u003c/div\u003e 如果不想有标题，可以将标题设置为空字符串\"\" !!! important \"\" This is a admonition box without a title. \u003cdiv class=\"admonition important\"\u003e \u003cp\u003eThis is a admonition box without a title.\u003c/p\u003e \u003c/div\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:10:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"CodeHilite ","date":"2017-10-29","objectID":"/posts/ac7c7/:11:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"安装 该扩展使用 Pygments 为代码块添加语法高亮。使用该插件需要先安装 Pygments： pip3 install pygments 通过 Pygments 生成 css 样式文件： pygmentize -S default -f html -a .codehilite \u003e styles.css -S 指定使用的 css 主题样式名称，Pygments 内置了多种主题，查看内置主题列表： pygmentize -L style 下面的网站提供了主题的预览： Pygments Syntax Highlighter CSS Theme Files pygments-css by richleland -a 选项应与 codehilete 的配置 css_class 保持一致。 把生成的 css 文件集成到展示 markdown 文档的 html 中，即可实现代码块语法高亮。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:11:1","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"配置 该扩展有以下配置项： linenums 是否展示行号。默认为 None 表示自动处理，可以设置为 True - 展示，False - 不展示。 guess_lang 猜测代码块语言。默认为 True，可以设置为 False。 css_class 设置代码块 div 标签中的 css类名，默认为 codehilite。 pygments_style Pygment HTML 主题样式名称，默认为 default。该选项只在 noclasses 为 True 时有效，否则应该另外提供 css 文件。 noclasses 使用内联样式，默认为 False。 use_pygments 使用 Pygment，默认为 True。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:11:2","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Headerld 该扩展自动为生成的HTML文件中的标题元素（h1-h6)生成id属性。 注意：该扩展即将被弃用，请使用提供了更多特性的TOC扩展作为替代。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:12:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"语法 默认情况下，将会基于标题的文本生成唯一的标题id。举🌰如下： # Header # Header # Header 渲染结果是： \u003ch1 id=\"header\"\u003eHeader\u003c/h1\u003e \u003ch1 id=\"header_1\"\u003eHeader\u003c/h1\u003e \u003ch1 id=\"header_2\"\u003eHeader\u003c/h1\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:12:1","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"使用 选项如下： level：设置标题的基本级别，默认值为1。假如你要设置所有的标题都不高于level 3(\u003ch3\u003e)： \u003e\u003e\u003e text = ''' ... #Some Header ... ## Next Level''' \u003e\u003e\u003e from markdown.extensions.headerid import HeaderIdExtension \u003e\u003e\u003e html = markdown.markdown(text, extensions=[HeaderIdExtension(level=3)]) \u003e\u003e\u003e print html \u003ch3 id=\"some_header\"\u003eSome Header\u003c/h3\u003e \u003ch4 id=\"next_level\"\u003eNext Level\u003c/h4\u003e' fouceid：强制所有headers都有id，默认值True。 \u003e\u003e\u003e text = ''' ... # Some Header ... # Header with ID # { #foo }''' \u003e\u003e\u003e html = markdown.markdown(text, extensions=['markdown.extensions.attr_list', HeaderIdExtension(forceid=False)]) \u003e\u003e\u003e print(html) \u003ch1\u003eSome Header\u003c/h1\u003e \u003ch1 id=\"foo\"\u003eHeader with ID\u003c/h1\u003e separator：单词分隔符，用于代替id中的空格。默认值-。 slugify：用于生成锚点。默认值markdown.extensions.headerid.slugify。如果你想使用不同的id生成算法，你可以传一个包含以下两个参数的可调用对象： value：slugify字符串。 separator：单词分隔符。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:12:2","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"使用Meta-data 该扩展支持Meta-data扩展。使用的关键字是： header_level header_forceid 使用时，meta-data将会覆盖通过extension_configs接口传入的设置。 header_level: 2 header_forceid: Off # A Header 渲染后： \u003ch2\u003eA Header\u003c/h2\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:12:3","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Meta-Data 该扩展提供了定义文档元数据的方法。目前，该扩展并不使用元数据，而是作为Markdown实例的 Meta 属性，供其他扩展或直接被 Python 代码调用。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:13:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Syntax Meta-data 定义在 markdown 文件的开头，包含一系列的 keyword 和 value。keyword 不区分大小写，可能包含字母、数字、下划线和短横线，必须以冒号结尾。value 包含冒号后当前行的所有内容，也可为空。 如果一行缩进不少于 4 个空格，这一行被认为是先前行 keyword 的 value 的附加行，可以有多行 keyword。 空行将会结束所有 Meta-data 的定义。因此，如果含有元数据定义，文档的第一行不能是空行。 Title: My Document Summary: A brief description of my document. Authors: Waylan Limberg John Doe Date: October 2, 2007 blank-value: base_url: http://example.com This is the first paragraph of the document. 你也可以使用 YAML 样式来标识 Meta-data 的起止行。此时，文档的第一行必须是 —--，Meta-data 在遇到第一个空白行结束，或遇到包含结尾分隔符（--- 或者 ...）的行结束。如此做的话，即使 Markdown 支持 YAML 解析，元数据也不会被解析为 YAML 内容。 --- Title: My Document Summary: A brief description of my document. Authors: Waylan Limberg John Doe Date: October 2, 2007 blank-value: base_url: http://example.com --- This is the first paragraph of the document. 上面两个例子的解析结果： \"\u003cp\u003eThis is the first paragraph of the document.\u003c/p\u003e\" ","date":"2017-10-29","objectID":"/posts/ac7c7/:13:1","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"访问Meta-data meta-data 在 Markdown 类实例的 Meta 属性中作为一个 python Dict 提供。注意：所有的 keyword 都是小写的，value 是一个 String 组成的 List，其中的每一个元素是该 keyword 的一行，不包含换行符。如果有需要，可以保留换行符或者在合适的时候加上。 { 'authors': ['Waylan Limberg', 'John Doe'], 'base_url': ['http://example.com'], 'blank-value': [''], 'date': ['October 2, 2007'], 'summary': ['A brief description of my document.'], 'title': ['My Document'] } 元数据可以在模版系统中传入，或者被其他Markdown扩展使用。只有你想不到哈哈哈～ ","date":"2017-10-29","objectID":"/posts/ac7c7/:13:2","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"已兼容的扩展 HeaderId header_level header_forceid WikiLinks wiki_base_url wiki_end_url wiki_html_class ","date":"2017-10-29","objectID":"/posts/ac7c7/:13:3","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"New Line to Break 该扩展(nl2br)会把markdown中的换行视为”hard break“，类似StackOverFlow和GitHub的风格。 \u003e\u003e\u003e import markdown \u003e\u003e\u003e text = \"\"\" ... Line 1 ... Line 2 ... \"\"\" \u003e\u003e\u003e html = markdown.markdown(text, extensions=['markdown.extensions.nl2br']) \u003e\u003e\u003e print html \u003cp\u003eLine 1\u003cbr /\u003e Line 2\u003c/p\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:14:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Sane Lists 该扩展改变了Markdown中列表的语法。 Sane List不允许列表项混合。即当遇到无序列表时，有序列表将不会继续，反之亦然。例如： 1. Ordered item 1 2. Ordered item 2 * Unordered item 1 * Unordered item 2 将产生以下输出： \u003col\u003e \u003cli\u003eOrdered item 1\u003c/li\u003e \u003cli\u003eOrdered item 2\u003c/li\u003e \u003c/ol\u003e \u003cul\u003e \u003cli\u003eUnordered item 1\u003c/li\u003e \u003cli\u003eUnordered item 2\u003c/li\u003e \u003c/ul\u003e 而默认的Markdown行为是生成有序列表（实测）。 注意，与默认的Markdown行为不同，如果列表项之间未包含空白行，不同的列表类型将被忽略，这与段落的行为一致。 A Paragraph. * Not a list item. 1. Ordered list item. * Not a separate list item. 该扩展的输出为： \u003cp\u003eA Paragraph. * Not a list item.\u003c/p\u003e \u003col\u003e \u003cli\u003eOrdered list item. * Not a separate list item.\u003c/li\u003e \u003c/ol\u003e 默认Markdown输出： \u003cp\u003eA Paragraph. * Not a list item.\u003c/p\u003e \u003col\u003e \u003cli\u003eOrdered list item.\u003c/li\u003e \u003cli\u003eNot a separate list item.\u003c/li\u003e \u003c/ol\u003e 在其他方面，该扩展与正常的Markdown列表一致。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:15:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"SmartyPants 该扩展将ASCII码的短横线dash、引号quotes、和省略号ellipses替换为他们的html表示法。 ASCII symbol Replacements HTML Entities Substitution Keys ' ‘ ’ \u0026lsquo; \u0026rsquo; 'left-single-quote', 'right-single-quote' \" “ ” \u0026ldquo; \u0026rdquo; 'left-double-quote', 'right-double-quote' \u003c\u003c \u003e\u003e « » \u0026laquo; \u0026raquo; 'left-angle-quote', 'right-angle-quote' ... … \u0026hellip; 'ellipsis' -- – \u0026ndash; 'ndash' --- — \u0026mdash; 'mdash' 使用’substitutions’配置项你可以覆盖默认配置。只需要传一个dict映射key和替代的string。 举个🌰 extension_configs = { 'markdown.extensions.smarty': { 'substitutions': { 'left-single-quote': '\u0026sbquo;', # sb is not a typo! 'right-single-quote': '\u0026lsquo;', 'left-double-quote': '\u0026bdquo;', 'right-double-quote': '\u0026ldquo;' } } } 扩展配置项： 选项 默认值 描述 smart_dashes True 是否转换破折号 smart_quotes True 是否直接转换引号 smart_angled_quotes False 是否转换尖括号 smart_ellipses True 是否转换省略号 substitutions {} 即上面说到的配置项 ","date":"2017-10-29","objectID":"/posts/ac7c7/:16:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Table of Contents 该扩展用于生成目录。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:17:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Syntax 使用扩展时默认情况下，所有标题将自动基于标题文本生成唯一的标题id属性，像HeaderId扩展一样。 在文档需要放置目录的地方放一个[TOC]标记，将会替换为由所有标题生成的嵌套列表。 无论在文档中有没有maker（默认是[TOC]），都可以使用Markdown类实例的toc属性读取目录内容，然后在页面模版中使用目录。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:17:1","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Usage 提供以下选项来配置输出： maker：在文档中用于寻找和替换目录的字符串，默认值是[TOC]。设置为空字符串将会禁用搜索maker，这在长文档中能够节约转换的时间。 title：插入目录\u003cdiv\u003e元素的title，默认值为None。 anchorlink：设置为True将使所有标题链接到自己。默认值为False。 permalink：设置为True或一个String，以在每个标题的末尾生成永久链接。适用于Sphinx样式表。当设置为True时，段落符号（¶或 \u0026para;）用作链接文本；当设置为String时，提供的String作为链接文本。 baselevel：标题的基本级别，默认为1。举个例子，假如设置为3，那么所有标题的级别都不会高于3，如下： \u003e\u003e\u003e text = ''' ... #Some Header ... ## Next Level''' \u003e\u003e\u003e from markdown.extensions.toc import TocExtension \u003e\u003e\u003e html = markdown.markdown(text, extensions=[TocExtension(baselevel=3)]) \u003e\u003e\u003e print html \u003ch3 id=\"some_header\"\u003eSome Header\u003c/h3\u003e \u003ch4 id=\"next_level\"\u003eNext Level\u003c/h4\u003e' slugify：用于生成锚点，默认值markdown.extensions.headerid.slugify。与HeaderId的slugify参数用法相同。 separator：单词分隔符，用于替换id中的空格，默认值是-。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:17:2","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"WikiLinks 该扩展提供了对WikiLinks的支持。具体来说，任何的[[bracketed]]标记都将转换为链接。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:18:0","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Syntax [[bracketed]]标记由大写字母、小写字母、数字、短横线dash、下划线和空格组成，被两个方括号包裹而成。WikiLinks会自动分配class=\"wikilink\"属性以使WikiLink的样式与页面上其他链接进行区别。下面会降到如何修改class名。因此： [[Bracketed]] 将会被转换为： \u003ca href=\"/Bracketed/\" class=\"wikilink\"\u003eBracketed\u003c/a\u003e 注意，如果标记中含有空格，将会在链接中被转换为下划线，但在文本中保留原样。举个🌰： [[Wiki Link]] 会转换为： \u003ca href=\"/Wiki_Link/\" class=\"wikilink\"\u003eWiki Link\u003c/a\u003e ","date":"2017-10-29","objectID":"/posts/ac7c7/:18:1","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Usage 默认情况下，链接将会指向域名的根目录，并使用尾部斜线关闭。此外，每个链接都分配了CSS class wikilink。 配置项如下： base_url：添加到URL开头的字符串，默认值/。 end_url：添加到URL末尾的字符串，默认值/。 html_class：CSS类名，留空为None，默认值wikilink。 build_url：可调用对象，用于格式化URL，传入三个参数（label， base，和end），返回URL。 ","date":"2017-10-29","objectID":"/posts/ac7c7/:18:2","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"Examples 使链接始终指向/wiki/的子目录并以.html结尾： \u003e\u003e\u003e from markdown.extensions.wikilinks import WikiLinkExtension \u003e\u003e\u003e html = markdown.markdown(text, ... extensions=[WikiLinkExtension(base_url='/wiki/', end_url='.html')] ... ) 将会使[[WikiLink]]变为： \u003ca href=\"/wiki/WikiLink.html\" class=\"wikilink\"\u003eWikiLink\u003c/a\u003e 如果你想要的不只是改变url的开头和结尾，可以使用build_url： \u003e\u003e\u003e def my_url_builder(label, base, end): ... # do stuff ... return url ... \u003e\u003e\u003e html = markdown.markdown(text, ... extensions=[WikiLinkExtension(build_url=my_url_builder)], ... ) ","date":"2017-10-29","objectID":"/posts/ac7c7/:18:3","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["Python"],"content":"使用Meta-Data扩展 支持使用的meta-data关键字是： wiki_base_url wiki_end_url wiki_html_class 使用时，meta-data将覆盖通过extension_configs提供的设置。 如下的markdown文件： wiki_base_url: http://example.com/ wiki_end_url: .html wiki_html_class: A [[WikiLink]] in the first paragraph. 将会导致以下输出（注意wiki_html_class是空白的）： \u003cp\u003eA \u003ca href=\"http://example.com/WikiLink.html\"\u003eWikiLink\u003c/a\u003e in the first paragraph.\u003c/p\u003e 第三方Extensions 这有个第三方扩展的列表——Third Party Extensions Extension API 放个链接，暂时用不上。https://pythonhosted.org/Markdown/extensions/api.html ","date":"2017-10-29","objectID":"/posts/ac7c7/:18:4","tags":[],"title":"Python-Markdown学习笔记","uri":"/posts/ac7c7/"},{"categories":["工欲善其事"],"content":"简介 ","date":"2017-09-16","objectID":"/posts/38ba7/:0:0","tags":[],"title":"在Ubuntu上使用Conda","uri":"/posts/38ba7/"},{"categories":["工欲善其事"],"content":"Conda Conda is an open source package management system and environment management system that runs on Windows, macOS and Linux. Conda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language. ","date":"2017-09-16","objectID":"/posts/38ba7/:1:0","tags":[],"title":"在Ubuntu上使用Conda","uri":"/posts/38ba7/"},{"categories":["工欲善其事"],"content":"Anaconda A downloadable, free, open source, high-performance and optimized Python and R distribution. Anaconda includes conda, conda build, Python and 100+ automatically installed, open source scientific packages and their dependencies that have been tested to work well together, including SciPy, NumPy and many others. Use the conda install command to easily install 1,000+ popular open source packages for data science—including advanced and scientific analytics—from the Anaconda repository. Use the conda command to install thousands more open source packages. ","date":"2017-09-16","objectID":"/posts/38ba7/:2:0","tags":[],"title":"在Ubuntu上使用Conda","uri":"/posts/38ba7/"},{"categories":["工欲善其事"],"content":"Miniconda Don’t want the huge collection of 720 software packages? Get Miniconda. 安装 首先下载安装脚本： # Python3 64位机 https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh # Python3 32位机 https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86.sh 修改权限并运行： chmod u+x Miniconda3-latest-Linux-x86_64.sh ./Miniconda3-latest-Linux-x86_64.sh 安装完成后在~/.zshrc 中增加： export PATH=\"/root/miniconda3/bin:$PATH\" 配置 # 添加Anaconda的TUNA镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ # 设置搜索时显示通道地址 conda config --set show_channel_urls yes 环境管理 Conda的环境管理功能允许我们同时安装若干不同版本的Python，并自由切换。 创建环境。如果不指定版本，则默认使用安装的py版本： conda create -n py35env python=3.5 查看已安装的环境。当前被激活的环境会有一个*或者()标识。 conda info -e 删除环境： conda remove -n py35env --all 激活环境： source activate py35env 退出环境： source deactivate py35env 包管理 与pip类似。以下操作，不使用-n指定环境时操作到当前环境。 安装package conda install -n py35env numpy 查看已安装的package conda list -n py35env 更新package conda update -n py35env numpy 删除package conda remove -n py35env numpy 查找package信息(不需要也不能指定环境) conda search numpy 卸载 rm -rf ~/miniconda rm -rf ~/.condarc ~/.conda ~/.continuum 删除在.zshrc中增加的export行。 ","date":"2017-09-16","objectID":"/posts/38ba7/:3:0","tags":[],"title":"在Ubuntu上使用Conda","uri":"/posts/38ba7/"},{"categories":["Infrastructure"],"content":"连接数据库 连接本地数据库： mysql -u root -p 连接远程数据库： mysql -h HOSTNAME -u root -p 数据库操作 显示所有数据库： show databases; 建立新数据库，并设置默认编码： create database dbname CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci;; 选择一个数据库： use dbname; 删除数据库： drop database dbname; 用户和权限操作 ","date":"2017-09-08","objectID":"/posts/29275/:0:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"新建用户 create user '[USERNAME]'@'[HOST]' identified by '[PASSWORD]'; ","date":"2017-09-08","objectID":"/posts/29275/:1:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"分配权限 grant all on [DB.TABLES] to '[USERNAME]'@'[HOST]'; ","date":"2017-09-08","objectID":"/posts/29275/:2:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"新建用户并分配权限 grant [PRIVILEGE_LIST] on [DB.TABLES] to '[USERNAME]'@'[HOST]' identified by '[PASSWORD]'; flush privileges; [PRIVILEGE_LIST]：权限列表见官方文档，如果赋予所有权限使用ALL； [DB.TABLE]：如果赋予该用户操作该数据库所有表的权限，table可以使用*代替，数据库也可以用*代替； [HOST]：HOST可以是具体的地址；也可以是localhost，表示只监听本地；或者使用%表示监听所有地址； 举个例子：新建用户aaa，密码为sccc@123，可以从其他所有主机登录，赋予对dbname所有表的CRUD权限： grant insert, delete, update, select on dbname.* to 'aaa'@'%' identified by \"sccc@123\"; flush privileges; ","date":"2017-09-08","objectID":"/posts/29275/:3:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"用户密码管理 更改用户密码： alter user '[USERNAME]'@'[HOST]' identified by '[PASSWORD]'; 更改用户密码过期时间： ALTER USER 'username'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY; ALTER USER 'username'@'localhost' PASSWORD EXPIRE NEVER; ALTER USER 'username'@'localhost' PASSWORD EXPIRE DEFAULT; ","date":"2017-09-08","objectID":"/posts/29275/:4:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"删除用户 DROP USER 'username'@'localhost'; 表操作 ","date":"2017-09-08","objectID":"/posts/29275/:5:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"创建表 CREATE TABLE `topic` ( `token` varchar(10) NOT NULL, `name` varchar(100) NOT NULL, `followers` int(11) NOT NULL, `description` varchar(1000) NOT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; ","date":"2017-09-08","objectID":"/posts/29275/:6:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"修改表 重命名： ALTER TABLE t1 RENAME t2; 修改字段，modify不改变字段名，只修改字段属性；change既可改变字段名，也可修改字段属性； 因此change可以用来重命名字段。 ALTER TABLE t2 MODIFY a TINYINT NOT NULL, CHANGE b c CHAR(20); 增加字段： ALTER TABLE t2 ADD d TIMESTAMP; 删除字段： ALTER TABLE t2 DROP COLUMN c; ","date":"2017-09-08","objectID":"/posts/29275/:7:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"删除表 DROP TABLE t2; 数据（记录）操作 CRUD(Create Read Update Delete)，是软件系统中数据库或者持久层的基本功能操作。 查询： SELECT * FROM t1 WHERE a=3 AND b like '%foo%'; 更新： UPDATE t1 set a=3 where a=4 and b like '%foo%'; 新建： INSERT INTO t1 (`a`, `b`) VALUES (33, 'foo'); 删除： DELETE FROM t1 WHERE a=3 and `b` in (1, 2, 3); 索引操作 ","date":"2017-09-08","objectID":"/posts/29275/:8:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"使用 ALTER 语法 添加索引 ALTER TABLE table_name ADD INDEX index_name (column_list); 添加唯一索引 ALTER TABLE table_name ADD UNIQUE index_name (column_list); 添加主键索引 ALTER TABLE table_name ADD PRIMARY KEY index_name (column_list); ","date":"2017-09-08","objectID":"/posts/29275/:9:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Infrastructure"],"content":"使用 ADD 语法 添加索引 CREATE INDEX index_name ON table_name (column_list); 添加唯一索引 CREATE UNIQUE INDEX index_name ON table_name (column_list); ","date":"2017-09-08","objectID":"/posts/29275/:10:0","tags":[],"title":"MySQL基础操作","uri":"/posts/29275/"},{"categories":["Python"],"content":"Scrapy ","date":"2017-09-03","objectID":"/posts/63928/:0:0","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"Scrapy组件 engine：用来控制整个系统所有组件间的数据流，在特定动作发生时触发事务； spider：分析器，用于解析response，抓取数据，返回items和新的request； downloader：下载器，接收request下载网页内容，并将结果response返回给spider； scheduler：调度器，用来接收request压入队列中，并在引擎再次要求返回时给出request； item pipeline：项目管道，处理spider返回的格式化数据，进行清洗、验证和存储，比如存入数据库等； middleware：中间件，实现定制化功能，比如下载器使用代理池等。 ","date":"2017-09-03","objectID":"/posts/63928/:1:0","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"Scrapy数据流 上图描述了Scrapy框架中数据的流向： Engine从Spider中获得初始Request； Engine把Request放入Scheduler并要求返回下一个Request； Sheduler返回下一个Request给Engine； Engine经过Downloader Middleware把Request发送给Downloader（process_request()）； 网页下载完成后，Downloader生成一个Response，经过Downloader Middleware发送给Engine（process_response()）； Engine接收Response，并经过Spider Middleware把Response发送给Spider（process_spider_input()）； Spider处理Response后，经过Spider Middleware把Items和新的Requests（解析得到）发送给Engine（process_spider_output()）； Engine把Items发送给Item Pipelines，把新的Requests发送给Scheduler并要求返回下一个Requests； 重复以上步骤（从1开始，因为初始Request可能有多个），直到Scheduler中所有的请求都处理完成且没有新请求为止。 ","date":"2017-09-03","objectID":"/posts/63928/:2:0","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"官方推荐使用姿势 官方文档推荐你这样写一个爬虫： 新建一个Scrapy项目； 写爬虫爬取单个网页并抓取数据； 使用命令行导出抓取的数据，检查数据； 把爬虫改为爬取所有链接； 使用spider参数，添加中间件，存储数据等。 ","date":"2017-09-03","objectID":"/posts/63928/:3:0","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"爬取豆瓣电影top250榜单 ","date":"2017-09-03","objectID":"/posts/63928/:4:0","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"新建项目 安装好Scrapy后，可以运行以下命令生成项目的默认结构（使用douban作为项目名）： scrapy startproject douban 下面是scrapy生成的文件树结构： . ├── douban │ ├── __init__.py │ ├── items.py │ ├── middlewares.py │ ├── pipelines.py │ ├── settings.py │ └── spiders │ ├── __init__.py │ └── douban_spider.py └── scrapy.cfg 2 directories, 8 files 各个文件的作用如下： items.py：该文件用于定义待抓取的模型item； middlewares.py：该文件用于定义中间件middleware； pipelines.py：该文件用于定义项目管道item pipeline； settings.py：该文件定义了一些设置，如Headers、用户代理和爬取延时等等。 spiders/：该目录存储实际的爬虫代码。 另外scrapy.cfg定义了项目配置，一般无需修改，除非定义了多个爬虫。 ","date":"2017-09-03","objectID":"/posts/63928/:4:1","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"定义模型 对每条记录，我们爬取四项内容：排名、电影名称、评分、点评人数。 # -*- coding: utf-8 -*- # Define here the models for your scraped items # # See documentation in: # http://doc.scrapy.org/en/latest/topics/items.html import scrapy class DoubanMovieItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() ranking = scrapy.Field() # 排名 movie_name = scrapy.Field() # 电影名称 score = scrapy.Field() # 评分 score_num = scrapy.Field() # 点评人数 ","date":"2017-09-03","objectID":"/posts/63928/:4:2","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"创建爬虫 用户创建的爬虫（Spider）继承自scrapy.Spider类，用于解析网页数据。 可以使用以下命令快速生成Spider： scrapy genspider douban_movie_top250 https://movie.douban.com/top250 以下是几个主要的属性和方法： name：该属性定义了爬虫名称的字符串。名字应该是唯一的，用于区别Spider，应当为不同的Spider设定不同的名字。 start_urls：该属性定义了爬虫起始URL列表。但通过模版生成的URL列表可能与实际需求不一致。 allowed_domains：该属性定义了可以爬取的域名列表。如果没有定义该属性，则表示可以爬取任何域名。 rules：该属性为一个scrapy.spiders.Rule对象集合，用于过滤需要跟踪哪些链接进行下载。该属性还有一个callback参数，用于解析下载得到的response。 start_requests()：该方法也返回可以爬取的域名列表，但可以在方法中做一些处理，应实现为生成器。 parse()：该方法参数为response对象，需要在该方法中解析数据，返回item对象和新的request对象，也应实现为生成器。 代码如下： #!/usr/bin/env python3 # -*- coding: utf-8 -*- from scrapy import Request from scrapy.spiders import Spider from douban.items import DoubanMovieItem class DoubanMovieTop250Spider(Spider): name = 'douban_movie_top250' headers = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36', } def start_requests(self): url = 'https://movie.douban.com/top250' yield Request(url, headers=self.headers) def parse(self, response): item = DoubanMovieItem() movies = response.css('ol.grid_view\u003eli') for movie in movies: item['ranking'] = movie.css('div.pic\u003eem::text').extract()[0] item['movie_name'] = movie.css('div.hd span.title::text').extract()[0] item['score'] = movie.css('div.star\u003espan.rating_num::text').extract()[0] item['score_num'] = movie.css('div.star\u003espan::text').re(r'(\\d+)人评价')[0] yield item next_url = response.css('span.next\u003ea::attr(href)').extract() if next_url: next_url = 'https://movie.douban.com/top250' + next_url[0] yield Request(next_url, headers=self.headers) 关于解析： 可以使用xpath、css选择器和正则表达式解析response对象，也可以组合使用几种解析方式； 使用css选择器时，要取得html标签的文本使用::text，要取得html标签的属性使用::attr(href)（取得href属性）。 ","date":"2017-09-03","objectID":"/posts/63928/:4:3","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"优化设置 在settings.py文件中可以对爬虫进行设置。 CONCURRENT_REQUESTS_PER_DOMAIN：单域名并发数； DOWNLOAD_DELAY：下载延时，但延时并不是精确的，精确延时会造成爬虫更加容易被检测到。 DEFAULT_REQUEST_HEADERS：设置默认的Headers。 ","date":"2017-09-03","objectID":"/posts/63928/:4:4","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"测试爬虫 想要从命令行运行爬虫，需要使用crawl命令，并带上爬虫名称。 scrapy crawl douban_movie_top250 -o result.csv -o选项指定了输出形式，可以选择为json、csv或xml。 如果出现403错误，可能是被反爬虫策略拦截了，可以采用设置UA的形式来绕过。 ","date":"2017-09-03","objectID":"/posts/63928/:4:5","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"其他技巧 ","date":"2017-09-03","objectID":"/posts/63928/:5:0","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"添加中间件 占坑待更。参考https://github.com/amoyiki/LearnedAndProTest/tree/master/douban。 ","date":"2017-09-03","objectID":"/posts/63928/:5:1","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"使用shell命令抓取 为了帮助测试如何从网页中抽取数据，Scrapy提供了shell命令，可以下载URL并在Python解释器中给出结果状态。 scrapy shell https://movie.douban.com/top250 完成后的python解释器界面中，可以直接使用response对象： response.url：抓取链接； response.status：HTTP响应码； response.css()：css选择器； ","date":"2017-09-03","objectID":"/posts/63928/:5:2","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"中断与恢复爬虫 Scrapy内置了对暂停与恢复爬取的支持，要开启该功能，只需要设定用于保存爬虫当前状态目录的JOBDIR即可。需要注意的是，多个爬虫的状态需要保存在不同的目录当中。 scrapy crawl douban_moive_top250 -s JOBDIR=douban/jobdir 另外，要中止爬虫时，首次使用Crtl+C发送终止信号，Scrapy可以保存爬虫状态；但如果再次使用Crtl+C，爬虫会立即强行终止，此时无法恢复。 ","date":"2017-09-03","objectID":"/posts/63928/:5:3","tags":[],"title":"用Python写网络爬虫(6)-Scrapy","uri":"/posts/63928/"},{"categories":["Python"],"content":"验证码处理 验证码（CAPTCHA）的全称为全自动区分计算机和人类的公开图灵测试（Completely Automated Public Turing test to tell Computersand Humans Apart）。验证码用于测试用户是否为真实人类。 自动化处理字符验证码主要有光学字符识别（OCR）和验证码处理API（打码平台）。 ","date":"2017-08-21","objectID":"/posts/55b1c/:0:0","tags":[],"title":"用Python写网络爬虫(5)-验证码处理","uri":"/posts/55b1c/"},{"categories":["Python"],"content":"光学字符识别OCR 通常在对验证码图像进行识别之前，要先对图像进行预处理，以提高识别效率。 预处理主要包括： 将图像阈值化（二值化）； 对图像进行增强，突出字符形状； 调整图像大小； 然后使用开源的Tesseract OCR引擎进行识别，目前该引擎由Google主导。 import pytesseract pytesseract.image_to_string(img) 如果需要进一步改善验证码OCR的性能，可以： 根据验证码字体训练OCR工具； 限制结果为组成验证码的字符（数字、字母等）； ","date":"2017-08-21","objectID":"/posts/55b1c/:1:0","tags":[],"title":"用Python写网络爬虫(5)-验证码处理","uri":"/posts/55b1c/"},{"categories":["Python"],"content":"图像二值化 图像二值化，即是将图像转换为黑白图像。但不能直接使用PIL.Image.convert('1')方法，因为我们二值化的目的是将验证码文字与背景干扰区分开来。 首先将验证码图像转换为灰度图像: from PIL import Image from io import BytesIO img = Image.open(BytesIO(img_bindata)) gray_img = img.convert('L') # 转换为灰度图像 得到图像的灰度直方图： gray_img.histogram() # 得到的是一个list 一般来说，验证码直方图上会有两个峰值，一个是背景干扰，一个是验证码文字，取两峰中间的值作为阈值进行二值化。 table = [0 if i \u003c= 180 else 1 for i in range(256)] bilevel_img = gray_img.point(table, '1') table是转换映射表。此处取阈值为180，灰度低于180的映射为黑色0，灰度高于180的映射为白色。使用point方法进行转换。转换后，验证码图像的背景干扰应该已经被去除了。 ","date":"2017-08-21","objectID":"/posts/55b1c/:1:1","tags":[],"title":"用Python写网络爬虫(5)-验证码处理","uri":"/posts/55b1c/"},{"categories":["Python"],"content":"图像增强 经过二值化的图像，背景干扰可能已经被去除了，但验证码文字可能过胖或有缺失，此时直接进行ocr识别成功率会比较低，可以先进行图像增强，再进行OCR识别。 如果文字过胖，可以对图像进行腐蚀；如果文字缺失，可以干啥来着，我忘了= =；如果图像过小，可以先进行放大。挖坑待更。 ","date":"2017-08-21","objectID":"/posts/55b1c/:1:2","tags":[],"title":"用Python写网络爬虫(5)-验证码处理","uri":"/posts/55b1c/"},{"categories":["Python"],"content":"Tesseract OCR识别 import pytesseract pytesseract.image_to_string(bilevel_img, lang='eng', config='-psm 13') lang可以指定识别文字的语言，默认为英文；config默认为-psm 3，调整成不同值会有不同的效果，具体参见 tesseract命令行参数帮助。 ","date":"2017-08-21","objectID":"/posts/55b1c/:1:3","tags":[],"title":"用Python写网络爬虫(5)-验证码处理","uri":"/posts/55b1c/"},{"categories":["Python"],"content":"使用打码平台 将验证码提交给打码平台API，打码平台通过人工查看，在HTTP响应中给出解析后的文本，一般来讲该过程在30秒内。但是打码平台一般属于黑产，谨慎使用为妙。 国外有一网站9kw，允许用户人工处理验证码以获取积分，然后花费积分处理自己的验证码。不用花钱哟！但是其只会返回普通字符串，且返回时间取决于当时在线的人数，不是很稳定。 ","date":"2017-08-21","objectID":"/posts/55b1c/:2:0","tags":[],"title":"用Python写网络爬虫(5)-验证码处理","uri":"/posts/55b1c/"},{"categories":["Python"],"content":"动态内容 ","date":"2017-08-20","objectID":"/posts/e5f60/:0:0","tags":[],"title":"用Python写网络爬虫(4)-动态内容和表单交互","uri":"/posts/e5f60/"},{"categories":["Python"],"content":"逆向动态网页 依赖于AJAX的网站虽然看起来更加复杂，但是其结构促使数据和表现层分离，因此抽取数据时会更加容易。 通过网络请求抓包工具，查看AJAX请求，分析其模式，使用requests库模仿其请求模式，获得内容。一般来讲返回的都是xml或者json等序列化的数据，十分方便。 ","date":"2017-08-20","objectID":"/posts/e5f60/:1:0","tags":[],"title":"用Python写网络爬虫(4)-动态内容和表单交互","uri":"/posts/e5f60/"},{"categories":["Python"],"content":"渲染动态网页 使用浏览器引擎渲染解析HTML、应用CSS样式并执行JavaScript语句，再从HTML中得到内容。 可以使用Selenium+PhantomJS配合在命令行中实现。 这里只演示selenium的用法(Chrome需要相应的驱动文件)： from selenium import webdriver # 这里可以换成PhantomJS driver = webdriver.Chrome() driver.get('http://example.webscraping.com/search') # 填写表单内容 driver.find_element_by_id('search_term').send_keys('.') # 使用JS直接设置表单内容，突破前端限制 js = \"document.getElementById('page_size').options[1].text='1000'\" driver.execute_script(js) # 模拟点击按钮，提交表单 driver.find_element_by_id('search').click() # 至多等待30s，如果查询的元素没有出现，就抛出异常 driver.implicitly_wait(30) links = dirver.find_elements_by_css_selector('#results a') countries = [link.text for link in links] ","date":"2017-08-20","objectID":"/posts/e5f60/:2:0","tags":[],"title":"用Python写网络爬虫(4)-动态内容和表单交互","uri":"/posts/e5f60/"},{"categories":["Python"],"content":"如何选择动态网页抓取方式 浏览器渲染引擎帮助我们节省了了解网站后端工作原理的时间，但是该方法也有其劣势。渲染网页增加了开销，使其比单纯下载HTML更慢。另外，通常需要轮询网页来检查是否已经得到时间生成的HTML，这种方式非常脆弱，在网络较慢时经常会失败。 一般将浏览器引擎作为短期解决方案，此时长期的性能和可靠性并不算重要；而作为长期解决方案，应该尽最大努力对网站进行逆向工程。 表单交互 ","date":"2017-08-20","objectID":"/posts/e5f60/:3:0","tags":[],"title":"用Python写网络爬虫(4)-动态内容和表单交互","uri":"/posts/e5f60/"},{"categories":["Python"],"content":"表单简介 form表单的几个重要设置： action属性用于设置表单数据提交的地址，如果设置为#表示和登录表单相同的URL； enctype属性用于设置数据提交的编码，例如application/x-www-form-urlencoded； method属性用于设置HTTP请求方法。 input标签的重要属性是name，用于设定提交到服务器端时某个域的名称。 表单**使用POST方法时，默认编码类型为application/x-www-form-urlencoded，**此时所有非字母数字类型的字符都需要转换为十六进制的ASCII值。但是，如果表单中包含大量非字母数字类型的字符时，**如上传二进制文件，这种编码类型的效率就会非常低，此时需要指定编码类型为multipart/form-data。**使用这种编码类型时，不会对输入进行编码，而是使用MIME协议将其作为多个部分进行发送，和邮件的传输标准相同。 ","date":"2017-08-20","objectID":"/posts/e5f60/:4:0","tags":[],"title":"用Python写网络爬虫(4)-动态内容和表单交互","uri":"/posts/e5f60/"},{"categories":["Python"],"content":"提交表单 注意提交隐藏域和cookie，同时保持cookie和隐藏域中某些参数的一致。 也可以从浏览器中获取cookie，但是个人并不建议这样做，原因如下： 不同的操作系统不同浏览器cookie保存位置不一样，且可能会随浏览器发布新版本而改变； 可以用代码请求然后将cookie持久化存储，下次请求时先使用已保存的cookie，不行再重新请求，代码实现并不复杂，而且可以跨平台使用； ","date":"2017-08-20","objectID":"/posts/e5f60/:5:0","tags":[],"title":"用Python写网络爬虫(4)-动态内容和表单交互","uri":"/posts/e5f60/"},{"categories":["Python"],"content":"使用Mechanize模块实现自动化表单处理 Mechanize只支持Python2.x版本，GG。 ","date":"2017-08-20","objectID":"/posts/e5f60/:6:0","tags":[],"title":"用Python写网络爬虫(4)-动态内容和表单交互","uri":"/posts/e5f60/"},{"categories":["Python"],"content":"由于并发下载实在没有啥写的东西，不如就合并到这一节吧。 下载缓存 当需要抓取的数据发生变化时，我们需要重新下载整个网站。对于大型网站而言，重新抓取可能需要耗费几个星期的时间。一种可行的方式是对已爬取网页进行缓存的方案，可以让每个网页之下载一次。 ","date":"2017-08-19","objectID":"/posts/4d744/:0:0","tags":[],"title":"用Python写网络爬虫(3)-下载缓存和并发下载","uri":"/posts/4d744/"},{"categories":["Python"],"content":"添加缓存支持 使用回调添加缓存支持后，下载的流程是这样的： 接收一个新的URL； 该URL是否已被缓存； 如果已经缓存，检查： 之前的下载时是否发生5xx错误； 缓存是否已经过期失效； 如果缓存可用返回缓存内容； 否则，进行限速检测，然后下载； 新下载内容和状态码写入缓存，或更新缓存。 ","date":"2017-08-19","objectID":"/posts/4d744/:1:0","tags":[],"title":"用Python写网络爬虫(3)-下载缓存和并发下载","uri":"/posts/4d744/"},{"categories":["Python"],"content":"磁盘缓存 将下载到的网页按照URL的路径存储到文件系统中。 需要对URL进行安全映射，屏蔽掉非法的文件名字符； 不能超过文件系统对文件名最大长度的限制； URL路径可能会以/结尾，此时/后面的空字符串就会成为一个非法的文件名。但是如果移除这个/，使用父字符串作为文件名，又会造成无法保存其他URL的问题。 DiskCache类需要实现以下几个方法： __init__(self, cache_dir='cache')：初始化，设定缓存目录，设定过期时间； url_to_path(self, url)：URL到文件路径的转换方法； __getitem__(self, url)：根据URL获取缓存； __setitem__(self, url, result)：存储缓存。 为了节约磁盘空间，可以使用zlib模块对序列化字符串逆行压缩。 **缺点：**受制于本地文件系统的限制。包括：文件名使用的字符、文件名长度、每个目录的最大文件数和文件系统可存储的文件总数等。 ","date":"2017-08-19","objectID":"/posts/4d744/:2:0","tags":[],"title":"用Python写网络爬虫(3)-下载缓存和并发下载","uri":"/posts/4d744/"},{"categories":["Python"],"content":"数据库缓存 爬取时，我们可能需要缓存大量的数据，而又无须任何复杂的连接操作，因为我们将选用NoSQL数据库，这种数据库比传统的SQL数据库更容易扩展。 MongoDB是一个面向文档的数据库，非常适合存储网页文件。MongoDB中的键值可以重复，当使用insert插入时，若使用了同一个键值，将会产生多条记录。避免重复的方式是使用upsert，若键值已经存在则会更新记录，而不是插入新的纪录。 MongoCache类同样要实现__getitem__和__setitem__方法，同时在构造方法中，我们创建了timestamp索引。在达到给定时间戳一定秒数之后，MongoDB便可以自动删除记录。 不过，MongoDB缓存无法按照给定时间精确清理过期记录，会存在至多一分钟的延迟，这是由MongoDB的运行机制造成的——MongoDB运行了一个后台任务每分钟会检查一次过期记录。一般来说，由于缓存过期时间通常设定为几周或几个月，所以这个相对较小的延时不会存在太大问题。 并发下载 多线程+多进程，可以显著提升效率。但提升不是无限的，因为线程越多，线程间切换的时间也越长。 爬虫网络请求是IO阻塞的，因此使用多线程能提高效率。若是CPU计算阻塞的，则只有多进程+多核CPU才能提升效率。 ","date":"2017-08-19","objectID":"/posts/4d744/:3:0","tags":[],"title":"用Python写网络爬虫(3)-下载缓存和并发下载","uri":"/posts/4d744/"},{"categories":["Web 开发"],"content":"传统的方法 在按钮的点击事件函数中，在新标签页中打开下载链接。 window.open('/download/exportdata'); 会打开一个空白页面，然后消失，用户体验不太好。 优雅的用户体验 ","date":"2017-08-16","objectID":"/posts/902dd/:0:0","tags":[],"title":"在当前窗口中直接下载文件的几种方法","uri":"/posts/902dd/"},{"categories":["Web 开发"],"content":"JS构造form后提交 var $form = $('\u003cform method=\"GET\"\u003e\u003c/form\u003e'); $form.attr('action', '/download/exportdata'); $form.appendTo($('body')); $form.submit(); ","date":"2017-08-16","objectID":"/posts/902dd/:1:0","tags":[],"title":"在当前窗口中直接下载文件的几种方法","uri":"/posts/902dd/"},{"categories":["Web 开发"],"content":"JS构造iframe var iframe = document.createElement(\"iframe\"); iframe.style.display = \"none\"; iframe.src = '/download/exportdata'; document.body.appendChild(iframe); ","date":"2017-08-16","objectID":"/posts/902dd/:2:0","tags":[],"title":"在当前窗口中直接下载文件的几种方法","uri":"/posts/902dd/"},{"categories":["Web 开发"],"content":"页面中使用含有download属性的a标签 \u003ca href=\"/download/exportdata\" download=\"xxx.csv\"\u003edownload\u003c/a\u003e ","date":"2017-08-16","objectID":"/posts/902dd/:3:0","tags":[],"title":"在当前窗口中直接下载文件的几种方法","uri":"/posts/902dd/"},{"categories":["Python"],"content":"数据抓取 从网页中抽取数据用于后续处理，这种做法称为抓取（scraping）。 ","date":"2017-08-16","objectID":"/posts/63476/:0:0","tags":[],"title":"用Python写网络爬虫(2)-数据抓取","uri":"/posts/63476/"},{"categories":["Python"],"content":"正则表达式 优点：能够简短地把需要的数据抓取出来。在一次性数据抓取中非常有用，此外还可以避免解析整个网页带来的开销； 缺点：网页更新后易失效，健壮的正则表达式又存在难以构造、可读性差的问题。 ","date":"2017-08-16","objectID":"/posts/63476/:1:0","tags":[],"title":"用Python写网络爬虫(2)-数据抓取","uri":"/posts/63476/"},{"categories":["Python"],"content":"Beautifulsoup 漂亮汤是一个非常流行的Python模块。该模块可以解析网页，并提供定位内容的便捷接口。 可以正确解析缺失的引号并闭合标签(html.parser)； 可以使用正则表达式; 可以使用css选择器； 可以使用lxml作为解析器（谁还说我慢！）； 注意：查询得到的对象并不是字符串，而是bs4库的element对象。 ","date":"2017-08-16","objectID":"/posts/63476/:2:0","tags":[],"title":"用Python写网络爬虫(2)-数据抓取","uri":"/posts/63476/"},{"categories":["Python"],"content":"Lxml 使用C语言编写，就是快，不过安装比较麻烦。 可以正确解析缺失的引号并闭合标签(html.parser)； 可以使用XPath选择器； 可以使用CSS选择器； ","date":"2017-08-16","objectID":"/posts/63476/:3:0","tags":[],"title":"用Python写网络爬虫(2)-数据抓取","uri":"/posts/63476/"},{"categories":["Python"],"content":"为链接爬虫添加抓取回调 为爬虫函数添加一个callback参数处理抓取行为。 def crawler(..., scrape_callback=None): ... links = [] if scrape_callback: # 利用抓取到的内容更新url列表 links.extend(scrape_callback(url, html) or []) 使用类的魔术方法__call__()来构造回调类，回调类的对象是可执行的。（是否可执行使用内置函数callable()来判断。下面是一个抓取网站/view/xxx下的信息，并保存到csv文件中的示例： import csv import re class ScrapeCallback: def __init__(self): self.writer = csv.writer(open('countries.csv', 'w')) self.fields = ('area', 'population', 'iso', 'country', ...) self.writer.writerow(self.fields) def __call__(self, url, html): if re.search('/view/', url): tree = lxml.html.fromstring(html) row = [] for field in self.fields: row.append(tree.cssselect('table \u003e tr#places_{}__row \u003e td.w2p_fw'.format(field))[0].text_content()) self.writer.writerow(row) 向链接爬虫传入回调： crawler('http://example.webscraping.com/', '/(index|view)', max_depth=-1, scrape_callback=ScrapeCallback()) ","date":"2017-08-16","objectID":"/posts/63476/:4:0","tags":[],"title":"用Python写网络爬虫(2)-数据抓取","uri":"/posts/63476/"},{"categories":["Infrastructure"],"content":"crontab命令格式和参数 crontab [ -u user ] [ -i ] { -e | -l | -r } -e (edit user's crontab)编辑某个用户的crontab文件内容 -l (list user's crontab)显示某个用户的crontab文件内容 -r (delete user's crontab)删除某个用户的crontab文件内容 -i (prompt before deleting user's crontab)与-r配合，删除前提示 crontab的文件格式 分钟 小时 日 月 星期 要运行的命令 第1列分钟1～59 第2列小时1～23（0表示子夜） 第3列日1～31 第4列月1～12 第5列星期0～6（0表示星期天） 第6列要运行的命令 创建一个新任务 crontab -e打开编辑器对crontab文件进行编辑； 在文件中添加新的一行并保存： # 每分钟打印当前时间到1.log中 * * * * * date \u003e\u003e 1.log 使用 crontab -l 查看文件内容，发现该定时任务已被写入。任务应该可以正常执行了。 注意事项 ","date":"2017-08-16","objectID":"/posts/aef23/:0:0","tags":[],"title":"Linux定时任务crontab设置方法","uri":"/posts/aef23/"},{"categories":["Infrastructure"],"content":"执行环境变量 如果是执行自己写的脚本或者程序，要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。 有时我们创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。因为我们手动执行某个任务时，是在当前shell环境下进行的，程序当然能找到环境变量；而系统自动执行任务调度时，跟shell所在环境不同，许多环境变量需要手动设置。 解决方案： 脚本中涉及文件路径时写全局路径； 脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如: !/bin/sh source /etc/profile export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf 当手动执行脚本OK，但是crontab死活不执行时,很可能是环境变量惹的祸，可尝试在crontab中直接引入环境变量解决问题。如: 0 * * * * . /etc/profile;/bin/sh /home/pi/myscripts.sh ","date":"2017-08-16","objectID":"/posts/aef23/:1:0","tags":[],"title":"Linux定时任务crontab设置方法","uri":"/posts/aef23/"},{"categories":["Infrastructure"],"content":"用户邮件日志 每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。 例如，可以在crontab文件中设置如下形式，忽略日志输出: 0 */3 * * * /usr/local/apache2/apachectl restart \u003e/dev/null 2\u003e\u00261 “/dev/null 2\u003e\u00261” 表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。 系统级任务调度与用户级任务调度 系统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么做），但是反过来却不行，root用户的任务调度操作可以通过crontab –u root –e来设置，也可以将调度任务直接写入/etc/crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个定时重启系统的任务也是无效的。 常见使用实例 每隔两天的上午8点到11点的第3和第15分钟执行 3,15 8-11 */2 * * myCommand 每周一上午8点到11点的第3和第15分钟执行 3,15 8-11 * * 1 myCommand 每晚的21:30执行 30 21 * * * myCommand 每小时执行 */60 * * * * myCommand 0 * * * * myCommand ","date":"2017-08-16","objectID":"/posts/aef23/:2:0","tags":[],"title":"Linux定时任务crontab设置方法","uri":"/posts/aef23/"},{"categories":["Infrastructure"],"content":"其他 打开/关闭/重启crontab服务： service cron start/stop/restart /etc/init.d/cron start/stop/restart 当crontab失效时，可以尝试重启crontab服务。 在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义%。 更新系统时间时区后需要重启cron。 ","date":"2017-08-16","objectID":"/posts/aef23/:3:0","tags":[],"title":"Linux定时任务crontab设置方法","uri":"/posts/aef23/"},{"categories":["工欲善其事"],"content":" git branch -av 显示所有本地即远程分支，并显示最后提交的 Commit 信息。如果不加参数，则只会显示所有本地分支的名字。 git checkout -b \u003cNAME\u003e [\u003cSTART POINT\u003e] 创建，并切换到新分支。git branch \u003cNAME\u003e 只会创建分支而不会切换到新分支，可以用它备份当前分支。 git tag -L \u003cPATTERN\u003e 列出所有符合条件的标签。如果你的项目严格按照 Major.Minor.Update 作为版本名称，那么这条命令就非常有用。它可以直接列出来当前版本下有那些小的 bugfix 版本。当然如果你非要 grep 一下我也没意见。 git diff -w 显示未提交的更改，忽略空格。人们往往注重实际代码的改变而不注重缩进的变化。如果某个文件有大量缩进改变，-w 这个参数就非常有用。 git commit --amend 修补前一次提交。相当于撤销前一次提交，做更改后重新提交。这也是一条非常实用的命令。当你发现前一次提交有一些小问题的时候（比如说漏提交了新创建的文件，或者有一些小的拼写错误），可以用这条命令修正前一次提交。它对 merge 提交友好，而且可以用于修正前一次提交的 message 信息。需要注意的是：如果你已经推送了前一次提交，amend 之后需要强推，这一点需要注意。 git log --graph --oneline --no-merge 显示当前仓库的提交历史。git log 大家都用过，但真正研究过 git log 后面参数的人可能就不多。git log 后面可以接很多实用的参数，示例中的让提交历史以单行模式显示、显示提交历史树并删除 merge 提交。 git log -p --follow --stat -- \u003cPATH\u003e 显示某个文件的提交历史。在 git 中，-- 后接文件路径就代表对单个文件的操作。-p 可以显示具体修改的行，--follow可以跟踪文件的移动和重命名，--stat 用于显示添加、删除行的数量。 git config --global alias.xx \"\u003cCOMMAND\u003e\" 给某 git 命令创建别名。对于一些比较长的命令，可以创建别名。以后只需要 git xx 即可执行 COMMAND 这条命令 git pull --rebase, --rebase 可以简写为 -r 使用 git rebase 代替 git merge 执行 pull 操作。git pull --rebase 可以构造出非常整齐的提交历史树，强迫症的福利。git 的官方文档一再提醒这是个危险操作，因为它会修改你的代码提交历史。git rebase 的本质是撤销指定的提交，然后以指定的方式重新提交他们。git pull -r 就相当于首先撤销没有推送到远端的 commit，将远程代码覆盖到本地之后，重新提交所有之前撤销的 commit。与 git merge 不同，当有冲突产生时，git rebase 不会为你的 merge 操作生成一个新的提交。所以一旦 git pull --rebase 执行完毕就无法撤销。 git config --global pull.rebase true 默认使用 git rebase 代替 git merge 执行 pull 操作。git 提供了一系列配置 git pull --rebase 操作：branch.\u003cBRANCH NAME\u003e.rebase、branch.autosetuprebase。这条是最简单的全局配置项。尽管配置了默认使用 rebase，你可以使用 --merge 开关强制使用 git merge 执行 git pull。 git rebase -i 交互式变基操作。git 中最强大的修改提交历史的操作，当然也是最危险的操作。它可以让你修改 commit 说明、让几个 commit 合并、交换 commit、删除 commit，甚至在提交某 commit 前执行一段 shell 命令。非常有用、非常强大、同时也是极其危险的操作。强烈建议在执行 git rebase -i 之前先使用 git branch 备份当前分支。 git push \u003cremote\u003e [\u003ccommit\u003e]:\u003cbranch\u003e 推送指定的 commit 到远程。有时候你某个工作做到一半，然后来了一个bug要修。当然最好的做法是基于最新的远端分支新开一个分支，基于这个分支开发。但是如果你忘了新开分支，直接把代码提交到了当前分支怎么办？在你需要 push 的分支之前又有别的不需要的 commit。这时就可以先用 git rebase 交换 commit 的顺序，然后推送单个提交。如果你写了冒号但是不写 commit 号，就会变成删除某个远端分支。这是完全不同的而且可能有危险操作，需要注意。 git blame \u003cPATH\u003e [-L \u003cM,N\u003e] 逐行检查某文件的提交人、提交时间和 commit 号。blame 的中文意思是职责，大家顾名思义，撕逼甩锅时用。 -L 可以指定要检查的行号。 git stash [push] [-u] 贮存当前工作区的更改。经常有这样的事情发生，当你正在进行项目中某一部分的工作，里面的东西处于一个比较杂乱的状态，而你想转到其他分支上进行一些工作。问题是你还不想提交这些代码，这是就可以用 git stash 命令将未提交的更改临时保存到一个贮存项中。-u 表示将未加入版本管理的文件也保存（比如新建的一些文件） git stash apply \u003cINDEX\u003e、git stash pop \u003cINDEX\u003e 将最后一次保存的（或指定的某个）贮存项应用至当前工作区。与前面的 git stash [push] 配套使用。 apply 与 pop 的区别是：pop 会在应用更改的同时把所应用的贮存项删除，而 apply 不会。 git cherry-pick -x \u003cCOMMIT\u003e.. 摘取 某些提交。即把另一个本地分支的 commit 应用到当前分支。如果我们同时维护多个分支，这个操作就很有用。比如说你在主干 master 分支上修复了一个 bug，然后你想把这个修复应用到一个旧版本的分支上，但是你又不想把其他 master 分支的新功能拉进来，这时就可以用 cherry-pick。-x：在提交记录中添加一行 (cherry picked from commit \u003ccommit\u003e)，让两个提交关联起来。 git revert \u003cCOMMIT\u003e 回滚某个提交。即提交某个 COMMIT 的反提交。最快修复某个 bug 的方式就是把引入 bug 的代码干掉。注意干掉代码不代表就要用 git rebase -i 把提交本身也干掉。 git grep \u003cPATTERN\u003e 在当前加入版本管理的文件中全文检索某字符串。类似于 grep 操作，但是会忽略不需要的（加入 .gitignore 的）文件，非常实用的命令。 git bisect 实用二分查找的方式定位引入问题的提交。快速定位 bug 的方式。在找不到 bug 出现的原因时，不妨用 git bisect 将 bug 先锁定到某个 commit 上。 git push —delete origin auth 删除远端origin的auth分支。 ","date":"2017-08-16","objectID":"/posts/9d5d8/:0:0","tags":[],"title":"常用git命令","uri":"/posts/9d5d8/"},{"categories":["Python"],"content":"Python变量和数据类型 ","date":"2017-08-16","objectID":"/posts/5aab7/:0:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"数据类型 整数和浮点数：在计算机内部存储的方式是不同的，整数运算永远是精确的（除法也是精确的），而浮点数运算则可能会有四舍五入的误差； 布尔值：用True、False表示（注意大小写）； 空值：用None表示，None不能理解为0，因为0是有意义的，而None是一个特殊的空值。 ","date":"2017-08-16","objectID":"/posts/5aab7/:1:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"Print语句 print语句也可以跟上多个字符串，用逗号“,”隔开，print会依次打印每个字符串。每个逗号“,”会输出一个空格。 ","date":"2017-08-16","objectID":"/posts/5aab7/:2:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"注释 Python的注释以#开头，后面的文字直到行尾都算注释。 ","date":"2017-08-16","objectID":"/posts/5aab7/:3:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"变量 变量名必须是大小写英文、数字和_的组合，且不能用数字开头； 动态语言：变量本身类型不固定的语言，例如Python； 常量：在Python中，通常用全部大写的变量名表示常量，但事实上仍然是一个变量； ","date":"2017-08-16","objectID":"/posts/5aab7/:4:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"定义字符串 字符串可以用'...'或者\"...\"括起来表示。 如果字符串本身包含'，可以用\"...\"括起来表示； 如果字符串本身包含\"，可以用'...'括起来表示； 如果字符串既包含'又包含\"，使用转义字符\\。 注意：Python区分大小写！ ","date":"2017-08-16","objectID":"/posts/5aab7/:5:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"raw字符串和多行字符串 ","date":"2017-08-16","objectID":"/posts/5aab7/:6:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"raw字符串 在字符串前面加个前缀r， 表示这是一个raw字符串，里面的字符就不需要转义。例如： \u003e\u003e\u003eprint(r'\\n\\t\\\\') \\n\\t\\\\ ","date":"2017-08-16","objectID":"/posts/5aab7/:6:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"多行字符串 多行字符串，可以用'''...'''表示： '''Line1 Line2 Line3''' 上面这个字符串的表示方法和下面的是完全一样的： 'Line 1\\nLine 2\\nLine 3' 注：还可以在多行字符串前面添加r，把这个多行字符串也变成一个raw字符串： r'''Python is created by \"Guido\". It is free and easy to learn. Let's start learn Python in imooc!''' ","date":"2017-08-16","objectID":"/posts/5aab7/:6:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"字符串编码 ","date":"2017-08-16","objectID":"/posts/5aab7/:7:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"几种常见的编码 GB2312：国标简体中文编码； GBK：GBK是包括中日韩字符的大字符集合，GB2312是GBK的子集； Unicode：Unicode把所有语言都统一到一套编码里； UTF-8：UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，是可变长编码； 默认情况下，Python3源码文件中使用UTF-8编码，在内存中使用Unicode编码，即Python3中的字符串是Unicode编码的。 ","date":"2017-08-16","objectID":"/posts/5aab7/:7:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"Unicode编码与其他编码的转换 Unicode编码转换成其他编码时，使用encode方法，参数值为要转换成的编码类型： \u003e\u003e\u003e '中文'.encode('gb2312') b'\\xd6\\xd0\\xce\\xc4' \u003e\u003e\u003e '中文'.encode('utf-8') b'\\xe4\\xb8\\xad\\xe6\\x96\\x87' 其他编码转换成Unicode编码时，使用decode方法，参数值为原编码类型： \u003e\u003e\u003e b'\\xe4\\xb8\\xad\\xe6\\x96\\x87'.decode('utf-8') '中文' \u003e\u003e\u003e b'\\xe4\\xb8\\xad\\xe6\\x96\\x87'.decode('gb2312') Traceback (most recent call last): File \"\u003cpyshell#96\u003e\", line 1, in \u003cmodule\u003e b'\\xe4\\xb8\\xad\\xe6\\x96\\x87'.decode('gb2312') UnicodeDecodeError: 'gb2312' codec can't decode byte 0xad in position 2: illegal multibyte sequence ","date":"2017-08-16","objectID":"/posts/5aab7/:7:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"数据类型 python中数有四种类型：整数、长整数、浮点数和复数。 整数：如1, 二进制0b1001, 十六进制0x2E； 长整数：是比较大的整数； 浮点数：如1.23、3E-2； 复数：如1+2j、1.1+2.2j； ","date":"2017-08-16","objectID":"/posts/5aab7/:8:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"布尔类型 Python把0、None、空字符串、空list、空tuple、空dict和空set看成False，其他数值和非空数据类型都看成True。 and 和 or 运算的重要法则——短路计算 在计算a and b时，如果 a 是 False，则根据与运算法则，整个结果必定为 False，因此返回 a；如果 a 是 True，则整个计算结果必定取决与 b，因此返回 b； 在计算a or b时，如果 a 是 True，则根据或运算法则，整个计算结果必定为 True，因此返回 a；如果 a 是 False，则整个计算结果必定取决于 b，因此返回 b。 注：利用这一点，可以通过 or 运算，把空字符串“变成”默认字符串，而非空字符串保持不变。 List和Tuple类型 ","date":"2017-08-16","objectID":"/posts/5aab7/:9:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"List ","date":"2017-08-16","objectID":"/posts/5aab7/:10:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"创建list list是一种有序的列表，可以随时添加和删除其中的元素。用 [ ] 把list的所有元素括起来就构造了一个list对象。list中包含的元素可以是不同种数据类型。一个元素也没有的list是空list。list中元素可重复。 ","date":"2017-08-16","objectID":"/posts/5aab7/:10:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"按照索引访问list 索引从 0 开始，格式为L[0]； 使用索引时，千万注意不要越界，否则报错IndexError。 ","date":"2017-08-16","objectID":"/posts/5aab7/:10:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"倒序访问list 用 -1 这个索引来表示最后一个元素，即L[-1]；类似的，倒数第二用 -2 表示，倒数第三用 -3 表示。 使用倒序索引时，也要注意不要越界，否则同样报错IndexError。 ","date":"2017-08-16","objectID":"/posts/5aab7/:10:3","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"添加新元素 用 list 的append()方法把新元素添加到 list 的尾部； \u003e\u003e\u003e L = ['Adam', 'Lisa', 'Bart'] \u003e\u003e\u003e L.append('Paul') \u003e\u003e\u003e print(L) ['Adam', 'Lisa', 'Bart', 'Paul'] 用list的insert()方法把新元素添加到除尾部的其他位置，它有两个参数，第一个参数是索引位置，第二个参数是待添加的新元素； \u003e\u003e\u003e L = ['Adam', 'Lisa', 'Bart'] \u003e\u003e\u003e L.insert(0, 'Paul') \u003e\u003e\u003e print(L) ['Paul', 'Adam', 'Lisa', 'Bart'] 注意：使用insert()方法，，可以认为是插入到了索引位置的前面。使用倒序索引时注意： \u003e\u003e\u003e L = [1, 2, 4] \u003e\u003e\u003e L.insert(-1, 3) \u003e\u003e\u003e print(L) [1, 2, 3, 4] #元素插入到了倒序索引位置为-1的前面 ","date":"2017-08-16","objectID":"/posts/5aab7/:10:4","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"从list删除元素 用list的pop()方法删掉list的末尾元素，返回值是被删掉的元素； \u003e\u003e\u003e L = ['Adam', 'Lisa', 'Bart', 'Paul'] \u003e\u003e\u003e L.pop() 'Paul' \u003e\u003e\u003e print(L) ['Adam', 'Lisa', 'Bart'] 用list的pop(x)方法删掉list的任意位置元素，参数x为索引（可倒序索引），返回值是被删掉的元素； \u003e\u003e\u003e L = ['Adam', 'Lisa', 'Paul', 'Bart'] \u003e\u003e\u003e L.pop(-2) 'Paul' \u003e\u003e\u003e print(L) ['Adam', 'Lisa', 'Bart'] ","date":"2017-08-16","objectID":"/posts/5aab7/:10:5","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"替换元素 对list中的某一个索引（可倒序索引）赋值，就可以直接用新的元素替换掉原来的元素，list包含的元素个数保持不变。 \u003e\u003e\u003e L = ['Adam', 'Lisa', 'Bart'] \u003e\u003e\u003e L[-1] = 'Paul' \u003e\u003e\u003e print(L) L = ['Adam', 'Lisa', 'Paul'] ","date":"2017-08-16","objectID":"/posts/5aab7/:10:6","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"Tuple ","date":"2017-08-16","objectID":"/posts/5aab7/:11:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"创建tuple tuple是另一种有序的列表，中文翻译为“元组”。创建tuple使用()。tuple一旦创建完毕就不能修改。tuple没有append()方法，也没有insert()和pop()方法。可以使用索引方式访问元素，但是不能对其中的元素赋值。 ","date":"2017-08-16","objectID":"/posts/5aab7/:11:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"创建单元素tuple 包含 0 个元素的 tuple，也就是空tuple，直接用 ()表示，即t = ()； 因为()既可以表示tuple，又可以作为括号表示运算时的优先级，用()定义单元素的tuple有歧义。所以 Python 规定，单元素 tuple 要多加一个逗号“,”避免歧义： \u003e\u003e\u003e t = (1,) \u003e\u003e\u003e print(t) (1,) ","date":"2017-08-16","objectID":"/posts/5aab7/:11:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"“可变”的tuple tuple所谓的“不变”是说，tuple的每个元素，指向永远不变，即指向’a’，就不能改成指向’b’。指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！ \u003e\u003e\u003e t = ('a', 'b', ['A', 'B']) \u003e\u003e\u003e L = t[2] \u003e\u003e\u003e L[0] = 'X' \u003e\u003e\u003e print(t) ('a', 'b', ['X', 'B']) 条件判断和循环 Python代码的缩进规则： 具有相同缩进的代码被视为代码块。 缩进为4个空格，不要使用Tab，更不要混合Tab和空格，否则很容易造成因为缩进引起的语法错误。 ","date":"2017-08-16","objectID":"/posts/5aab7/:11:3","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"条件判断语句 ","date":"2017-08-16","objectID":"/posts/5aab7/:12:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"if语句 if 语句后接条件表达式，然后用:表示代码块开始。 ","date":"2017-08-16","objectID":"/posts/5aab7/:12:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"if-else 如果条件判断是**“非此即彼”**的，即要么符合条件1，要么符合条件2，可以用一个if ... else ...语句把它们统一起来。根据条件表达式的值为 True 或者 False ，分别执行 if 代码块或者 else 代码块。**注意else后面有个“:”**。 ","date":"2017-08-16","objectID":"/posts/5aab7/:12:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"if-elif-else if \u003c条件判断1\u003e: \u003c执行1\u003e elif \u003c条件判断2\u003e: \u003c执行2\u003e elif \u003c条件判断3\u003e: \u003c执行3\u003e else: \u003c执行4\u003e 注意：这一系列条件判断会从上到下依次判断，如果某个判断为 True，执行完对应的代码块，后面的条件判断就直接忽略，不再执行了。 ","date":"2017-08-16","objectID":"/posts/5aab7/:12:3","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"循环 ","date":"2017-08-16","objectID":"/posts/5aab7/:13:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"for…in循环 \u0026 range()函数 names = ['Michael', 'Bob', 'Tracy'] #names也可以是tuple类型 for name in names: print(name) name 这个变量是在 for 循环中定义的，意思是，依次取出list中的每一个元素，并把元素赋值给 name，然后执行for循环体（就是缩进的代码块）。 range(x)函数生成一个整数序列list，元素是从0开始到x-1的整数。例如求1-100的整数和： sum = 0 for x in range(101): sum = sum + x print(sum) ","date":"2017-08-16","objectID":"/posts/5aab7/:13:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"while循环 while 循环不会迭代 list 或 tuple 的元素，而是根据表达式判断循环是否结束。while循环每次先判断条件表达式，如果为True，则执行循环体的代码块，否则，退出循环。 while \u003c条件判断\u003e: \u003c执行\u003e 注意：要特别留意while循环的退出条件。 ","date":"2017-08-16","objectID":"/posts/5aab7/:13:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"break退出循环 用 for 循环或者 while 循环时，如果要在循环体内直接退出循环，可以使用 break 语句。break语句生效时，其后面的循环体语句将不会执行。 ","date":"2017-08-16","objectID":"/posts/5aab7/:13:3","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"continue继续循环 在循环过程中，可以用continue跳过后续循环代码，结束本次循环，继续下一次循环。continue语句生效时，其后面的循环体语句将不会执行。 ","date":"2017-08-16","objectID":"/posts/5aab7/:13:4","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"多重循环 在循环内部，还可以嵌套循环。 Dict和Set类型 ","date":"2017-08-16","objectID":"/posts/5aab7/:13:5","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"Dict ","date":"2017-08-16","objectID":"/posts/5aab7/:14:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"什么是dict dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。dict用{ }表示，元素按照key: value写出来即可。最后一个key: value的逗号可以省略。 d = { key1: value1, key2: value2, key3: value3 } ","date":"2017-08-16","objectID":"/posts/5aab7/:14:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"访问dict 使用d[key]的形式来查找对应的 value，如果key 存在，dict就返回对应的value。这和 list 的不同之处是，list 使用索引返回对应的元素，而dict使用key。 注意：使用时要先用in操作符判断一下 key 是否存在，否则会报错KeyError！ d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 } if 'Paul' in d: #使用in运算符判断key存在否 print(d['Paul']) 使用dict提供的一个get方法，在Key不存在的时候，返回None或者自己指定的value。 \u003e\u003e\u003e print(d.get('Bart')) 59 \u003e\u003e\u003e print(d.get('Paul')) None \u003e\u003e\u003e print(d.get('Paul', -1)) -1 ","date":"2017-08-16","objectID":"/posts/5aab7/:14:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"dict的特点 查找速度快。无论dict有10个元素还是10万个元素，查找速度都一样。但代价是dict 占用内存大。（由于dict是按 key 查找，所以key不能重复。） 存储的key-value序对是没有顺序的。print的顺序不一定是我们创建时的顺序，而且，不同的机器打印的顺序都可能不同，这说明dict内部是无序的，不能用dict存储有序的集合。 key只能是不可变对象。Python的基本类型如字符串、整数、浮点数都是不可变的，都可以作为key。但是list是可变的，就不能作为key。 ","date":"2017-08-16","objectID":"/posts/5aab7/:14:3","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"更新dict 添加元素：可以用d[NewKey] = NewValue往dict中添加新的 key-value。如果 key 已经存在，则赋值会用新的 value 替换掉原来的 value。 d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 } \u003e\u003e\u003e d['Paul'] = 72 #添加新元素 \u003e\u003e\u003e print(d) {'Lisa': 85, 'Paul': 72, 'Adam': 95, 'Bart': 59} 删除元素：要删除一个key，用pop(key)方法（返回值是value），对应的value也会从dict中删除： \u003e\u003e\u003e d.pop('Paul') 72 \u003e\u003e\u003e d d = {'Adam': 95, 'Lisa': 85, 'Bart': 59} ","date":"2017-08-16","objectID":"/posts/5aab7/:14:4","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"遍历dict 直接使用for循环可以遍历 dict 的 key。又由于通过 key 可以获取对应的 value，因此在循环体内可以获取到value的值。 \u003e\u003e\u003e d = {'Adam': 95, 'Lisa': 85, 'Bart': 59} \u003e\u003e\u003e for key in d: ... print(key + ':', d[key]) ... Lisa: 85 Adam: 95 Bart: 59 ","date":"2017-08-16","objectID":"/posts/5aab7/:14:5","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"Set ","date":"2017-08-16","objectID":"/posts/5aab7/:15:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"什么是set set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中key不重复、无序且是确定的。set相当于数学上定义的集合。 创建 set 的方式是使用set()函数并传入一个可迭代对象，可迭代对象的元素将作为set的元素。当包含重复元素时，set会自动去掉重复的元素。 \u003e\u003e\u003e s = set(['A', 'B', 'C', 'C']) \u003e\u003e\u003e print(s) {'A', 'C', 'B'} \u003e\u003e\u003e len(s) 3 #重复的元素被删除 注意：上述打印的形式类似 list，但它不是 list；打印的顺序和原始 list 的顺序有可能是不同的，因为set内部存储的元素是无序的。 ","date":"2017-08-16","objectID":"/posts/5aab7/:15:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"遍历set 由于 set 也是一个集合，所以，遍历 set 和遍历 list 类似，通过 for 循环实现。 注意： for循环在遍历set时，元素的顺序和list的顺序很可能是不同的，而且不同的机器上运行的结果也可能不同。 ","date":"2017-08-16","objectID":"/posts/5aab7/:15:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"更新set 更新set主要做两件事： 添加元素：用set的add()方法。可以直接添加，元素已经存在则不会添加。 删除元素：用set的remove()方法。如果删除的元素不存在会报错KeyError，因此remove()前需要判断。 函数 ","date":"2017-08-16","objectID":"/posts/5aab7/:15:3","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"调用函数 调用一个函数，需要知道函数的名称和参数。调用函数的时候，如果传入的参数数量不对，或者参数类型不能被函数所接受，会报TypeError的错误。 ","date":"2017-08-16","objectID":"/posts/5aab7/:16:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"编写函数 定义函数要使用def语句，依次写出函数名、括号、括号中的参数和冒号，然后，在缩进中编写函数体，函数的返回值用return语句返回。 注意： 函数体内部的语句在执行时，一旦执行到return时，函数就执行完毕，并将结果返回； 如果没有return语句，函数执行完毕后也会返回结果，只是结果为None； return None可以简写为return； ","date":"2017-08-16","objectID":"/posts/5aab7/:17:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"返回多值 在函数体中，使用return x, y的形式来返回多个值，实际返回值是一个tuple。 import math def cal(len, angle): nx = len * math.cos(angle) ny = len * math.sin(angle) return nx, ny 这样我们就可以同时获得返回值： \u003e\u003e\u003e x, y = cal(10, math.pi / 6) \u003e\u003e\u003e print(x, y) 8.66025403784 5.0 但其实这只是一种假象，Python函数返回的仍然是单一值——一个tuple： \u003e\u003e\u003e r = cal(10, math.pi / 6) \u003e\u003e\u003e print(r) (8.66025403784, 5.0) 在语法上，返回一个tuple可以省略括号，而多个变量可以同时接收一个tuple，按位置赋给对应的值，所以，Python的函数返回多值其实就是返回一个tuple，但写起来更方便。 ","date":"2017-08-16","objectID":"/posts/5aab7/:18:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"递归函数 如果一个函数在内部调用自身本身，这个函数就是递归函数。 递归函数的优点是定义简单，逻辑清晰。理论上，所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰。 使用递归函数需要注意防止栈溢出。在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。尾递归可以有效防止栈溢出，但是Python并不支持:) 汉诺塔的移动可以看做是递归函数。我们对柱子编号为a, b, c，将所有圆盘从a移到c可以描述为：如果a只有一个圆盘，可以直接移动到c；如果a有N个圆盘，可以看成a有1个圆盘（底盘） + (N-1)个圆盘，首先需要把 (N-1) 个圆盘移动到 b，然后，将 a的最后一个圆盘移动到c，再将b的(N-1)个圆盘移动到c。请编写一个函数move(n, a, b, c)，给定输入 n, a, b, c，打印出移动的步骤。 例如，输入 move(2, ‘A’, ‘B’, ‘C’)，打印出： A –\u003e B A –\u003e C B –\u003e C def move(n, a, b, c): if n == 1: print('%s--\u003e%s' % (a, c)) else: move(n-1, a, c, b) move(1, a, b, c) move(n-1, b, a, c) ","date":"2017-08-16","objectID":"/posts/5aab7/:19:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"函数的参数 ","date":"2017-08-16","objectID":"/posts/5aab7/:20:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"定义默认参数 默认参数的作用是简化调用，你只要把必须的参数传进去。但在必要的时候，又可以传入额外的参数来覆盖默认参数值。默认参数必须指向不变对象。 由于函数的参数按从左到右的顺序匹配，所以默认参数只能定义在必需参数的后面——def function(a, b=1, c=2)。b和c即是默认参数。 设置原则：当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。变化小的参数就可以作为默认参数。 ","date":"2017-08-16","objectID":"/posts/5aab7/:20:1","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"定义可变参数 可变参数的目的也是为了简化调用。一个可变参数能让一个函数接受任意个参数。 可变参数的名字前面有个*号，我们可以传入0个、1个或多个参数给可变参数。 def calc(*numbers): sum = 0 for n in numbers: sum = sum + n * n return sum 在函数内部，参数numbers接收到的是一个tuple。 函数调用时，在list或者tuple前加一个*，可以把list或tuple的元素变成可变参数传进去。 \u003e\u003e\u003e nums = [1, 2, 3] \u003e\u003e\u003e calc(*nums) 14 ","date":"2017-08-16","objectID":"/posts/5aab7/:20:2","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"关键字参数 关键字参数允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。 def person(name, age, **kw): print('name:', name, 'age:', age, 'other:', kw) \u003e\u003e\u003e person('Adam', 45, gender='M', job='Engineer') name: Adam age: 45 other: {'gender': 'M', 'job': 'Engineer'} 和可变参数类似，也可以先组装出一个dict，然后，把该dict转换为关键字参数传进去： \u003e\u003e\u003e extra = {'city': 'Beijing', 'job': 'Engineer'} \u003e\u003e\u003e person('Jack', 24, **extra) name: Jack age: 24 other: {'city': 'Beijing', 'job': 'Engineer'} **extra表示把extra这个dict的所有key-value用关键字参数传入到函数的**kw参数，kw将获得一个dict，注意kw获得的dict是extra的一份拷贝，对kw的改动不会影响到函数外的extra。 ","date":"2017-08-16","objectID":"/posts/5aab7/:20:3","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"命名关键字参数 命名关键字参数用来限制传入函数的关键字参数的名字，只接收指定名字的参数。 命名关键字参数需要一个特殊分隔符*，*后面的参数被视为命名关键字参数。命名关键字参数必须传入参数名。 def person(name, age, *, city, job): print(name, age, city, job) \u003e\u003e\u003e person('Jack', 24, city='Beijing', job='Engineer') Jack 24 Beijing Engineer 如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了： def person(name, age, *args, city, job): print(name, age, args, city, job) 命名关键字参数可以有默认值，此时调用时可以不传入该参数： def person(name, age, *, city='Beijing', job): print(name, age, city, job) ","date":"2017-08-16","objectID":"/posts/5aab7/:20:4","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"参数组合 参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 对于任意函数，都可以通过类似func(*args, **kw)的形式调用它，无论它的参数是如何定义的。 切片 ","date":"2017-08-16","objectID":"/posts/5aab7/:20:5","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"对list/tuple进行切片 Python提供切片（Slice）操作符用于取list/tuple指定索引范围。 \u003e\u003e\u003e L = ['Adam', 'Lisa', 'Bart', 'Paul'] L[0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3。即索引0，1，2。 \u003e\u003e\u003e L[0:3] ['Adam', 'Lisa', 'Bart'] 如果第一个索引是0，还可以省略： \u003e\u003e\u003e L[:3] ['Adam', 'Lisa', 'Bart'] 只用一个:，表示从头到尾取全部元素（实际上复制出了一个新list。）： \u003e\u003e\u003e L[:] ['Adam', 'Lisa', 'Bart', 'Paul'] 切片操作还可以指定第三个参数。第三个参数表示每N个取一个，上面的 L[::2] 会每两个元素取出一个来，也就是隔一个取一个。 \u003e\u003e\u003e L[::2] ['Adam', 'Bart'] 对list切片的结果是list，对tuple切片的结果是tuple。 ","date":"2017-08-16","objectID":"/posts/5aab7/:21:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"倒序切片 倒序切片也是包含起始索引，不包含结束索引。 \u003e\u003e\u003e L = ['Adam', 'Lisa', 'Bart', 'Paul'] \u003e\u003e\u003e L[-2:] ['Bart', 'Paul'] \u003e\u003e\u003e L[:-2] ['Adam', 'Lisa'] \u003e\u003e\u003e L[-3:-1] ['Lisa', 'Bart'] \u003e\u003e\u003e L[-4👎2] ['Adam', 'Bart'] ","date":"2017-08-16","objectID":"/posts/5aab7/:22:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"对字符串切片 字符串'xxx'可以看成是一种list，每个元素就是一个字符。因此，字符串也可以用切片操作，操作结果仍是字符串。 \u003e\u003e\u003e 'ABCDEFG'[:3] 'ABC' \u003e\u003e\u003e 'ABCDEFG'[-3:] 'EFG' \u003e\u003e\u003e 'ABCDEFG'[::2] 'ACEG' 迭代 ","date":"2017-08-16","objectID":"/posts/5aab7/:23:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"什么是迭代 在Python中，迭代操作就是对于一个集合，无论该集合是有序还是无序，我们用 for 循环遍历这个集合，依次取出集合的每一个元素，这种遍历我们称为迭代（Iteration）。 注意：集合是指包含一组元素的数据结构，我们已经介绍的包括： 有序集合：list，tuple，str； 无序集合：set 无序集合并且具有 key-value 对：dict Python的for循环抽象程度要高于Java的for循环。Python的for循环不仅可以用在list或tuple上，还可以作用在其他可迭代对象上。 ","date":"2017-08-16","objectID":"/posts/5aab7/:24:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"判断可迭代对象 通过collections模块的Iterable类型可以判断。 \u003e\u003e\u003e from collections import Iterable \u003e\u003e\u003e isinstance([1,2,3], Iterable) # list可迭代 True \u003e\u003e\u003e isinstance(123, Iterable) # 整数不可迭代 False ","date":"2017-08-16","objectID":"/posts/5aab7/:25:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"迭代list的下标和元素 Python内置的enumerate函数可以把一个list变成“(索引, 元素)”形式的tuple组成的可迭代对象，这样就可以在for循环中同时迭代索引和元素本身： \u003e\u003e\u003e for i, value in enumerate(['A', 'B', 'C']): ... print(i, '-', value) ... 0 - A 1 - B 2 - C ","date":"2017-08-16","objectID":"/posts/5aab7/:26:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"迭代dict的value dict 对象有一个values()方法，可以用来迭代dict的value，注意dict是无序的。 for v in d.values(): ","date":"2017-08-16","objectID":"/posts/5aab7/:27:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"迭代dict的key 默认情况下，dict迭代的是key。 for key in d: ","date":"2017-08-16","objectID":"/posts/5aab7/:28:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"迭代dict的key和value dict对象的items()方法可以用来同时迭代key和value。 \u003e\u003e\u003e d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 } \u003e\u003e\u003e for key, value in d.items(): ... print('%s: %s' % (key, value)) ... Adam: 95 Bart: 59 Lisa: 85 列表生成式 ","date":"2017-08-16","objectID":"/posts/5aab7/:29:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"生成列表 如果要生成[1x1, 2x2, 3x3, …, 10x10]，方法一是循环，但是循环太繁琐；方法二是写列表生成式。 写列表生成式时，把要生成的元素 x * x 放到前面，后面跟 for 循环，就可以把list创建出来。 \u003e\u003e\u003e [x * x for x in range(1, 11)] [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] ","date":"2017-08-16","objectID":"/posts/5aab7/:30:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"进行条件过滤 列表生成式的 for 循环后面还可以加上 if 判断，只有 if 判断为 True 的时候，才把循环的当前元素添加到列表中。 \u003e\u003e\u003e [x * x for x in range(1, 11) if x % 2 == 0] [4, 16, 36, 64, 100] ","date":"2017-08-16","objectID":"/posts/5aab7/:31:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"使用多层表达式 for循环可以嵌套，因此，在列表生成式中，也可以用多层 for 循环来生成列表。 \u003e\u003e\u003e [m + n for m in 'ABC' for n in '123'] ['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3'] 生成器 通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器（Generator）。 ","date":"2017-08-16","objectID":"/posts/5aab7/:32:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"使用()创建生成器 把一个列表生成式的[]改成()，就创建了一个generator。如果要一个一个打印出generator的元素，可以通过next()函数。generator保存的是算法，每次调用next()，就计算出下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。 当然，上面这种不断调用next()函数实在是太变态了，正确的方法是使用for循环，因为generator也是可迭代对象。 \u003e\u003e\u003e g = (x * x for x in range(2)) \u003e\u003e\u003e g \u003cgenerator object \u003cgenexpr\u003e at 0x1021e0a98\u003e \u003e\u003e\u003e next(g) 0 \u003e\u003e\u003e next(g) 1 \u003e\u003e\u003e next(g) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e StopIteration ","date":"2017-08-16","objectID":"/posts/5aab7/:33:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"使用yield创建生成器 如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator。**变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。**同样的，把函数改成generator后，我们基本上从来不会用next()来调用它，而是直接使用for循环来迭代。 \u003e\u003e\u003e def fib(max): ... n, a, b = 0, 0, 1 ... while n \u003c max: ... yield b ... a, b = b, a + b ... n = n + 1 ... \u003e\u003e\u003e g = fib(6) \u003e\u003e\u003e g \u003cgenerator object fib at 0x101166a50\u003e \u003e\u003e\u003e for i in g: ... print(i) ... 1 1 2 3 5 8 迭代器 可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。 通过collections模块的Iterator类型可以判断是否是迭代器。 \u003e\u003e\u003e from collections import Iterator \u003e\u003e\u003e isinstance((x * x for x in range(10)), Iterator) True \u003e\u003e\u003e isinstance('abc', Iterator) False ","date":"2017-08-16","objectID":"/posts/5aab7/:34:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"迭代器和可迭代对象的区别 迭代器一定是可迭代对象，可迭代对象不一定是迭代器。两者是包含与被包含的关系。 生成器都是Iterator对象，但list、dict、str虽然是Iterable，却不是Iterator。 Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。Iterator甚至可以表示一个无限大的数据流，例如全体自然数 ","date":"2017-08-16","objectID":"/posts/5aab7/:35:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"把可迭代对象变为迭代器 把list、dict、str等Iterable变成Iterator可以使用iter()函数： \u003e\u003e\u003e isinstance(iter([]), Iterator) True \u003e\u003e\u003e isinstance(iter('abc'), Iterator) True Python的for循环本质上就是通过不断调用next()函数实现的。 写于2015年5月，2017年2月整理为Python3版本。 ","date":"2017-08-16","objectID":"/posts/5aab7/:36:0","tags":[],"title":"慕课网Python3入门课程笔记","uri":"/posts/5aab7/"},{"categories":["Python"],"content":"网络爬虫简介 ","date":"2017-08-16","objectID":"/posts/a0773/:0:0","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"合法性和注意事项 根据世界各地法院的一些案件： 如果抓取数据的行为用于个人使用，则不存在问题； 如果用于转载，则数据应该是现实生活中的真实数据（营业地址、电话清单等）；如果是原创数据（意见和评论），通常就会受到版权限制，而不能转载。 作为爬虫的自觉：约束自己的抓取速度，伪装成正常用户，使用浏览器UA来标识自己。 ","date":"2017-08-16","objectID":"/posts/a0773/:1:0","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"背景调研 ","date":"2017-08-16","objectID":"/posts/a0773/:2:0","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"检查robots.txt文件 使用urllib.robotparser模块解析robots.txt； \u003e\u003e\u003e import urllib.robotparser \u003e\u003e\u003e rp = urllib.robotparser.RobotFileParser() \u003e\u003e\u003e rp.set_url(\"http://www.musi-cal.com/robots.txt\") \u003e\u003e\u003e rp.read() \u003e\u003e\u003e rrate = rp.request_rate(\"*\") \u003e\u003e\u003e rrate.requests 3 \u003e\u003e\u003e rrate.seconds 20 \u003e\u003e\u003e rp.crawl_delay(\"*\") 6 \u003e\u003e\u003e rp.can_fetch(\"*\", \"http://www.musi-cal.com/cgi-bin/search?city=San+Francisco\") False \u003e\u003e\u003e rp.can_fetch(\"*\", \"http://www.musi-cal.com/\") True ","date":"2017-08-16","objectID":"/posts/a0773/:2:1","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"检查sitmap.xml文件 网站地图提供了所有网页的链接，网址由\u003cloc\u003e\u003c/loc\u003e标签包裹。 虽然sitemap文件提供了一种爬取网站的有效方式，但是我们仍需要对其谨慎处理，因为该文件经常存在缺失、过期或不完整的问题。 ","date":"2017-08-16","objectID":"/posts/a0773/:2:2","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"估算网站大小 目标网站的大小会影响我们如何进行爬取，大型网站需要考虑效率问题。我们可以通过Google搜索的site关键词过滤域名结果，从而获取该信息，在Google中搜索：site:example.webscraping.com。 在域名后面添加URL路径，可以对结果进行过滤，仅显示网站的某些部分。 ","date":"2017-08-16","objectID":"/posts/a0773/:2:3","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"识别网站所用的技术 使用builtwith模块（目前只支持Python2，作者已经更新了Python3的支持，但还没有提交到PyPI）分析网站使用的框架和技术； 可以使用Chrome扩展程序wappalyzer替代。 \u003e\u003e\u003e builtwith('http://wordpress.com') {u'blogs': [u'PHP', u'WordPress'], u'font-scripts': [u'Google Font API'], u'web-servers': [u'Nginx'], u'javascript-frameworks': [u'Modernizr'], u'programming-languages': [u'PHP'], u'cms': [u'WordPress']} \u003e\u003e\u003e builtwith('http://webscraping.com') {u'javascript-frameworks': [u'jQuery', u'Modernizr'], u'web-frameworks': [u'Twitter Bootstrap'], u'web-servers': [u'Nginx']} \u003e\u003e\u003e builtwith('http://microsoft.com') {u'javascript-frameworks': [u'jQuery'], u'mobile-frameworks': [u'jQuery Mobile'], u'operating-systems': [u'Windows Server'], u'web-servers': [u'IIS']} ","date":"2017-08-16","objectID":"/posts/a0773/:2:4","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"寻找网站所有者 使用python-whois包进行whois查询。 \u003e\u003e\u003e from pprint import pprint \u003e\u003e\u003e pprint(whois.whois('senguo.cc')) {'address': 'Le Jia International No.999 Liang Mu Road Yuhang District', 'city': 'Hangzhou', 'country': 'CN', 'creation_date': datetime.datetime(2014, 3, 25, 2, 36, 37), 'dnssec': 'unsigned', 'domain_name': ['SENGUO.CC', 'senguo.cc'], 'emails': ['DomainAbuse@service.aliyun.com', 'YuMing@YinSiBaoHu.AliYun.com'], 'expiration_date': datetime.datetime(2021, 3, 25, 2, 36, 37), 'name': 'Nexperian Holding Limited', 'name_servers': ['DNS31.HICHINA.COM', 'DNS32.HICHINA.COM', 'dns31.hichina.com', 'dns32.hichina.com'], 'org': 'Nexperian Holding Limited', 'referral_url': None, 'registrar': 'HICHINA ZHICHENG TECHNOLOGY LTD.', 'state': 'Zhejiang', 'status': ['ok https://icann.org/epp#ok', 'ok http://www.icann.org/epp#OK'], 'updated_date': datetime.datetime(2017, 2, 5, 1, 42, 34), 'whois_server': 'grs-whois.hichina.com', 'zipcode': '311121'} ","date":"2017-08-16","objectID":"/posts/a0773/:2:5","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"爬取（crawling） 为了抓取网站，我们首先需要下载包含有感兴趣数据的网页，该过程一般被称为爬取（crawling）。爬取一个网站有很多种方法，而选用那种方法更加合适，则取决于目标网站的结构。常见的3种爬取网站的方法： 爬取网站地图sitemap.xml； 便利每个网页的数据库ID； 跟踪网页链接。 要写一个健壮的爬虫，最好能实现以下高级特性。 ","date":"2017-08-16","objectID":"/posts/a0773/:3:0","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"自动重试 下载时遇到的错误经常是临时性的，对于此类错误，我们可以尝试重新下载。 4xx错误发生在请求存在问题时，不必重试； 5xx错误发生在服务器存在问题时，应该重试。 使用递归实现： def download(url, num_retries=3): try: result = ... # 下载相关代码 except DownloadError as e: http_code = ... # 获取http code if num_retries \u003e 0: if 500 \u003c= http_code \u003c 600: return download(url, num_retries-1) return result ","date":"2017-08-16","objectID":"/posts/a0773/:3:1","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"设置User-Agent Mac + Chrome: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36 Mac + Safari: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 iPad Mini4 + Safari： Mozilla/5.0 (iPad; CPU OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 iPhone SE + Safari： Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 ","date":"2017-08-16","objectID":"/posts/a0773/:3:2","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"使用代理 将可用的代理地址组成一个list，每次请求时使用random.choice从中随机取出一个使用。当然，这需要不断维护一个可用的代理列表。 在requests模块中，请求的proxies参数可以单独指定某个地址使用代理: Dictionary mapping protocol or protocol and host to the URL of the proxy (e.g. {‘http’: ‘foo.bar:3128’, ‘http://host.name’: ‘foo.bar:4012’}) to be used on each Request. ","date":"2017-08-16","objectID":"/posts/a0773/:3:3","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"下载限速 如果爬取速度过快，就会面临被服务器封禁或造成服务器过载的风险。为了降低这些风险，我们可以在两次下载之间添加延时，从而对爬虫限速。 import urllib.parse import time class Throttle: \"\"\"Add delay between downloads to the same domain\"\"\" def __init__(self, delay): # amount of delay between downloads for each domain self.delay = delay self.domains = {} def wait(self, url): domain = urllib.parse.urlparse(url).netloc last_accessed = self.domains.get(domain) if self.delay \u003e 0 and last_accessed is not None: sleep_secs = self.delay - (time.time() - last_accessed) / 1000 if sleep_secs \u003e 0: time.sleep(sleep_secs) self.domains[domain] = time.time() ","date":"2017-08-16","objectID":"/posts/a0773/:3:4","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Python"],"content":"控制爬取深度 跟踪网页链接爬取时，我们的爬虫会跟踪所有之前没有访问过的链接。但是一些网站会动态生成页面内容，这样会出现无限多的网页，页面无止境的链接下去，被称为爬虫陷阱。 避免爬虫陷阱的一种有效方式，是记录到达当前网页时的深度。当达到最大深度时，爬虫不再向队列中添加该网页中的链接。 def crawler(..., max_depth=2): max_depth = 2 seen = {} ... depth = seen[url] if depth != max_depth: for link in links: if link not in seen: seen[link] = depth + 1 crawl_queue.append(link) ","date":"2017-08-16","objectID":"/posts/a0773/:3:5","tags":[],"title":"用Python写网络爬虫(1)-网络爬虫简介","uri":"/posts/a0773/"},{"categories":["Infrastructure"],"content":"计算机网络综述 ","date":"2017-08-16","objectID":"/posts/45d45/:0:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"网络分层 OSI七层模型，从下往上：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。 TCP/IP四层模型，从下往上： 接口层：负责相邻物理设备之间的信息传输，对应物理层和数据链路层； 网络层：为两个主机之间提供通信服务，IP协议、ICMP(ping)、IGMP等协议； 传输层：为两个主机的不同端口之间的通信提供服务，TCP协议和UDP协议； 应用层：为用户进程直接提供服务。HTTP(S)、SSH等协议。 下面如果没有特别说明，都是以TCP/IP模型作为描述。 ","date":"2017-08-16","objectID":"/posts/45d45/:1:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"网络设备 集线器：工作在接口层，构成广播域（冲突域）； 交换机：工作在接口层，常用于划分VLAN，可以根据MAC地址来定向转发包，而不是广播； 路由器：工作在网络层，根据IP进行路由； ","date":"2017-08-16","objectID":"/posts/45d45/:2:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"IP地址、域名和URL IP地址：32位二进制数，常用4个十进制数字表示，有ABCDE五类； 域名：是一个应用层概念，由一串用点分割的名字组成，级别低的域名向左，级别高的域名向右，总长不超过255字符； URL：协议]://[主机]:[端口/路径?[参数]，其中主机可以是IP地址或者域名。 TCP和UDP ","date":"2017-08-16","objectID":"/posts/45d45/:3:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"端口 端口范围是0~65535，端口是软件级的概念，是传输层的寻址方式。 TCP和UDP可以在同一主机上使用相同的端口而互不干扰。 常见默认端口号： 端口号 传输层协议 解释 25 TCP SMTP简单邮件传输协议 3389 TCP Windows Remote Desktop远程桌面 1521 TCP Oracle数据库默认端口 3306 TCP MySQL数据库默认端口 6379 TCP Redis数据库默认端口 7001 TCP 网络服务器WebLogic的默认端口 8080 TCP 很多开源网络服务器的默认端口，例如JBoss、Tomcat等 5432 TCP PostgreSQL数据库的默认连接端口 ","date":"2017-08-16","objectID":"/posts/45d45/:4:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"TCP协议 TCP(Transmission Control Protocol，传输控制协议)是一种面向连接的、可靠的、基于字节流的传输层通信协议。其特性有：有序性、正确性、可靠性、可控性。 ","date":"2017-08-16","objectID":"/posts/45d45/:5:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"TCP建立连接 建立连接三次握手： 客户端发送SYN，进入SYN_SENT状态； 服务器反馈SYN+ACK包，进入SYN_RECV状态； 客户端发送确认包ACK，客户端和服务器同时进入ESTABLISHED状态。 ","date":"2017-08-16","objectID":"/posts/45d45/:5:1","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"TCP关闭连接 关闭连接四次握手： 关闭请求方（例如客户端）发送一个带有FIN标记的报文段； 服务器发送ACK确认信号，同时通知应用程序进行清理工作； 服务器的应用程序完成清理工作后，向客户端发送一个FIN报文段； 客户端向服务器发送ACK，表示连接彻底释放。 ","date":"2017-08-16","objectID":"/posts/45d45/:5:2","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"UDP协议 UDP(User Datagram Protocol，用户数据报协议)是一种无连接的传输层协议，提供面向事物的简单的不可靠信息传送服务。 应用场景：吞吐量大、可以承受信息丢失。 采用的协议：SNMP,NFS,DNS,BOOTP等。 HTTP HTTP(HyperText Transfer Protocol，超文本传输协议)，是一种用于分布式、协作式和超媒体信息系统的应用层协议。 客户端\u003c–\u003eWeb服务器\u003c–\u003e接口标准(WSGI/CGI/ISAPI)\u003c–\u003e服务端程序 ","date":"2017-08-16","objectID":"/posts/45d45/:6:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"HTTP流程 典型流程如下： 客户端主动建立TCP连接； 客户端发送HTTP请求； 服务端返回HTTP结果； 客户端主动关闭TCP连接。 当前HTTP版本还允许客户端在一次HTTP请求完成后不关闭TCP连接，后续HTTP请求可以复用该连接，达到减少系统整体开销的目的，此技术在HTTP中称为keep-alive。 ","date":"2017-08-16","objectID":"/posts/45d45/:7:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"HTTP消息结构 ","date":"2017-08-16","objectID":"/posts/45d45/:8:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"Request消息结构 [请求方法] [URL] [协议版本] [头字段1]: [值1] ... [头字段N]: [值N] [消息体] ","date":"2017-08-16","objectID":"/posts/45d45/:8:1","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"Response消息结构 [协议版本] [错误码] [错误字符串] [头字段1]: [值1] ... [头字段N]: [值N] [消息体] ","date":"2017-08-16","objectID":"/posts/45d45/:8:2","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"HTTP请求方法 HTTP方法 意义 DELETE 从给定的地址中删除信息 GET 从访问的地址中获取信息，包括信息头和信息体 HEAD 与GET的区别是，HEAD只获取信息头 OPTIONS 为客户端提供一种查询“本URL地址中有哪些可用的访问方式”的方法 POST 向服务器提交新数据，不允许出现重复的POST提交 PUT PUT允许客户端提交重复主键的数据，会用新提交的数据覆盖服务器中已有的数据 Socket Socket最初作为BSD UNIX的进程通信机制，通常被称作“套接字”。而如今Socket已经是操作系统所共同遵守的网络编程标准，用于描述IP地址和端口，是一个通信链的句柄，可以用来实现不同虚拟机或不同计算机之间的通道，Internet上的主机一般运行了多个服务软件，同时提供几种服务，每种服务都打开一个Socket，并绑定到一个端口上，不同的端口对应不同的服务。 Socket使用IP地址+端口+协议的三元组唯一标识一个通信链路。服务器端的一个通信链路可以对应于多个客户端。 ","date":"2017-08-16","objectID":"/posts/45d45/:9:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"Socket TCP原语 socket()：建立Socket对象。参数中通常包括使用的传输层协议类型、网络层地址类型等。 bind()：绑定。在参数中需要传入要绑定的IP地址的端口。IP地址必须可用（绑定0.0.0.0时可以监听所有可用IP。端口必须是一个该socket协议未被占用的端口。服务器端程序在listen()之前必须进行bind()操作，而客户端程序如果在connect()前没有bind()，系统会自动为该Socket分配一个未被占用的地址和端口。 listen()：监听。只在服务器端有用，开始坚挺之前绑定的IP地址和端口。可以在参数中指定允许排队的最大连接数量。 connect()：在客户端连接服务器。参数中需要指定服务器的IP和端口。 accept()：接收连接。只在服务器端有用，从监听到的连接中取出一个，并将其包装成一个新的socket对象，这个对象可被用于和相应的客户端进行通信。如果当前客户端没有连接请求，则accept()会阻塞等待。 send()：发送数据。 recv()：接收数据。如果Socket中没有消息可以读取，默认recv()调用会被阻塞直到有消息到达，如果设置为非阻塞模式，recv()以失败形式返回。 close()：关闭连接。任何一方都可调用，另一方收到后也调用close()关闭连接。 Socket流程： 客户端建立Socket对象socket()； 服务端建立Socket对象socket()，绑定IP和端口bind()，开始监听listen()； 客户端连接服务器connect()，服务器接收连接accept()； 客户端与服务端互相发送send() 接收recv()数据； 关闭连接close()。 ","date":"2017-08-16","objectID":"/posts/45d45/:10:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":["Infrastructure"],"content":"Socket UDP原语 除复用TCP中的socket()和bind()原语之外，UDP属于自己的原语有： recvfrom()：从绑定的地址接收数据； sendto()：向指定的地址发送数据，在调用的参数中应该传入通信对端的地址和端口。 ","date":"2017-08-16","objectID":"/posts/45d45/:11:0","tags":[],"title":"网络基础","uri":"/posts/45d45/"},{"categories":null,"content":"WechatJump 基于 adb + pillow + opencv + sklearn 实现的微信跳一跳机器人，采用线性回归和多项式回归，轻松上 30 万分。 flask-tutorial 参照 Flask 官方文档 tutorial 部分 写的 Flaskr 博客应用。 与官方示例应用不同的是，我使用了以下常用的 Flask 扩展来完成功能。 Flask-SQLAlchemy Flask-Login Flask-Migrate shadowsocks-docker 使用 Docker 快速部署 Shadowsocks 服务端，包含内核参数调优配置和 BBR 算法开启步骤。 secure-nginx 基于 https://nginxconfig.io/ 为 HTTPS 网站生成的 Nginx 安全配置示例，易于拓展业务配置，并保证安全性。 flask-with-celery-example 在 Flask 的大型程序结构中集成 Celery 的一种方式，能够在 Flask 中使用 current_app 上下文。 欢迎访问 我的 GitHub 查看更多项目。 ","date":"0001-01-01","objectID":"/projects/:0:0","tags":null,"title":"项目","uri":"/projects/"}]